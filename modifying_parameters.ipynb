{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modifying and Loading Parameters of Policies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "import gym\n",
    "import numpy as np\n",
    "import torch as th\n",
    "\n",
    "from stable_baselines3 import A2C\n",
    "from stable_baselines3.common.evaluation import evaluate_policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mutate Function to modify Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutate(params: Dict[str, th.Tensor]) -> Dict[str, th.Tensor]:\n",
    "    \"\"\"Mutate parameters by adding normal noise to them\"\"\"\n",
    "    return dict((name, param + th.randn_like(param)) for name, param in params.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Policy with a small Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('CartPole-v1')\n",
    "model = A2C(\n",
    "    \"MlpPolicy\",\n",
    "    env,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Initial Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 59.6     |\n",
      "|    ep_rew_mean        | 59.6     |\n",
      "| time/                 |          |\n",
      "|    fps                | 686      |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 0        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.644   |\n",
      "|    explained_variance | 0.104    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | 1.4      |\n",
      "|    value_loss         | 8.78     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 58.2     |\n",
      "|    ep_rew_mean        | 58.2     |\n",
      "| time/                 |          |\n",
      "|    fps                | 716      |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 1        |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.618   |\n",
      "|    explained_variance | -0.0138  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | 1.1      |\n",
      "|    value_loss         | 7.26     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 62.5     |\n",
      "|    ep_rew_mean        | 62.5     |\n",
      "| time/                 |          |\n",
      "|    fps                | 752      |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 1        |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.515   |\n",
      "|    explained_variance | 0.0459   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | 0.583    |\n",
      "|    value_loss         | 5.93     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 66       |\n",
      "|    ep_rew_mean        | 66       |\n",
      "| time/                 |          |\n",
      "|    fps                | 784      |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 2        |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.451   |\n",
      "|    explained_variance | -0.00878 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | 0.719    |\n",
      "|    value_loss         | 5.44     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 66.1     |\n",
      "|    ep_rew_mean        | 66.1     |\n",
      "| time/                 |          |\n",
      "|    fps                | 809      |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 3        |\n",
      "|    total_timesteps    | 2500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.486   |\n",
      "|    explained_variance | -0.00336 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | 0.741    |\n",
      "|    value_loss         | 4.82     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 69.3     |\n",
      "|    ep_rew_mean        | 69.3     |\n",
      "| time/                 |          |\n",
      "|    fps                | 827      |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 3        |\n",
      "|    total_timesteps    | 3000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.309   |\n",
      "|    explained_variance | 0.0214   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | 0.934    |\n",
      "|    value_loss         | 4.15     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 71.3     |\n",
      "|    ep_rew_mean        | 71.3     |\n",
      "| time/                 |          |\n",
      "|    fps                | 840      |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 4        |\n",
      "|    total_timesteps    | 3500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.289   |\n",
      "|    explained_variance | -0.00283 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | 0.749    |\n",
      "|    value_loss         | 3.71     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 76.7     |\n",
      "|    ep_rew_mean        | 76.7     |\n",
      "| time/                 |          |\n",
      "|    fps                | 850      |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 4        |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.377   |\n",
      "|    explained_variance | 0.000175 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | 1.11     |\n",
      "|    value_loss         | 3.19     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 80.1      |\n",
      "|    ep_rew_mean        | 80.1      |\n",
      "| time/                 |           |\n",
      "|    fps                | 859       |\n",
      "|    iterations         | 900       |\n",
      "|    time_elapsed       | 5         |\n",
      "|    total_timesteps    | 4500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.447    |\n",
      "|    explained_variance | -1.59e-05 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 899       |\n",
      "|    policy_loss        | 0.44      |\n",
      "|    value_loss         | 2.72      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 82       |\n",
      "|    ep_rew_mean        | 82       |\n",
      "| time/                 |          |\n",
      "|    fps                | 866      |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 5        |\n",
      "|    total_timesteps    | 5000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.327   |\n",
      "|    explained_variance | 0.00119  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | 0.477    |\n",
      "|    value_loss         | 2.29     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 85       |\n",
      "|    ep_rew_mean        | 85       |\n",
      "| time/                 |          |\n",
      "|    fps                | 872      |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 6        |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.381   |\n",
      "|    explained_variance | 2.75e-05 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | 0.195    |\n",
      "|    value_loss         | 1.89     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 87.2     |\n",
      "|    ep_rew_mean        | 87.2     |\n",
      "| time/                 |          |\n",
      "|    fps                | 876      |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 6        |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.388   |\n",
      "|    explained_variance | 4.65e-05 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | 0.308    |\n",
      "|    value_loss         | 1.54     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 90.4      |\n",
      "|    ep_rew_mean        | 90.4      |\n",
      "| time/                 |           |\n",
      "|    fps                | 880       |\n",
      "|    iterations         | 1300      |\n",
      "|    time_elapsed       | 7         |\n",
      "|    total_timesteps    | 6500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.441    |\n",
      "|    explained_variance | -0.000103 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1299      |\n",
      "|    policy_loss        | 0.381     |\n",
      "|    value_loss         | 1.21      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 91.3      |\n",
      "|    ep_rew_mean        | 91.3      |\n",
      "| time/                 |           |\n",
      "|    fps                | 884       |\n",
      "|    iterations         | 1400      |\n",
      "|    time_elapsed       | 7         |\n",
      "|    total_timesteps    | 7000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.449    |\n",
      "|    explained_variance | -5.96e-06 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1399      |\n",
      "|    policy_loss        | 0.24      |\n",
      "|    value_loss         | 0.931     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 92.1      |\n",
      "|    ep_rew_mean        | 92.1      |\n",
      "| time/                 |           |\n",
      "|    fps                | 887       |\n",
      "|    iterations         | 1500      |\n",
      "|    time_elapsed       | 8         |\n",
      "|    total_timesteps    | 7500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.384    |\n",
      "|    explained_variance | -0.000228 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1499      |\n",
      "|    policy_loss        | 0.181     |\n",
      "|    value_loss         | 0.691     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 92.6      |\n",
      "|    ep_rew_mean        | 92.6      |\n",
      "| time/                 |           |\n",
      "|    fps                | 890       |\n",
      "|    iterations         | 1600      |\n",
      "|    time_elapsed       | 8         |\n",
      "|    total_timesteps    | 8000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.423    |\n",
      "|    explained_variance | -3.71e-05 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1599      |\n",
      "|    policy_loss        | 0.159     |\n",
      "|    value_loss         | 0.485     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 93.7      |\n",
      "|    ep_rew_mean        | 93.7      |\n",
      "| time/                 |           |\n",
      "|    fps                | 892       |\n",
      "|    iterations         | 1700      |\n",
      "|    time_elapsed       | 9         |\n",
      "|    total_timesteps    | 8500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.41     |\n",
      "|    explained_variance | -3.67e-05 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1699      |\n",
      "|    policy_loss        | 0.21      |\n",
      "|    value_loss         | 0.313     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 94.4      |\n",
      "|    ep_rew_mean        | 94.4      |\n",
      "| time/                 |           |\n",
      "|    fps                | 894       |\n",
      "|    iterations         | 1800      |\n",
      "|    time_elapsed       | 10        |\n",
      "|    total_timesteps    | 9000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.374    |\n",
      "|    explained_variance | -2.52e-05 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1799      |\n",
      "|    policy_loss        | 0.0534    |\n",
      "|    value_loss         | 0.18      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 92.3      |\n",
      "|    ep_rew_mean        | 92.3      |\n",
      "| time/                 |           |\n",
      "|    fps                | 894       |\n",
      "|    iterations         | 1900      |\n",
      "|    time_elapsed       | 10        |\n",
      "|    total_timesteps    | 9500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.431    |\n",
      "|    explained_variance | -0.000203 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1899      |\n",
      "|    policy_loss        | 0.05      |\n",
      "|    value_loss         | 0.091     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 94.1     |\n",
      "|    ep_rew_mean        | 94.1     |\n",
      "| time/                 |          |\n",
      "|    fps                | 896      |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 11       |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.326   |\n",
      "|    explained_variance | 0.000183 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | 0.0445   |\n",
      "|    value_loss         | 0.0279   |\n",
      "------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.a2c.a2c.A2C at 0x7f6ec86e2cf8>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use traditional actor-critic policy gradient updates to\n",
    "# find good initial parameters\n",
    "model.learn(total_timesteps=10_000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve Policy Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mlp_extractor.policy_net.0.weight': tensor([[-1.2999e-01,  2.4489e-01, -2.4168e-01, -1.9392e-01],\n",
       "         [ 2.1343e-01, -1.4928e-01, -2.1906e-01, -2.2806e-01],\n",
       "         [-1.9922e-01, -7.2524e-02,  2.7773e-01,  5.9612e-02],\n",
       "         [ 1.2960e-03,  3.0906e-01, -1.7327e-01,  7.5899e-02],\n",
       "         [-1.5672e-02, -2.5386e-01,  1.5331e-01, -8.1522e-03],\n",
       "         [ 2.6331e-01,  1.9324e-01, -1.2731e-01, -8.8238e-02],\n",
       "         [ 6.9915e-02,  1.4019e-01,  4.9944e-02,  3.4992e-01],\n",
       "         [-8.7018e-02, -1.6019e-02,  4.3477e-02,  3.1152e-01],\n",
       "         [ 1.3564e-01,  2.2845e-01,  2.3310e-01,  9.6888e-02],\n",
       "         [ 9.0050e-02,  1.4930e-01,  3.0171e-01,  2.6908e-01],\n",
       "         [ 2.2106e-01,  2.9067e-01,  6.4909e-02, -3.8618e-01],\n",
       "         [ 1.0708e-01, -2.2509e-01, -2.4501e-01, -8.5982e-02],\n",
       "         [ 1.3579e-01,  2.9970e-01,  2.8183e-02, -3.9338e-01],\n",
       "         [-7.4302e-02,  1.4286e-01, -1.0769e-01, -3.3475e-01],\n",
       "         [ 3.5629e-01,  2.6837e-01, -2.3631e-02, -2.8512e-01],\n",
       "         [-1.0405e-01,  1.2668e-01,  1.5698e-01, -2.0183e-01],\n",
       "         [-8.6718e-02,  1.3084e-01, -8.0342e-02,  2.0361e-03],\n",
       "         [ 5.7250e-02, -2.2133e-01,  1.3900e-01,  5.3112e-01],\n",
       "         [ 1.4132e-01, -1.5912e-01, -3.5092e-01, -3.3850e-01],\n",
       "         [ 1.1991e-01,  1.3570e-01, -2.0652e-01, -3.3174e-01],\n",
       "         [ 5.7053e-02,  3.7851e-02, -1.4322e-02,  4.0581e-01],\n",
       "         [ 2.8468e-02,  3.2230e-02,  5.4385e-02, -2.0413e-01],\n",
       "         [ 9.6113e-03,  1.1510e-01, -6.0241e-02, -1.8162e-01],\n",
       "         [ 6.1430e-02,  1.1128e-01, -7.4527e-02,  2.0675e-01],\n",
       "         [ 1.5581e-01, -1.4727e-01,  8.1406e-02,  1.5949e-01],\n",
       "         [ 5.8365e-02, -3.6246e-02, -5.8328e-02, -1.4398e-01],\n",
       "         [-1.8061e-01,  1.3226e-02,  1.0208e-01, -2.3655e-01],\n",
       "         [ 8.7717e-02,  1.7795e-01,  3.4724e-01, -1.6461e-01],\n",
       "         [-1.1630e-01,  1.8989e-01,  1.2332e-03, -3.2998e-01],\n",
       "         [-1.5236e-01, -8.6286e-02,  1.6268e-01,  1.3492e-01],\n",
       "         [ 1.8295e-01, -2.7862e-01,  4.0046e-01,  4.9314e-02],\n",
       "         [ 4.4198e-02,  2.4250e-01, -1.5723e-01, -6.1178e-02],\n",
       "         [ 2.3482e-01, -9.0795e-02, -3.8064e-01, -1.9124e-02],\n",
       "         [-3.9922e-01,  2.2352e-02,  8.0550e-02, -2.6025e-02],\n",
       "         [-2.2519e-01,  2.4273e-01,  1.0617e-02,  1.9812e-01],\n",
       "         [-2.3917e-01, -1.3003e-01, -1.6389e-02, -4.5374e-01],\n",
       "         [-2.0592e-01, -2.3913e-01,  1.8313e-01, -7.9543e-02],\n",
       "         [ 1.7418e-01,  3.5256e-02, -1.9036e-01, -3.5812e-01],\n",
       "         [ 1.1501e-01, -1.5992e-01, -2.8000e-02,  1.7130e-02],\n",
       "         [-3.4650e-02, -2.6912e-01,  9.9126e-02, -4.0160e-01],\n",
       "         [ 6.4254e-02, -1.7900e-02,  1.4024e-01,  6.0276e-02],\n",
       "         [-2.9374e-02,  7.8235e-02, -3.3987e-02,  2.9041e-01],\n",
       "         [-7.3513e-02,  1.2904e-01,  2.0635e-01, -1.5970e-01],\n",
       "         [-2.8579e-01,  2.0000e-01,  9.7875e-02, -1.4313e-01],\n",
       "         [-2.6322e-01,  2.1784e-01,  1.0124e-01,  1.9280e-02],\n",
       "         [ 1.7407e-01, -2.2529e-02,  3.1282e-01,  2.1250e-01],\n",
       "         [-1.4260e-01, -1.8805e-01, -1.7483e-01, -5.3836e-01],\n",
       "         [ 1.6025e-01,  2.8206e-01,  3.0060e-02,  8.0127e-02],\n",
       "         [ 1.0952e-01,  3.7114e-02,  2.0387e-01,  3.0788e-01],\n",
       "         [-5.6110e-02, -1.3865e-01,  6.0189e-02,  2.3638e-01],\n",
       "         [-1.4112e-01,  4.1147e-01,  1.7494e-01,  6.3521e-02],\n",
       "         [-1.8880e-01,  7.7825e-03,  2.2445e-01,  1.0103e-01],\n",
       "         [-3.4327e-01,  7.1645e-02, -2.4234e-01, -8.6847e-02],\n",
       "         [-1.0313e-01, -1.0597e-01,  5.1991e-02, -2.1814e-01],\n",
       "         [-5.4413e-02,  2.7269e-01,  4.6842e-02, -3.7031e-02],\n",
       "         [ 1.9971e-01, -3.1048e-02,  3.8141e-01,  3.3528e-01],\n",
       "         [-1.7911e-01,  2.7798e-02, -4.1873e-01, -3.0762e-01],\n",
       "         [ 3.2005e-01, -1.0224e-01,  1.8016e-01,  2.4610e-01],\n",
       "         [ 2.9714e-01,  6.3317e-02, -6.3730e-02,  1.8132e-01],\n",
       "         [-4.4816e-04,  7.8402e-02, -8.6700e-02,  3.3715e-01],\n",
       "         [-2.9269e-01,  2.0217e-01, -4.3908e-01, -1.8875e-01],\n",
       "         [-3.1528e-01,  1.0824e-01, -4.2515e-01, -2.3890e-01],\n",
       "         [ 1.8028e-03,  8.6101e-02, -4.1733e-01, -1.7909e-01],\n",
       "         [-2.7667e-02, -1.0792e-01,  1.0802e-02, -4.9581e-01]]),\n",
       " 'mlp_extractor.policy_net.0.bias': tensor([-0.0297, -0.0292, -0.0240,  0.0560, -0.0349,  0.0191,  0.0346,  0.0287,\n",
       "          0.0346,  0.0309, -0.0351, -0.0298, -0.0333, -0.0274, -0.0305, -0.0264,\n",
       "          0.0409,  0.0319, -0.0297, -0.0297,  0.0307, -0.0283, -0.0293,  0.0306,\n",
       "          0.0286, -0.0301, -0.0303,  0.0289, -0.0284,  0.0271,  0.0249,  0.0197,\n",
       "         -0.0147, -0.0383,  0.0318, -0.0350, -0.0522, -0.0314, -0.0433, -0.0358,\n",
       "          0.0181,  0.0270,  0.0184, -0.0300,  0.0109,  0.0334, -0.0351,  0.0532,\n",
       "          0.0331,  0.0290,  0.0570,  0.0264, -0.0330, -0.0349,  0.0239,  0.0311,\n",
       "         -0.0284,  0.0318,  0.0381,  0.0284, -0.0276, -0.0278, -0.0306, -0.0315]),\n",
       " 'mlp_extractor.policy_net.2.weight': tensor([[-1.4552e-01, -7.6080e-02,  2.0567e-02,  ...,  3.1963e-01,\n",
       "          -1.8661e-01, -1.6802e-01],\n",
       "         [-1.9740e-02,  1.7513e-02, -1.7116e-01,  ..., -2.3174e-01,\n",
       "           1.4232e-01, -4.3447e-01],\n",
       "         [ 8.2743e-02, -3.3537e-01,  6.9178e-02,  ...,  3.2608e-02,\n",
       "           9.4826e-02, -1.6561e-02],\n",
       "         ...,\n",
       "         [ 2.0280e-01, -8.0746e-02, -1.8898e-01,  ..., -2.8332e-01,\n",
       "          -2.6046e-04, -1.6234e-01],\n",
       "         [-2.5918e-01, -2.1864e-01,  1.2891e-01,  ..., -3.2907e-01,\n",
       "          -5.6208e-02,  3.8690e-02],\n",
       "         [ 1.1665e-02, -9.6251e-02,  2.5890e-01,  ..., -9.5878e-02,\n",
       "          -1.4115e-02,  3.6580e-01]]),\n",
       " 'mlp_extractor.policy_net.2.bias': tensor([ 0.0324,  0.0318, -0.0293, -0.0308,  0.0359, -0.0359,  0.0311, -0.0292,\n",
       "          0.0299,  0.0316,  0.0357,  0.0294, -0.0293,  0.0273, -0.0330, -0.0326,\n",
       "         -0.0325, -0.0353, -0.0317,  0.0300,  0.0320, -0.0310, -0.0312,  0.0290,\n",
       "         -0.0315, -0.0305, -0.0312,  0.0280,  0.0278, -0.0296, -0.0313,  0.0301,\n",
       "         -0.0288, -0.0298, -0.0305, -0.0334,  0.0290, -0.0296, -0.0340,  0.0289,\n",
       "          0.0274,  0.0299, -0.0313,  0.0294, -0.0310, -0.0272, -0.0338,  0.0294,\n",
       "          0.0289, -0.0335, -0.0297, -0.0275,  0.0277,  0.0355, -0.0217,  0.0311,\n",
       "         -0.0304,  0.0305, -0.0319,  0.0314,  0.0315,  0.0264,  0.0291, -0.0332]),\n",
       " 'action_net.weight': tensor([[-0.1224, -0.1117,  0.0519,  0.0785, -0.1131,  0.1126, -0.0408,  0.0936,\n",
       "          -0.1082, -0.0728, -0.1024, -0.1056,  0.0659, -0.0689,  0.0624,  0.1010,\n",
       "           0.0327,  0.1121,  0.1219, -0.1036, -0.1112,  0.0654,  0.0180, -0.0625,\n",
       "           0.1137,  0.1087,  0.0233, -0.0649, -0.0544,  0.0742,  0.0481, -0.0686,\n",
       "           0.1029,  0.0703,  0.0808,  0.0465, -0.0566,  0.0865,  0.1087, -0.0239,\n",
       "          -0.0911, -0.1018,  0.0607, -0.1024,  0.0902,  0.0748,  0.0816, -0.1035,\n",
       "          -0.0491,  0.1006,  0.0025,  0.0843, -0.0678, -0.1137,  0.0013, -0.0844,\n",
       "           0.0615, -0.1051,  0.1136, -0.1198, -0.0596, -0.0650, -0.1070,  0.0939],\n",
       "         [ 0.1208,  0.1124, -0.0490, -0.0791,  0.1151, -0.1112,  0.0427, -0.0902,\n",
       "           0.1090,  0.0721,  0.1039,  0.1051, -0.0662,  0.0687, -0.0627, -0.1031,\n",
       "          -0.0323, -0.1108, -0.1194,  0.1019,  0.1114, -0.0674, -0.0194,  0.0633,\n",
       "          -0.1137, -0.1081, -0.0239,  0.0654,  0.0533, -0.0728, -0.0473,  0.0664,\n",
       "          -0.1016, -0.0729, -0.0804, -0.0487,  0.0550, -0.0839, -0.1129,  0.0244,\n",
       "           0.0917,  0.1020, -0.0569,  0.1022, -0.0910, -0.0740, -0.0802,  0.1040,\n",
       "           0.0523, -0.1008,  0.0005, -0.0850,  0.0652,  0.1149,  0.0018,  0.0835,\n",
       "          -0.0591,  0.1038, -0.1126,  0.1185,  0.0624,  0.0682,  0.1052, -0.0961]]),\n",
       " 'action_net.bias': tensor([-0.0383,  0.0383])}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Include only variables with \"policy\", \"action\" (policy) or \"shared_net\" (shared layers)\n",
    "# in their name: only these ones affect the action.\n",
    "# NOTE: you can retrieve those parameters using model.get_parameters() too\n",
    "mean_params = dict(\n",
    "    (key, value)\n",
    "    for key, value in model.policy.state_dict().items()\n",
    "    if (\"policy\" in key or \"shared_net\" in key or \"action\" in key)\n",
    ")\n",
    "\n",
    "mean_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Population Size and Retrieve Environment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# population size of 50 invdiduals\n",
    "pop_size = 50\n",
    "# Keep top 10%\n",
    "n_elite = pop_size // 10\n",
    "# Retrieve the environment\n",
    "env = model.get_env()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterate through Mutated Policy Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1   Mean top fitness: 59.66\n",
      "Best fitness: 88.30\n",
      "Iteration 2   Mean top fitness: 206.38\n",
      "Best fitness: 298.90\n",
      "Iteration 3   Mean top fitness: 137.26\n",
      "Best fitness: 217.20\n",
      "Iteration 4   Mean top fitness: 368.84\n",
      "Best fitness: 455.80\n",
      "Iteration 5   Mean top fitness: 278.04\n",
      "Best fitness: 384.50\n",
      "Iteration 6   Mean top fitness: 346.00\n",
      "Best fitness: 425.00\n",
      "Iteration 7   Mean top fitness: 485.16\n",
      "Best fitness: 500.00\n",
      "Iteration 8   Mean top fitness: 496.04\n",
      "Best fitness: 500.00\n",
      "Iteration 9   Mean top fitness: 486.30\n",
      "Best fitness: 500.00\n",
      "Iteration 10  Mean top fitness: 492.06\n",
      "Best fitness: 500.00\n"
     ]
    }
   ],
   "source": [
    "for iteration in range(10):\n",
    "    # Create population of candidates and evaluate them\n",
    "    population = []\n",
    "    for population_i in range(pop_size):\n",
    "        candidate = mutate(mean_params)\n",
    "        # Load new policy parameters to agent.\n",
    "        # Tell function that it should only update parameters\n",
    "        # we give it (policy parameters)\n",
    "        model.policy.load_state_dict(candidate, strict=False)\n",
    "        # Evaluate the candidate\n",
    "        fitness, _ = evaluate_policy(model, env)\n",
    "        population.append((candidate, fitness))\n",
    "    # Take top 10% and use average over their parameters as next mean parameter\n",
    "    top_candidates = sorted(population, key=lambda x: x[1], reverse=True)[:n_elite]\n",
    "    mean_params = dict(\n",
    "        (\n",
    "            name,\n",
    "            th.stack([candidate[0][name] for candidate in top_candidates]).mean(dim=0),\n",
    "        )\n",
    "        for name in mean_params.keys()\n",
    "    )\n",
    "    mean_fitness = sum(top_candidate[1] for top_candidate in top_candidates) / n_elite\n",
    "    print(f\"Iteration {iteration + 1:<3} Mean top fitness: {mean_fitness:.2f}\")\n",
    "    print(f\"Best fitness: {top_candidates[0][1]:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3fe87c7677a9be80aab770929aa8f3d40850ac08a0f73ec246342c77c48f1c11"
  },
  "kernelspec": {
   "display_name": "Python 3.7.2 64-bit ('pydrl': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
