{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi Train Gradient Update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arnab/.miniconda3/envs/pydrl/lib/python3.7/site-packages/ale_py/roms/utils.py:90: DeprecationWarning: SelectableGroups dict interface is deprecated. Use select.\n",
      "  for external in metadata.entry_points().get(self.group, []):\n"
     ]
    }
   ],
   "source": [
    "from typing import Dict\n",
    "import threading\n",
    "\n",
    "import gym\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from stable_baselines3 import PPO as ALGO\n",
    "from stable_baselines3.common.evaluation import evaluate_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-Parameters\n",
    "NUM_CLIENT_MODELS = 4\n",
    "NUM_TRAINING_STEPS = 1000\n",
    "NUM_ITERATIONS = 10\n",
    "ENV_NAME = 'CartPole-v1'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init. ENV and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(ENV_NAME)\n",
    "global_model = ALGO(\n",
    "    \"MlpPolicy\",\n",
    "    env\n",
    ")\n",
    "\n",
    "client_models = [ALGO(\"MlpPolicy\", gym.make(ENV_NAME)) for i in range(NUM_CLIENT_MODELS)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to Evaluate Model and Train Model within Thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(models, env, index, eval_results, message = '', verbose = 0):\n",
    "    # print('Starting Eval')\n",
    "    fitnesses = []\n",
    "    iterations = 10\n",
    "    for i in range(iterations):\n",
    "        fitness, _ = evaluate_policy(models[index], env)\n",
    "        if verbose == 1:\n",
    "            print(i, fitness, end=\" \")\n",
    "        fitnesses.append(fitness)\n",
    "\n",
    "    mean_fitness = np.mean(sorted(fitnesses))\n",
    "    eval_results[index] = mean_fitness\n",
    "    print(f'Type {message} Mean reward: {mean_fitness}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(models, index, timesteps):\n",
    "    # print('Starting Training')\n",
    "    models[index] = models[index].learn(reset_num_timesteps=False, total_timesteps=timesteps)\n",
    "    # print('Completed Training')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multithread_eval(client_models):\n",
    "    # Create Threads\n",
    "    client_threads = []\n",
    "    eval_results = [0 for i in range(len(client_models))] \n",
    "    for ci in range(NUM_CLIENT_MODELS):\n",
    "        thread = threading.Thread(target=evaluate, args=(client_models, gym.make(ENV_NAME), ci, eval_results, f'Trained Model {ci}'))\n",
    "        client_threads.append(thread)\n",
    "\n",
    "    # Start Threads\n",
    "    for thread in client_threads:\n",
    "        thread.start()\n",
    "\n",
    "    # Join Threads (wait until thread is completely executed)\n",
    "    for thread in client_threads:\n",
    "        thread.join()\n",
    "\n",
    "    return eval_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arnab/.miniconda3/envs/pydrl/lib/python3.7/site-packages/stable_baselines3/common/evaluation.py:69: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  UserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type  Mean reward: 9.879999999999999\n",
      "Type Trained Model 2 Mean reward: 9.879999999999999\n",
      "Type Trained Model 0 Mean reward: 9.830000000000002\n",
      "Type Trained Model 1 Mean reward: 9.84\n",
      "Type Trained Model 3 Mean reward: 9.95\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[9.830000000000002, 9.84, 9.879999999999999, 9.95]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for model in client_models:\n",
    "    model.set_parameters(global_model.get_parameters())\n",
    "\n",
    "global_model.save('initial')\n",
    "\n",
    "evaluate([global_model], env, 0, [0])\n",
    "\n",
    "multithread_eval(client_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type Global Initial Model Mean reward: 9.99\n",
      "Train Iter:  0\n",
      "Optim Steps:  320\n",
      "Type Trained Model 1 Mean reward: 108.34\n",
      "Type Trained Model 2 Mean reward: 176.39\n",
      "Type Trained Model 3 Mean reward: 181.3\n",
      "Type Trained Model 0 Mean reward: 312.37\n",
      "Type Global Updated Model Mean reward: 245.08999999999997\n",
      "Train Iter:  1\n",
      "Optim Steps:  640\n",
      "Type Trained Model 0 Mean reward: 222.47000000000003\n",
      "Type Trained Model 3 Mean reward: 255.99\n",
      "Type Trained Model 2 Mean reward: 271.81000000000006\n",
      "Type Trained Model 1 Mean reward: 292.27000000000004\n",
      "Type Global Updated Model Mean reward: 270.2\n",
      "Train Iter:  2\n",
      "Optim Steps:  960\n",
      "Type Trained Model 3 Mean reward: 274.69999999999993\n",
      "Type Trained Model 0 Mean reward: 325.22\n",
      "Type Trained Model 2 Mean reward: 345.07\n",
      "Type Trained Model 1 Mean reward: 371.90999999999997\n",
      "Type Global Updated Model Mean reward: 331.61999999999995\n",
      "Train Iter:  3\n",
      "Optim Steps:  1280\n",
      "Type Trained Model 2 Mean reward: 331.43\n",
      "Type Trained Model 3 Mean reward: 374.92999999999995\n",
      "Type Trained Model 1 Mean reward: 377.58000000000004\n",
      "Type Trained Model 0 Mean reward: 379.51\n",
      "Type Global Updated Model Mean reward: 368.24000000000007\n",
      "Train Iter:  4\n",
      "Optim Steps:  1600\n",
      "Type Trained Model 0 Mean reward: 363.96999999999997\n",
      "Type Trained Model 1 Mean reward: 375.05\n",
      "Type Trained Model 2 Mean reward: 403.24\n",
      "Type Trained Model 3 Mean reward: 428.06000000000006\n",
      "Type Global Updated Model Mean reward: 411.7200000000001\n",
      "Train Iter:  5\n",
      "Optim Steps:  1920\n",
      "Type Trained Model 2 Mean reward: 416.81000000000006\n",
      "Type Trained Model 3 Mean reward: 418.05\n",
      "Type Trained Model 1 Mean reward: 421.42999999999995\n",
      "Type Trained Model 0 Mean reward: 444.16999999999996\n",
      "Type Global Updated Model Mean reward: 428.75999999999993\n",
      "Train Iter:  6\n",
      "Optim Steps:  2240\n",
      "Type Trained Model 1 Mean reward: 450.91\n",
      "Type Trained Model 3 Mean reward: 450.65\n",
      "Type Trained Model 0 Mean reward: 450.73\n",
      "Type Trained Model 2 Mean reward: 452.73999999999995\n",
      "Type Global Updated Model Mean reward: 464.64\n",
      "Train Iter:  7\n",
      "Optim Steps:  2560\n",
      "Type Trained Model 0 Mean reward: 417.46000000000004\n",
      "Type Trained Model 3 Mean reward: 465.23999999999995\n",
      "Type Trained Model 1 Mean reward: 484.71000000000004\n",
      "Type Trained Model 2 Mean reward: 489.9\n",
      "Type Global Updated Model Mean reward: 472.13\n",
      "Train Iter:  8\n",
      "Optim Steps:  2880\n",
      "Type Trained Model 0 Mean reward: 493.91\n",
      "Type Trained Model 2 Mean reward: 498.28999999999996\n",
      "Type Trained Model 3 Mean reward: 500.0\n",
      "Type Trained Model 1 Mean reward: 500.0\n",
      "Type Global Updated Model Mean reward: 499.96999999999997\n",
      "Train Iter:  9\n",
      "Optim Steps:  3200\n",
      "Type Trained Model 2 Mean reward: 491.51000000000005\n",
      "Type Trained Model 1 Mean reward: 499.6\n",
      "Type Trained Model 3 Mean reward: 500.0\n",
      "Type Trained Model 0 Mean reward: 500.0\n",
      "Type Global Updated Model Mean reward: 500.0\n"
     ]
    }
   ],
   "source": [
    "# Evaluation Before Iterated Training\n",
    "evaluate([global_model], env, 0, [0], \"Global Initial Model\")\n",
    "\n",
    "for i in range(NUM_ITERATIONS):\n",
    "    print('Train Iter: ', i)\n",
    "\n",
    "    # Create Threads\n",
    "    client_threads = [] \n",
    "    for ci in range(NUM_CLIENT_MODELS):\n",
    "        thread = threading.Thread(target=train, args=(client_models, ci, NUM_TRAINING_STEPS))\n",
    "        client_threads.append(thread)\n",
    "\n",
    "\n",
    "    # Start Threads\n",
    "    for thread in client_threads:\n",
    "        thread.start()\n",
    "\n",
    "    # Join Threads (wait until thread is completely executed)\n",
    "    for thread in client_threads:\n",
    "        thread.join()\n",
    "\n",
    "    # Optimization Steps Check\n",
    "    print('Optim Steps: ', client_models[0].get_parameters()['policy.optimizer']['state'][0]['step'])\n",
    "\n",
    "    # Evaluation after Training\n",
    "    results = multithread_eval(client_models)\n",
    "    total = sum(results)\n",
    "\n",
    "    # Accumulate Client Parameters / Weights\n",
    "    global_dict = global_model.policy.state_dict()\n",
    "    for k in global_dict.keys():\n",
    "        global_dict[k] = torch.stack([client_models[i].policy.state_dict()[k].float()*(NUM_CLIENT_MODELS*results[i]/total) for i in range(len(client_models))], 0).mean(0)\n",
    "\n",
    "    # Load New Parameters to Global Model\n",
    "    global_model.policy.load_state_dict(global_dict)\n",
    "\n",
    "    # Load New Parameters to clients\n",
    "    for model in client_models:\n",
    "        model.policy.load_state_dict(global_model.policy.state_dict())\n",
    "\n",
    "    # Evaluate Updated Global Model\n",
    "    evaluate([global_model], env, 0, [0], 'Global Updated Model', verbose = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'policy': OrderedDict([('mlp_extractor.policy_net.0.weight',\n",
       "               tensor([[-1.7479e-01, -1.4356e-01, -2.9067e-01, -3.3917e-01],\n",
       "                       [-2.1077e-01, -1.2386e-02,  2.1131e-01,  7.6488e-02],\n",
       "                       [ 1.2600e-02, -1.1981e-01,  9.8463e-02, -3.1738e-01],\n",
       "                       [-1.5360e-01, -1.7929e-01, -2.2833e-01, -1.0829e-01],\n",
       "                       [ 2.8456e-02,  1.0108e-01,  1.2718e-01, -6.6476e-02],\n",
       "                       [ 4.4974e-02,  7.0620e-02,  4.7945e-01,  3.0896e-01],\n",
       "                       [ 4.9151e-01,  1.3986e-01,  8.1873e-02,  1.8094e-01],\n",
       "                       [-8.8696e-03, -2.3996e-02, -4.7761e-01, -6.6724e-02],\n",
       "                       [ 1.6739e-01,  9.2729e-02, -5.1045e-02,  3.3629e-02],\n",
       "                       [-5.4289e-02, -1.5929e-01, -2.8036e-01, -3.7247e-01],\n",
       "                       [-1.2554e-01,  1.2663e-01,  2.0524e-01,  2.8253e-01],\n",
       "                       [ 5.5599e-02,  8.9562e-02,  1.1913e-01,  1.1776e-01],\n",
       "                       [-2.1766e-01,  2.2694e-01,  4.5785e-01,  3.5713e-01],\n",
       "                       [-1.5374e-01,  4.1352e-01,  3.9925e-01,  6.6437e-03],\n",
       "                       [-1.2791e-01,  2.1302e-01, -9.7890e-02, -1.4516e-01],\n",
       "                       [-8.2475e-02,  2.9182e-02, -7.8061e-02, -5.4447e-02],\n",
       "                       [ 1.5742e-01, -7.6824e-02,  3.2445e-01,  3.0552e-01],\n",
       "                       [-4.9784e-02,  1.0570e-01,  9.1622e-02,  2.5594e-01],\n",
       "                       [-4.6168e-02,  5.0609e-02,  1.7200e-01,  1.6486e-01],\n",
       "                       [-9.1666e-02,  5.1851e-02, -2.2200e-01, -7.2685e-02],\n",
       "                       [-2.3283e-02,  6.9553e-02,  1.4076e-01,  6.5025e-02],\n",
       "                       [-2.2599e-01, -4.6129e-01, -7.3384e-02, -2.4206e-01],\n",
       "                       [-1.3966e-01,  1.2653e-01,  3.1613e-01, -5.2294e-02],\n",
       "                       [ 4.2437e-01, -2.3001e-04,  6.8441e-02,  2.1059e-02],\n",
       "                       [ 1.1763e-01,  5.6671e-02,  3.5478e-01,  6.8114e-02],\n",
       "                       [-3.7557e-01, -1.5765e-01,  4.9454e-01,  2.2986e-01],\n",
       "                       [-1.2388e-01,  1.3266e-01, -4.6880e-01, -1.9374e-02],\n",
       "                       [ 1.5331e-01,  7.7456e-02,  1.9126e-01, -3.1260e-01],\n",
       "                       [-1.5043e-01,  1.8456e-01, -2.8469e-04, -2.0912e-01],\n",
       "                       [-5.7872e-02,  2.9314e-01,  2.6371e-01,  2.3444e-01],\n",
       "                       [ 3.6840e-01,  1.1651e-01,  3.2293e-01, -9.3121e-02],\n",
       "                       [-1.4678e-01,  2.7454e-01,  8.4057e-02,  6.1602e-02],\n",
       "                       [-2.0649e-01, -1.3150e-01, -5.2436e-01, -2.7877e-01],\n",
       "                       [ 2.3286e-01, -3.2209e-01,  1.4081e-01,  1.3740e-01],\n",
       "                       [ 5.5247e-02,  1.1776e-03, -4.4287e-01, -3.1963e-01],\n",
       "                       [-4.3643e-01,  2.5991e-01,  5.9724e-02,  1.2681e-01],\n",
       "                       [-1.3174e-01,  2.3962e-01, -2.0881e-01, -1.3576e-01],\n",
       "                       [ 1.0025e-01, -3.2519e-02, -2.8385e-01, -2.8212e-01],\n",
       "                       [-1.4749e-01, -1.8696e-01, -1.4656e-01, -6.4769e-02],\n",
       "                       [ 2.9856e-01,  2.3660e-01,  4.6137e-01,  3.3063e-01],\n",
       "                       [ 2.6765e-01,  3.5965e-01, -3.5773e-01, -6.9017e-01],\n",
       "                       [ 9.6687e-02,  4.9095e-02, -5.8992e-01, -2.3147e-01],\n",
       "                       [-9.8531e-02,  1.7386e-01,  2.4397e-01,  4.3452e-01],\n",
       "                       [ 5.3071e-02, -1.9409e-02, -4.4782e-02, -1.5596e-01],\n",
       "                       [-1.8133e-01, -3.5557e-01, -3.8906e-01, -3.2919e-02],\n",
       "                       [ 5.1517e-01,  2.3505e-01,  3.8301e-01, -1.1591e-01],\n",
       "                       [-1.0645e-01,  9.9182e-02,  2.0615e-01, -1.2999e-01],\n",
       "                       [-2.5814e-01,  4.2557e-01, -2.8143e-02,  8.2886e-03],\n",
       "                       [-1.1543e-01, -1.8423e-01, -3.2953e-01,  4.8655e-02],\n",
       "                       [-6.3373e-02,  3.5876e-01, -1.0479e-01, -1.6996e-01],\n",
       "                       [-7.8596e-02,  2.2056e-01,  3.7421e-01,  3.5003e-01],\n",
       "                       [-2.4707e-01, -1.1315e-02,  4.7945e-01, -9.6579e-02],\n",
       "                       [-2.3554e-01,  1.2158e-01,  2.2944e-01,  5.3569e-01],\n",
       "                       [ 2.0743e-01,  2.5866e-01, -3.4887e-02, -5.8750e-02],\n",
       "                       [-1.6645e-01,  2.0345e-01,  4.8434e-01, -1.2141e-01],\n",
       "                       [-2.4776e-01, -1.8506e-02, -1.4622e-01, -3.9983e-01],\n",
       "                       [ 1.9851e-01,  7.2021e-02,  1.3190e-02, -4.6149e-02],\n",
       "                       [-7.5819e-02,  8.6727e-02,  3.9536e-01,  5.1178e-01],\n",
       "                       [-7.3160e-02, -2.5206e-01, -1.7398e-01,  2.9707e-01],\n",
       "                       [ 2.0923e-01,  2.9690e-01, -1.3551e-01,  2.8443e-01],\n",
       "                       [-4.3576e-02, -3.7714e-01,  4.8988e-01,  4.6151e-01],\n",
       "                       [ 2.1817e-01, -1.8770e-01,  2.4459e-01,  4.7179e-01],\n",
       "                       [ 2.9808e-01,  1.4394e-01, -5.2494e-01, -9.9226e-02],\n",
       "                       [-1.0218e-01, -9.6305e-02, -1.1242e-01, -1.1288e-01]])),\n",
       "              ('mlp_extractor.policy_net.0.bias',\n",
       "               tensor([ 1.1284e-02,  9.6020e-03,  6.9599e-04,  6.3545e-03, -5.0464e-04,\n",
       "                       -5.2749e-03, -1.0668e-02, -4.5921e-05,  8.5212e-03,  8.6850e-03,\n",
       "                       -1.8041e-03, -1.1055e-03, -1.8515e-03,  3.0659e-03, -4.2101e-03,\n",
       "                        6.1851e-03, -4.6002e-03, -4.8768e-03, -7.4225e-03,  2.2940e-03,\n",
       "                       -2.7253e-04,  6.2596e-03, -2.3668e-03, -4.3493e-03, -8.0351e-04,\n",
       "                        2.2744e-03,  1.2910e-02, -9.3428e-04,  4.8034e-04, -2.6620e-03,\n",
       "                       -2.3099e-03,  1.4695e-03,  9.4147e-03, -3.9494e-03,  1.1327e-03,\n",
       "                        1.1013e-03, -8.3842e-03,  1.3370e-03,  2.3874e-02, -1.0445e-02,\n",
       "                        2.7112e-04, -6.1545e-03, -2.9614e-03, -1.3181e-02,  3.7657e-03,\n",
       "                       -2.3535e-02,  5.8470e-03,  3.1569e-03,  3.3467e-03,  1.5682e-03,\n",
       "                       -2.5447e-03, -1.0758e-02, -1.7204e-03, -7.1917e-03,  2.0694e-03,\n",
       "                        1.2008e-02, -1.8963e-02, -1.3900e-04,  9.3029e-03, -1.6135e-02,\n",
       "                        3.2756e-03, -2.9836e-03, -1.2239e-03,  4.0941e-03])),\n",
       "              ('mlp_extractor.policy_net.2.weight',\n",
       "               tensor([[-0.0744,  0.3329, -0.3799,  ...,  0.1677,  0.1931,  0.0251],\n",
       "                       [-0.1006,  0.0601, -0.3037,  ...,  0.1024, -0.0780, -0.1317],\n",
       "                       [ 0.0772, -0.1825,  0.1717,  ...,  0.0573, -0.1985, -0.1875],\n",
       "                       ...,\n",
       "                       [ 0.1319, -0.0752, -0.1147,  ...,  0.1945, -0.5896,  0.1660],\n",
       "                       [ 0.2498,  0.0424,  0.2280,  ...,  0.1979, -0.0691,  0.0407],\n",
       "                       [-0.2180, -0.1757,  0.2829,  ...,  0.0306, -0.1787,  0.1477]])),\n",
       "              ('mlp_extractor.policy_net.2.bias',\n",
       "               tensor([ 5.9929e-03, -1.3643e-03, -2.9154e-03,  1.6397e-03,  5.7306e-03,\n",
       "                        2.1703e-03,  3.1292e-03, -6.5092e-04, -1.7324e-02, -5.8837e-04,\n",
       "                        2.4827e-03, -6.6130e-03,  1.3643e-03, -3.7711e-03,  3.4592e-03,\n",
       "                       -1.7433e-03,  1.1101e-03, -5.2922e-03, -7.7466e-03,  2.9102e-03,\n",
       "                        7.8409e-03, -3.2275e-03, -8.3693e-04,  7.8289e-03, -5.1612e-03,\n",
       "                       -2.1169e-03,  4.0223e-03,  6.9851e-05,  1.0061e-02,  1.1591e-03,\n",
       "                        1.6555e-03,  4.6237e-03, -6.4535e-04, -7.4363e-03,  2.7397e-03,\n",
       "                        3.9844e-03,  2.9687e-03, -1.5452e-03,  8.9089e-03,  7.1894e-03,\n",
       "                        2.8405e-03, -3.3059e-04, -4.0795e-03,  1.5634e-02,  2.0001e-03,\n",
       "                       -2.9359e-03, -2.9903e-03, -3.8433e-03,  2.7780e-03, -2.6169e-03,\n",
       "                       -2.7038e-03,  2.7413e-04, -3.3128e-03,  1.0157e-03, -1.7671e-03,\n",
       "                        4.2196e-03, -3.5444e-03,  9.7735e-04,  1.0187e-02, -1.4063e-03,\n",
       "                        7.1390e-04,  8.8654e-05, -2.8182e-03, -1.5909e-03])),\n",
       "              ('mlp_extractor.value_net.0.weight',\n",
       "               tensor([[ 3.3681e-01,  5.2276e-03,  9.9263e-02,  6.3919e-02],\n",
       "                       [-2.1664e-01, -5.4336e-02, -5.5407e-01, -1.2470e-01],\n",
       "                       [-2.2483e-01, -1.9281e-01,  6.1075e-01,  2.5184e-01],\n",
       "                       [-3.2435e-02, -2.1610e-01, -6.9276e-01, -2.8274e-01],\n",
       "                       [ 1.7123e-01,  9.3770e-02,  3.0356e-01,  2.4518e-02],\n",
       "                       [ 2.3340e-01, -1.4198e-01, -3.0082e-01, -2.8147e-01],\n",
       "                       [ 2.9357e-01,  3.0397e-01,  6.4357e-01,  5.4892e-02],\n",
       "                       [ 4.7658e-02,  1.9363e-01, -3.9245e-01, -3.0249e-01],\n",
       "                       [ 2.1472e-01,  5.1677e-02, -8.5954e-01, -2.9658e-02],\n",
       "                       [ 2.9960e-01,  6.5957e-02, -9.9151e-03, -6.2437e-02],\n",
       "                       [-4.0453e-01, -2.4529e-01, -4.3432e-01, -1.6154e-01],\n",
       "                       [-7.7564e-02, -1.5179e-01,  1.2524e-01,  3.3218e-01],\n",
       "                       [ 2.9666e-01, -2.6236e-03, -5.4120e-01, -3.5335e-01],\n",
       "                       [-2.3623e-01, -1.0732e-01, -1.9604e-01, -3.2997e-01],\n",
       "                       [-3.8203e-01, -4.4377e-01, -2.1172e-01, -6.2347e-03],\n",
       "                       [-9.8036e-02, -1.4816e-01, -3.2063e-01, -1.1616e-01],\n",
       "                       [-4.9947e-01,  6.8977e-02, -2.4166e-01,  1.3734e-01],\n",
       "                       [ 1.7688e-01,  2.4911e-01,  2.7014e-01,  1.5296e-01],\n",
       "                       [-3.6922e-01, -3.5268e-01,  3.0055e-03, -1.1457e-01],\n",
       "                       [ 4.0869e-02, -6.4000e-02,  2.7940e-01,  6.4683e-02],\n",
       "                       [ 2.8188e-02,  1.1127e-01,  3.3950e-01,  3.3069e-01],\n",
       "                       [ 2.8772e-01,  6.0144e-02,  4.1281e-01,  5.0935e-01],\n",
       "                       [ 1.6946e-01,  3.5918e-01,  1.5100e-01, -5.3733e-02],\n",
       "                       [-8.8239e-02,  2.0623e-01, -5.7904e-01, -3.9886e-01],\n",
       "                       [ 2.5543e-01, -4.3976e-01,  4.9203e-01,  3.0136e-01],\n",
       "                       [ 3.6321e-01,  6.8169e-02, -5.6978e-01, -5.1548e-02],\n",
       "                       [ 6.9372e-04, -2.2924e-01, -7.4708e-01, -4.1604e-02],\n",
       "                       [ 1.8899e-01, -8.7404e-02, -2.6269e-01, -4.8038e-01],\n",
       "                       [-9.4326e-02, -1.9556e-02, -5.5830e-01, -3.2990e-01],\n",
       "                       [-1.4786e-01, -5.0073e-01, -7.6932e-01, -1.8646e-01],\n",
       "                       [ 2.5081e-01,  4.9938e-02, -4.0463e-01, -1.6666e-01],\n",
       "                       [-1.7145e-01, -1.2390e-01,  1.8943e-01,  3.5506e-02],\n",
       "                       [-3.1790e-01, -3.9710e-01, -3.3819e-01, -1.5447e-01],\n",
       "                       [ 1.5433e-01,  2.6742e-01,  3.6786e-02, -4.5585e-02],\n",
       "                       [-3.2361e-01,  9.4513e-02,  3.0694e-01,  3.5068e-01],\n",
       "                       [ 2.4127e-02,  4.8478e-03, -3.4588e-01, -3.7764e-01],\n",
       "                       [ 2.1990e-01,  5.1037e-02,  6.6502e-01,  1.5491e-01],\n",
       "                       [ 7.5303e-02,  1.7051e-01, -5.9746e-01, -3.2275e-01],\n",
       "                       [-3.9362e-01, -1.2916e-01, -3.4201e-01, -1.5889e-01],\n",
       "                       [ 1.0055e-01, -2.8688e-01, -7.3137e-01, -3.3229e-01],\n",
       "                       [ 2.2823e-01,  9.4012e-02, -7.1489e-02,  1.3699e-01],\n",
       "                       [-2.8246e-01, -2.8589e-01, -3.0518e-01, -3.0779e-02],\n",
       "                       [-3.5561e-01, -1.1317e-01, -2.5607e-01, -2.7740e-02],\n",
       "                       [ 1.5705e-01,  1.9338e-01, -6.6642e-02, -9.7570e-02],\n",
       "                       [-2.8427e-01,  5.1945e-02, -5.1916e-01, -2.6003e-01],\n",
       "                       [-4.1877e-01, -2.7293e-01, -4.7642e-01, -1.5068e-01],\n",
       "                       [ 3.2137e-01,  2.8469e-01,  7.8487e-01,  1.2947e-01],\n",
       "                       [-2.2685e-01,  5.9045e-02, -5.1083e-01, -1.2342e-01],\n",
       "                       [ 3.2471e-01, -6.3147e-02, -3.2942e-01, -1.5706e-01],\n",
       "                       [-7.7928e-02, -3.9043e-02,  6.0429e-01,  4.0281e-01],\n",
       "                       [ 2.8331e-01, -8.1981e-02,  4.2024e-01, -2.9967e-04],\n",
       "                       [-4.4528e-02, -3.1226e-02, -5.7056e-01, -1.2815e-01],\n",
       "                       [-5.9304e-02,  1.7422e-01,  4.6466e-01, -1.9871e-02],\n",
       "                       [-5.7240e-01,  1.7116e-02, -4.2319e-01, -1.5863e-01],\n",
       "                       [ 5.8093e-02,  2.6738e-01,  1.8778e-01,  2.1972e-01],\n",
       "                       [ 1.6655e-01,  1.8878e-01,  4.1145e-01, -1.0956e-01],\n",
       "                       [ 1.8990e-01, -5.5489e-02,  5.0392e-01, -6.8414e-03],\n",
       "                       [ 3.9873e-02,  2.5142e-01,  1.8665e-01,  2.4116e-01],\n",
       "                       [ 5.7713e-02, -2.2061e-01,  5.6395e-01,  2.7439e-01],\n",
       "                       [ 6.5532e-01, -4.8450e-03,  5.5631e-02, -2.6914e-01],\n",
       "                       [-3.0976e-01,  1.6912e-01, -4.4035e-01, -1.4221e-01],\n",
       "                       [-1.7203e-01, -7.1168e-02, -6.7326e-01, -1.4944e-01],\n",
       "                       [-2.2015e-01, -4.1794e-01, -2.5011e-01, -3.2010e-01],\n",
       "                       [-1.5533e-01, -1.9608e-01, -5.1911e-01, -1.4628e-01]])),\n",
       "              ('mlp_extractor.value_net.0.bias',\n",
       "               tensor([ 0.2356,  0.2114, -0.2215,  0.2070, -0.2394,  0.2492,  0.2828,  0.2617,\n",
       "                       -0.2432,  0.2579,  0.2196, -0.2380,  0.2329,  0.2345,  0.2747,  0.1958,\n",
       "                        0.2776, -0.2352,  0.2368, -0.2551, -0.2380,  0.2143, -0.2388,  0.2122,\n",
       "                        0.2467,  0.2605, -0.2443, -0.2780, -0.1851,  0.0317, -0.2688,  0.2404,\n",
       "                       -0.2852, -0.2626,  0.2345, -0.2159,  0.2522,  0.2281,  0.2146, -0.2433,\n",
       "                        0.2475, -0.2875,  0.2409,  0.2585, -0.2287, -0.2681, -0.2186, -0.2117,\n",
       "                        0.2369,  0.2514,  0.1064,  0.2181, -0.2108,  0.2128,  0.2026, -0.2261,\n",
       "                       -0.2404,  0.1955, -0.2112, -0.2495,  0.2663, -0.2458,  0.0192, -0.2568])),\n",
       "              ('mlp_extractor.value_net.2.weight',\n",
       "               tensor([[-0.7236,  0.1535, -0.0598,  ...,  0.8071, -0.3023,  0.5441],\n",
       "                       [-0.2620,  0.4674, -0.5298,  ..., -0.1504,  0.0316, -0.1899],\n",
       "                       [ 0.0804, -0.0101,  0.5405,  ..., -0.0868, -0.1620, -0.5155],\n",
       "                       ...,\n",
       "                       [ 0.1203,  0.7975, -0.1565,  ..., -0.1615,  0.5129, -0.3442],\n",
       "                       [ 0.3849,  0.1057, -0.1483,  ..., -0.8850, -0.3016, -0.7711],\n",
       "                       [-0.5926, -0.1432, -0.1077,  ...,  0.7138,  0.1293,  0.6336]])),\n",
       "              ('mlp_extractor.value_net.2.bias',\n",
       "               tensor([-0.1414,  0.1781,  0.0850,  0.1330,  0.1542, -0.1126, -0.2655,  0.0939,\n",
       "                        0.1095, -0.1263,  0.1144, -0.1237,  0.1470,  0.1223,  0.1698, -0.1178,\n",
       "                       -0.0918, -0.1413, -0.1591,  0.0916, -0.1988,  0.0904,  0.1289, -0.2039,\n",
       "                        0.1755,  0.1766, -0.1160,  0.1244,  0.2285,  0.1255, -0.1221, -0.1471,\n",
       "                       -0.1324,  0.2141,  0.1161, -0.1624, -0.1273, -0.1028,  0.0971,  0.0956,\n",
       "                       -0.1442,  0.1145, -0.1395, -0.1520, -0.1602, -0.1546,  0.1388,  0.1063,\n",
       "                        0.0817, -0.1566,  0.1563, -0.0931,  0.0955, -0.1103, -0.2046,  0.1445,\n",
       "                       -0.1388,  0.1063, -0.1213, -0.1405, -0.1409,  0.1309,  0.1614, -0.0730])),\n",
       "              ('action_net.weight',\n",
       "               tensor([[-0.0386,  0.1311, -0.1038, -0.0839,  0.0759,  0.1191, -0.0752, -0.0100,\n",
       "                        -0.1196,  0.0068, -0.0224,  0.0742, -0.0717, -0.0927, -0.0544, -0.0291,\n",
       "                         0.0656,  0.0583, -0.0755, -0.0539, -0.0473, -0.0641, -0.0133, -0.0400,\n",
       "                         0.0213,  0.0947, -0.0518, -0.0964, -0.0692, -0.0225, -0.1432,  0.0727,\n",
       "                        -0.0440, -0.0420, -0.0523,  0.0707, -0.0284,  0.0192,  0.0587, -0.0602,\n",
       "                        -0.1140, -0.0008,  0.0074,  0.1441,  0.0222,  0.0495, -0.0849,  0.0730,\n",
       "                         0.0480,  0.0088,  0.0522,  0.0666,  0.0360,  0.0938,  0.0140, -0.0716,\n",
       "                        -0.0680, -0.0156, -0.0515, -0.0124, -0.1224,  0.0894,  0.0102,  0.0557],\n",
       "                       [ 0.0381, -0.1313,  0.1041,  0.0851, -0.0735, -0.1210,  0.0763,  0.0093,\n",
       "                         0.1188, -0.0077,  0.0263, -0.0744,  0.0722,  0.0947,  0.0534,  0.0278,\n",
       "                        -0.0649, -0.0576,  0.0760,  0.0526,  0.0465,  0.0594,  0.0144,  0.0400,\n",
       "                        -0.0236, -0.0935,  0.0505,  0.0951,  0.0707,  0.0261,  0.1407, -0.0715,\n",
       "                         0.0451,  0.0423,  0.0520, -0.0707,  0.0293, -0.0193, -0.0584,  0.0620,\n",
       "                         0.1124, -0.0002, -0.0090, -0.1436, -0.0168, -0.0503,  0.0850, -0.0719,\n",
       "                        -0.0509, -0.0087, -0.0518, -0.0669, -0.0366, -0.0970, -0.0109,  0.0739,\n",
       "                         0.0687,  0.0163,  0.0516,  0.0127,  0.1252, -0.0894, -0.0135, -0.0529]])),\n",
       "              ('action_net.bias', tensor([-0.0016,  0.0016])),\n",
       "              ('value_net.weight',\n",
       "               tensor([[-0.9888,  0.9334,  1.1264,  0.9328,  0.9813, -1.0709, -0.8570,  1.1072,\n",
       "                         0.9957, -1.1065,  1.0623, -0.9281,  0.9757,  1.0631,  1.0051, -0.9712,\n",
       "                        -0.9946, -1.0435, -1.0468,  1.0376, -0.9227,  1.1192,  1.0325, -0.9416,\n",
       "                         1.0084,  0.9446, -1.1374,  0.9578,  0.9552,  0.9493, -1.0347, -0.9998,\n",
       "                        -0.9799,  0.9233,  0.9799, -0.9585, -1.1173, -1.1453,  1.0501,  1.0973,\n",
       "                        -0.9440,  0.9530, -0.9843, -0.9867, -0.9778, -1.0256,  0.9668,  1.0949,\n",
       "                         1.2638, -0.9402,  0.9540, -1.1082,  1.0509, -1.0993, -0.9458,  0.9737,\n",
       "                        -0.9707,  1.2336, -1.0498, -1.0955, -0.9577,  1.0350,  1.0592, -0.9564]])),\n",
       "              ('value_net.bias', tensor([0.5714]))]),\n",
       " 'policy.optimizer': {'state': {},\n",
       "  'param_groups': [{'lr': 0.0003,\n",
       "    'betas': (0.9, 0.999),\n",
       "    'eps': 1e-05,\n",
       "    'weight_decay': 0,\n",
       "    'amsgrad': False,\n",
       "    'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_model.get_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model.save('a2c_lunar_multiproc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting Params as JSON\n",
    "## Function to Convert Params Dict to Flattened List\n",
    "def flatten_list(params):\n",
    "    \"\"\"\n",
    "    :param params: (dict)\n",
    "    :return: (np.ndarray)\n",
    "    \"\"\"\n",
    "    params_ = {}\n",
    "    for key in params.keys():\n",
    "        params_[key] = params[key].tolist()\n",
    "    return params_\n",
    "## Write Parameters to JSON File\n",
    "import json\n",
    "\n",
    "all_params = global_model.get_parameters()\n",
    "pol_params = flatten_list(all_params['policy'])\n",
    "\n",
    "all_params['policy'] = pol_params\n",
    "\n",
    "with open('a2c_lunar_multiproc.json', 'w') as f:\n",
    "    json.dump(all_params, f, indent='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_loaded = ALGO(\n",
    "#     \"MlpPolicy\",\n",
    "#     env\n",
    "# )\n",
    "\n",
    "# evaluate(model_loaded,env, verbose=1)\n",
    "\n",
    "# import json\n",
    "# with open('a2c_lunar_multiproc.json', 'w') as f:\n",
    "#     new_params = json.load(f)\n",
    "\n",
    "# loaded_pol_params = new_params['policy']\n",
    "# for key in loaded_pol_params.keys():\n",
    "#     loaded_pol_params[key] = th.tensor(loaded_pol_params[key])\n",
    "\n",
    "# new_params['policy'] = loaded_pol_params\n",
    "\n",
    "# model_loaded.set_parameters(new_params)\n",
    "\n",
    "model_loaded = ALGO.load('a2c_lunar_multiproc', env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "evaluate() missing 2 required positional arguments: 'index' and 'eval_results'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_42226/3268761085.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_loaded\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: evaluate() missing 2 required positional arguments: 'index' and 'eval_results'"
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "evaluate(model_loaded,env, verbose=1)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3fe87c7677a9be80aab770929aa8f3d40850ac08a0f73ec246342c77c48f1c11"
  },
  "kernelspec": {
   "display_name": "Python 3.7.2 64-bit ('pydrl': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
