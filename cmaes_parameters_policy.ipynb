{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modifying and Loading Parameters of Policies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "import gym\n",
    "import numpy as np\n",
    "import cma\n",
    "from collections import OrderedDict\n",
    "import torch as th\n",
    "\n",
    "from stable_baselines3 import A2C\n",
    "from stable_baselines3.common.evaluation import evaluate_policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to Convert Params Dict to Flattened N-D array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(params):\n",
    "    \"\"\"\n",
    "    :param params: (dict)\n",
    "    :return: (np.ndarray)\n",
    "    \"\"\"\n",
    "    params_ = []\n",
    "    for key in params.keys():\n",
    "        params_.append(params[key].flatten())\n",
    "    return np.concatenate(params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to Flattened Params to Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_dict(flat_vec, params):\n",
    "    \"\"\"\n",
    "    :param flat_vec: (np.ndarray)\n",
    "    :param params: (OrderedDict)\n",
    "    :return: (OrderedDict)\n",
    "    \"\"\"\n",
    "    params_ = OrderedDict()\n",
    "    start_idx = 0\n",
    "    for key in params.keys():\n",
    "        n_elem = list(params[key].size())\n",
    "        # print(n_elem, params[key].nelement())\n",
    "        params_[key] = th.from_numpy(flat_vec[start_idx:start_idx + params[key].nelement()].reshape(params[key].shape))\n",
    "        start_idx += params[key].nelement()\n",
    "    return params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model and Find Initial Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 109      |\n",
      "|    ep_rew_mean        | -235     |\n",
      "| time/                 |          |\n",
      "|    fps                | 635      |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 0        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.552   |\n",
      "|    explained_variance | 0.0209   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | -1.61    |\n",
      "|    value_loss         | 6.86     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 143      |\n",
      "|    ep_rew_mean        | -343     |\n",
      "| time/                 |          |\n",
      "|    fps                | 657      |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 1        |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.24    |\n",
      "|    explained_variance | -0.0048  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | -5.53    |\n",
      "|    value_loss         | 26.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 143      |\n",
      "|    ep_rew_mean        | -338     |\n",
      "| time/                 |          |\n",
      "|    fps                | 681      |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 2        |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.19    |\n",
      "|    explained_variance | 0.026    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | -7.44    |\n",
      "|    value_loss         | 113      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 160      |\n",
      "|    ep_rew_mean        | -358     |\n",
      "| time/                 |          |\n",
      "|    fps                | 634      |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 3        |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.502   |\n",
      "|    explained_variance | 0.000507 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | -1.41    |\n",
      "|    value_loss         | 121      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 155      |\n",
      "|    ep_rew_mean        | -383     |\n",
      "| time/                 |          |\n",
      "|    fps                | 632      |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 3        |\n",
      "|    total_timesteps    | 2500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.1     |\n",
      "|    explained_variance | 0.00103  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | -1.66    |\n",
      "|    value_loss         | 7.04     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 155       |\n",
      "|    ep_rew_mean        | -401      |\n",
      "| time/                 |           |\n",
      "|    fps                | 648       |\n",
      "|    iterations         | 600       |\n",
      "|    time_elapsed       | 4         |\n",
      "|    total_timesteps    | 3000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.18     |\n",
      "|    explained_variance | -0.000146 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 599       |\n",
      "|    policy_loss        | -7.51     |\n",
      "|    value_loss         | 31.2      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 158      |\n",
      "|    ep_rew_mean        | -397     |\n",
      "| time/                 |          |\n",
      "|    fps                | 655      |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 5        |\n",
      "|    total_timesteps    | 3500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.86    |\n",
      "|    explained_variance | 0.11     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | -3.61    |\n",
      "|    value_loss         | 43.2     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 160      |\n",
      "|    ep_rew_mean        | -388     |\n",
      "| time/                 |          |\n",
      "|    fps                | 664      |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 6        |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.795   |\n",
      "|    explained_variance | 0.0218   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | 0.81     |\n",
      "|    value_loss         | 14.8     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 163      |\n",
      "|    ep_rew_mean        | -377     |\n",
      "| time/                 |          |\n",
      "|    fps                | 670      |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 6        |\n",
      "|    total_timesteps    | 4500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.05    |\n",
      "|    explained_variance | 7.33e-06 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | -4.42    |\n",
      "|    value_loss         | 34.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 166      |\n",
      "|    ep_rew_mean        | -359     |\n",
      "| time/                 |          |\n",
      "|    fps                | 673      |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 7        |\n",
      "|    total_timesteps    | 5000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.581   |\n",
      "|    explained_variance | 0.0348   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | 20.2     |\n",
      "|    value_loss         | 3.06e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 173      |\n",
      "|    ep_rew_mean        | -348     |\n",
      "| time/                 |          |\n",
      "|    fps                | 671      |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 8        |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.774   |\n",
      "|    explained_variance | -0.0353  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | -4.28    |\n",
      "|    value_loss         | 55.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 176      |\n",
      "|    ep_rew_mean        | -339     |\n",
      "| time/                 |          |\n",
      "|    fps                | 673      |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 8        |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.723   |\n",
      "|    explained_variance | -0.211   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | 9.51     |\n",
      "|    value_loss         | 244      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 175      |\n",
      "|    ep_rew_mean        | -312     |\n",
      "| time/                 |          |\n",
      "|    fps                | 677      |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 9        |\n",
      "|    total_timesteps    | 6500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.02    |\n",
      "|    explained_variance | 0.00126  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | -1.59    |\n",
      "|    value_loss         | 5.6      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 177      |\n",
      "|    ep_rew_mean        | -299     |\n",
      "| time/                 |          |\n",
      "|    fps                | 677      |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 10       |\n",
      "|    total_timesteps    | 7000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.817   |\n",
      "|    explained_variance | 0.000759 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | 0.44     |\n",
      "|    value_loss         | 1.8      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 178      |\n",
      "|    ep_rew_mean        | -290     |\n",
      "| time/                 |          |\n",
      "|    fps                | 676      |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 11       |\n",
      "|    total_timesteps    | 7500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.67    |\n",
      "|    explained_variance | -0.0101  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | -5.96    |\n",
      "|    value_loss         | 117      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 184      |\n",
      "|    ep_rew_mean        | -287     |\n",
      "| time/                 |          |\n",
      "|    fps                | 675      |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 11       |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.696   |\n",
      "|    explained_variance | -0.0378  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | 2.34     |\n",
      "|    value_loss         | 22.6     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 185       |\n",
      "|    ep_rew_mean        | -274      |\n",
      "| time/                 |           |\n",
      "|    fps                | 677       |\n",
      "|    iterations         | 1700      |\n",
      "|    time_elapsed       | 12        |\n",
      "|    total_timesteps    | 8500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.448    |\n",
      "|    explained_variance | -1.92e-05 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1699      |\n",
      "|    policy_loss        | -0.237    |\n",
      "|    value_loss         | 54.1      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 189      |\n",
      "|    ep_rew_mean        | -273     |\n",
      "| time/                 |          |\n",
      "|    fps                | 675      |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 13       |\n",
      "|    total_timesteps    | 9000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.64    |\n",
      "|    explained_variance | 0.294    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | -0.155   |\n",
      "|    value_loss         | 1.28     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 188      |\n",
      "|    ep_rew_mean        | -267     |\n",
      "| time/                 |          |\n",
      "|    fps                | 672      |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 14       |\n",
      "|    total_timesteps    | 9500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.04    |\n",
      "|    explained_variance | 0.0128   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | 0.69     |\n",
      "|    value_loss         | 1.06     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 199      |\n",
      "|    ep_rew_mean        | -257     |\n",
      "| time/                 |          |\n",
      "|    fps                | 669      |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 14       |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.665   |\n",
      "|    explained_variance | -0.0378  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | -4.89    |\n",
      "|    value_loss         | 52.9     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.a2c.a2c.A2C at 0x7f1b0e7b5da0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = gym.make('LunarLander-v2')\n",
    "model = A2C(\n",
    "    \"MlpPolicy\",\n",
    "    env,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Use traditional actor-critic policy gradient updates to\n",
    "# find good initial parameters\n",
    "model.learn(total_timesteps=10_000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve Policy Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mlp_extractor.policy_net.0.weight': tensor([[ 3.4069e-01,  1.8471e-01,  1.4974e-01,  3.1768e-01, -2.1731e-01,\n",
       "          -1.6110e-02, -1.6159e-01,  2.2111e-02],\n",
       "         [ 1.0475e-01, -5.8903e-02,  2.9604e-02,  3.9440e-01, -2.3462e-01,\n",
       "           1.9133e-01, -4.5873e-02,  2.6314e-01],\n",
       "         [-1.5947e-01, -1.1737e-01, -1.9051e-01, -1.9990e-03,  1.5501e-01,\n",
       "          -8.9028e-02,  1.7459e-01, -1.6864e-01],\n",
       "         [-2.0997e-01, -1.2236e-01, -6.4666e-01,  1.3344e-01,  3.6844e-01,\n",
       "           9.3169e-02,  1.4598e-01,  1.6314e-01],\n",
       "         [ 1.4613e-01,  1.4389e-01,  1.6092e-01, -1.0492e-01,  4.1506e-01,\n",
       "           4.6695e-02, -2.0175e-01, -3.2073e-02],\n",
       "         [ 6.7694e-03, -6.4617e-02,  4.3404e-01,  2.7436e-01, -1.9169e-01,\n",
       "          -7.2924e-02,  1.6485e-01,  6.3676e-02],\n",
       "         [ 3.3669e-01, -1.8311e-01,  2.9578e-01,  2.4164e-01, -4.5920e-02,\n",
       "           6.8801e-03,  1.2487e-01, -2.8257e-01],\n",
       "         [-2.8457e-02, -1.7506e-01, -7.5848e-02, -6.4995e-01, -3.5214e-03,\n",
       "          -2.8933e-02,  8.6943e-02, -3.7338e-01],\n",
       "         [-3.1732e-01,  7.3541e-02, -2.2618e-01, -3.7084e-01, -2.0522e-01,\n",
       "          -2.7322e-01,  2.8547e-02, -2.1477e-01],\n",
       "         [-1.2951e-01, -4.4462e-02, -2.6877e-01, -4.2399e-01,  2.1552e-01,\n",
       "          -1.4360e-02, -3.0026e-01, -3.1675e-01],\n",
       "         [ 2.4884e-01,  1.9884e-01, -2.4608e-01, -5.0679e-01, -2.2318e-01,\n",
       "          -6.5256e-02, -1.0241e-01,  7.4882e-02],\n",
       "         [ 1.4762e-01,  1.9129e-01, -2.5189e-01,  3.2444e-01,  3.2447e-01,\n",
       "          -2.3773e-01,  2.9813e-01, -7.4285e-02],\n",
       "         [-3.6730e-01,  3.9546e-01, -1.6909e-01, -3.5031e-01,  1.1855e-01,\n",
       "          -4.3730e-02, -1.4267e-01, -4.8436e-02],\n",
       "         [-1.5599e-02, -3.5562e-01,  7.9702e-03, -1.3047e-01, -1.2349e-01,\n",
       "           1.4240e-02, -5.9935e-02, -1.9033e-01],\n",
       "         [-4.3570e-02, -7.2275e-02, -1.7550e-01, -4.9101e-01,  4.0469e-01,\n",
       "           2.3298e-02, -5.3836e-02, -1.2151e-01],\n",
       "         [ 1.0386e-01, -1.4327e-01,  8.9119e-02, -1.1518e-01, -1.4164e-01,\n",
       "           1.1400e-01, -1.3995e-01,  1.3849e-01],\n",
       "         [-6.5610e-02,  1.2967e-01,  4.5538e-01,  8.1829e-02, -3.5825e-01,\n",
       "           7.7185e-02,  2.4097e-01, -3.2064e-01],\n",
       "         [-1.0095e-01, -6.2282e-02, -4.1531e-01,  6.1157e-02,  1.9681e-01,\n",
       "           1.3388e-01, -2.4809e-01,  9.0270e-02],\n",
       "         [-1.7573e-01, -3.7397e-02,  3.3700e-01, -1.2706e-01, -1.7851e-01,\n",
       "           8.0036e-02, -1.6488e-01,  9.8990e-02],\n",
       "         [ 1.7530e-02, -2.2446e-02,  1.5159e-01,  4.0383e-01, -1.0279e-01,\n",
       "          -5.5662e-02, -9.1999e-02,  5.9039e-02],\n",
       "         [ 2.8287e-01, -1.3625e-01, -1.4771e-01,  2.2797e-01, -2.8035e-02,\n",
       "           7.3699e-02,  2.1412e-01,  3.5639e-01],\n",
       "         [ 2.7910e-01,  7.5166e-02,  5.6466e-02,  2.5152e-01,  3.9839e-01,\n",
       "          -2.1736e-01,  8.0706e-02,  2.7953e-01],\n",
       "         [ 2.2160e-02,  4.3798e-02,  1.0220e-01, -3.7446e-01, -1.9845e-01,\n",
       "          -5.7446e-02, -2.3632e-01, -1.0880e-01],\n",
       "         [ 1.4408e-01,  9.1778e-02, -2.0582e-02,  1.6856e-01,  2.2800e-01,\n",
       "           2.8163e-02,  1.0666e-01, -6.0204e-02],\n",
       "         [-2.7528e-01, -2.0887e-01, -3.1289e-01,  2.2290e-01,  5.9828e-01,\n",
       "          -1.8753e-01, -2.8732e-01,  1.2287e-01],\n",
       "         [-1.6099e-02, -4.0995e-01,  5.2804e-01,  9.4099e-02, -4.5525e-01,\n",
       "           3.7147e-02,  1.4956e-01,  1.5302e-01],\n",
       "         [-8.9148e-02,  8.7285e-02, -1.4875e-01, -5.3966e-01,  7.5316e-03,\n",
       "           1.8858e-01,  1.2196e-01,  9.3850e-02],\n",
       "         [-2.7316e-01, -4.1696e-02,  7.7606e-02,  4.0661e-01,  1.1795e-05,\n",
       "           2.4859e-01, -2.5370e-01, -2.7799e-01],\n",
       "         [-6.8063e-03,  2.3463e-01, -4.9464e-01, -3.8842e-01, -1.4897e-01,\n",
       "          -1.0564e-01,  1.3138e-01,  2.6272e-01],\n",
       "         [ 5.1524e-02,  3.7483e-02, -4.5651e-01,  1.8231e-01,  4.5212e-01,\n",
       "           2.3679e-02,  9.8606e-03,  1.7594e-01],\n",
       "         [-4.9960e-02,  1.9719e-01,  2.6923e-01, -3.6447e-01, -1.5915e-01,\n",
       "          -1.7355e-01,  3.0116e-01,  1.2246e-01],\n",
       "         [-1.8552e-01,  1.5890e-01, -4.6685e-01, -1.6544e-02,  2.8739e-01,\n",
       "          -9.4796e-02,  3.0852e-01,  2.5162e-02],\n",
       "         [ 3.2694e-01,  1.2708e-01, -2.0227e-01, -8.1775e-02,  3.0617e-01,\n",
       "           3.0523e-01, -1.7111e-01,  8.8562e-02],\n",
       "         [ 3.9233e-03, -2.0489e-01, -1.8026e-01, -2.9102e-02, -1.8457e-02,\n",
       "           5.8154e-01, -1.2677e-02,  4.3040e-01],\n",
       "         [ 4.7009e-02, -4.5623e-02, -5.8481e-02,  3.4896e-01, -4.2742e-02,\n",
       "           2.7328e-01,  2.8428e-01, -4.9100e-02],\n",
       "         [ 2.1710e-01,  1.8993e-01, -2.7320e-01,  1.4456e-01, -1.0248e-01,\n",
       "          -2.6102e-02, -1.1711e-01,  4.2758e-02],\n",
       "         [-1.5566e-01,  5.5334e-02,  2.7622e-01, -2.8748e-01, -5.0487e-02,\n",
       "          -6.9793e-02, -4.5882e-02,  1.6011e-01],\n",
       "         [ 3.6430e-01,  1.8818e-01,  3.0701e-01, -1.7909e-01,  2.9575e-02,\n",
       "          -4.7710e-02,  1.1003e-01, -2.0221e-01],\n",
       "         [ 1.3322e-01, -2.5035e-01, -1.3148e-01, -7.1847e-02,  9.3626e-02,\n",
       "          -2.9074e-01, -1.4635e-01, -1.5675e-01],\n",
       "         [ 4.4815e-02, -1.6425e-01, -1.1251e-01,  6.0194e-02, -1.8399e-01,\n",
       "          -2.6449e-01,  4.3531e-02, -2.0541e-01],\n",
       "         [ 2.4364e-01, -9.0392e-02,  2.8106e-01, -1.1592e-01, -1.8494e-01,\n",
       "           1.1064e-01,  1.9032e-01,  1.5314e-01],\n",
       "         [-1.9799e-01, -2.6594e-01, -7.1016e-02,  5.7533e-01,  2.9694e-01,\n",
       "          -1.9607e-02,  1.4286e-02,  1.5590e-01],\n",
       "         [ 2.4921e-01, -3.7219e-01, -3.1642e-02, -5.8321e-02,  2.1982e-03,\n",
       "           6.4221e-02,  1.9073e-01,  2.0738e-01],\n",
       "         [ 2.1000e-02, -6.8488e-02,  1.4257e-01,  4.4341e-01, -3.2848e-03,\n",
       "           3.1754e-03,  1.4040e-01,  7.0783e-02],\n",
       "         [ 1.6912e-01,  8.0502e-02,  4.0141e-01,  6.3089e-02, -2.0136e-01,\n",
       "          -4.5178e-01, -1.2862e-01,  3.9483e-01],\n",
       "         [-1.3251e-01, -9.8093e-02,  1.1327e-01,  2.0539e-01, -1.4659e-01,\n",
       "           1.6837e-01,  2.8027e-02,  1.9682e-02],\n",
       "         [-1.7691e-01, -1.0989e-01,  1.6797e-01, -4.3185e-01, -1.6574e-01,\n",
       "           7.7470e-02, -2.4974e-01, -1.5892e-01],\n",
       "         [ 4.0045e-02,  3.8704e-04,  1.1666e-02, -1.5926e-01,  2.1695e-01,\n",
       "          -2.6949e-01, -1.4072e-01,  1.1594e-01],\n",
       "         [-3.0740e-01, -4.8112e-02,  1.8113e-01, -4.5040e-01,  1.1914e-01,\n",
       "          -2.8764e-01, -7.3178e-02,  2.6063e-01],\n",
       "         [ 1.3637e-01, -2.2378e-02, -1.7781e-01,  4.5951e-01, -2.0953e-02,\n",
       "          -3.1587e-02,  6.4626e-02, -1.9734e-01],\n",
       "         [-1.1362e-02, -9.6469e-03,  2.9402e-01, -8.6834e-02, -2.6589e-01,\n",
       "           1.2573e-01, -4.5022e-02,  1.0792e-01],\n",
       "         [ 7.4788e-02, -5.0800e-01, -1.4769e-01,  7.6009e-02,  8.0451e-02,\n",
       "          -4.1680e-01,  9.6748e-02,  8.8744e-02],\n",
       "         [ 9.2715e-02,  1.3768e-01,  2.7555e-01,  7.4616e-02, -3.6125e-01,\n",
       "           4.2368e-03, -5.6955e-01, -2.9013e-02],\n",
       "         [ 1.7726e-01,  1.6710e-01,  4.1301e-01, -3.7218e-01, -2.9971e-01,\n",
       "          -1.3474e-01, -6.9744e-02, -2.1484e-02],\n",
       "         [ 5.0457e-02,  3.8828e-02, -5.2559e-03,  2.1625e-01,  5.6830e-01,\n",
       "           2.2153e-01,  2.0982e-01, -5.5008e-02],\n",
       "         [ 2.4038e-01,  3.4987e-03, -2.7079e-01,  2.9123e-01,  2.1999e-01,\n",
       "          -1.0996e-02,  9.2562e-02, -2.7181e-01],\n",
       "         [-1.9178e-01, -1.3457e-01, -1.3310e-01,  2.5962e-01,  3.7938e-01,\n",
       "          -5.1292e-02,  2.3004e-01,  2.6901e-01],\n",
       "         [-1.3953e-01, -4.4435e-02, -4.2665e-02,  3.7156e-01, -7.0807e-02,\n",
       "           2.7588e-02,  1.9889e-01, -1.4236e-01],\n",
       "         [ 3.7806e-01,  5.4303e-03, -1.8755e-01,  2.2226e-01, -2.7696e-02,\n",
       "          -1.7685e-02, -1.1957e-01,  1.5237e-02],\n",
       "         [ 1.7107e-01,  1.4089e-01,  3.1712e-01,  1.1451e-01, -2.1017e-01,\n",
       "          -2.9674e-02, -1.6541e-01,  3.8180e-02],\n",
       "         [ 4.7229e-02,  2.5629e-01,  4.4523e-02,  3.6764e-01, -1.2786e-01,\n",
       "           5.3370e-02,  1.7912e-01, -8.3012e-02],\n",
       "         [ 2.6179e-01, -3.9411e-02,  3.4200e-01,  1.0567e-01,  3.7406e-01,\n",
       "           1.6852e-01,  1.2059e-01, -5.8635e-02],\n",
       "         [-2.8390e-02,  2.3559e-01,  2.3101e-01,  2.7294e-01,  7.5761e-03,\n",
       "          -1.3405e-02, -1.3851e-01,  7.6571e-02],\n",
       "         [-1.7152e-01,  1.9082e-01,  5.5299e-01,  1.7454e-01, -1.8875e-01,\n",
       "           9.0300e-02,  2.4617e-01,  7.0102e-02]]),\n",
       " 'mlp_extractor.policy_net.0.bias': tensor([ 0.0440, -0.0251, -0.0408, -0.0333,  0.0420,  0.0089,  0.0121, -0.0436,\n",
       "         -0.0251,  0.0063,  0.0019, -0.0259, -0.0088,  0.0034,  0.0343, -0.0579,\n",
       "          0.0108, -0.0321,  0.0297,  0.0100, -0.0079,  0.0177,  0.0204, -0.0162,\n",
       "         -0.0270,  0.0020,  0.0101, -0.0213,  0.0014, -0.0387,  0.0108, -0.0475,\n",
       "          0.0350,  0.0497, -0.0106, -0.0092,  0.0162, -0.0384,  0.0069, -0.0432,\n",
       "          0.0388, -0.0099,  0.0195, -0.0137,  0.0205, -0.0073,  0.0041,  0.0252,\n",
       "          0.0266, -0.0160,  0.0463,  0.0503,  0.0393,  0.0190,  0.0355, -0.0033,\n",
       "         -0.0266,  0.0021, -0.0109,  0.0245,  0.0324,  0.0096,  0.0379,  0.0251]),\n",
       " 'mlp_extractor.policy_net.2.weight': tensor([[-0.1268,  0.1347,  0.0176,  ..., -0.0168, -0.3017,  0.2015],\n",
       "         [-0.3040,  0.1198,  0.3544,  ..., -0.0643,  0.1205, -0.2999],\n",
       "         [-0.3183,  0.4390,  0.1013,  ...,  0.0691,  0.2007,  0.3690],\n",
       "         ...,\n",
       "         [ 0.0276,  0.1321, -0.2943,  ..., -0.1247, -0.3985, -0.0572],\n",
       "         [ 0.1567,  0.0386,  0.1751,  ..., -0.1283, -0.1162, -0.0454],\n",
       "         [-0.1066,  0.1078,  0.2066,  ..., -0.0223, -0.1520,  0.1972]]),\n",
       " 'mlp_extractor.policy_net.2.bias': tensor([-0.0018, -0.0223,  0.0124,  0.0039,  0.0172, -0.0073,  0.0089, -0.0131,\n",
       "          0.0021, -0.0168, -0.0033,  0.0134, -0.0026,  0.0276, -0.0236,  0.0068,\n",
       "         -0.0235,  0.0146,  0.0015,  0.0037,  0.0139,  0.0110, -0.0279, -0.0077,\n",
       "         -0.0005, -0.0160, -0.0051, -0.0280, -0.0131, -0.0133,  0.0069, -0.0289,\n",
       "         -0.0162, -0.0280,  0.0211,  0.0037, -0.0226,  0.0266,  0.0142,  0.0139,\n",
       "          0.0034, -0.0145, -0.0111, -0.0005, -0.0227, -0.0018,  0.0058, -0.0124,\n",
       "          0.0073,  0.0082,  0.0014, -0.0071, -0.0085, -0.0224, -0.0113, -0.0175,\n",
       "          0.0155,  0.0050, -0.0005,  0.0135,  0.0084,  0.0047, -0.0100, -0.0107]),\n",
       " 'action_net.weight': tensor([[ 0.1425,  0.0454,  0.0152, -0.0660,  0.1561,  0.0918, -0.1540,  0.1056,\n",
       "          -0.1423,  0.1237,  0.0965, -0.1340,  0.1379, -0.1320,  0.0809,  0.1205,\n",
       "           0.1068,  0.0845, -0.0905, -0.1364, -0.1269, -0.0253,  0.1300,  0.1147,\n",
       "           0.0951,  0.0576,  0.1465,  0.1415,  0.0748,  0.0561,  0.0914,  0.0587,\n",
       "           0.1192,  0.0071, -0.0478, -0.1374,  0.0567, -0.0466, -0.1046, -0.0912,\n",
       "           0.1278,  0.1260,  0.1039,  0.1162,  0.0410, -0.1407, -0.1303,  0.0843,\n",
       "           0.0562, -0.0991,  0.0356,  0.1367, -0.1311,  0.1198,  0.0959, -0.1121,\n",
       "          -0.1072, -0.1552,  0.1144,  0.1232, -0.0371, -0.1472,  0.0992,  0.0950],\n",
       "         [-0.0192, -0.1559,  0.1421,  0.0240,  0.0707, -0.0148, -0.0124, -0.0682,\n",
       "           0.0245, -0.0229, -0.1112, -0.1442,  0.0515, -0.2158,  0.0255,  0.0572,\n",
       "          -0.0934,  0.0652, -0.0094, -0.1438,  0.0797,  0.0662,  0.2252,  0.1355,\n",
       "          -0.0555, -0.0968,  0.0457, -0.0089, -0.1126, -0.0314, -0.0131,  0.2693,\n",
       "           0.2182, -0.1721, -0.2161, -0.0208,  0.2439,  0.1939, -0.0085,  0.0532,\n",
       "          -0.0462,  0.1952,  0.1917, -0.0531, -0.0830, -0.0086,  0.0507,  0.2401,\n",
       "          -0.0356,  0.1413, -0.0577,  0.1591,  0.0031,  0.1748,  0.0682,  0.0364,\n",
       "          -0.1817,  0.0128,  0.1648,  0.0949,  0.0359,  0.0004, -0.1100, -0.0748],\n",
       "         [-0.0563, -0.0756,  0.0436,  0.1151, -0.0970, -0.1161,  0.0727, -0.0784,\n",
       "           0.0553, -0.0309, -0.0975,  0.1140, -0.0691,  0.1613, -0.0383, -0.0636,\n",
       "          -0.1251, -0.0482,  0.0698,  0.1118,  0.1217,  0.0618, -0.1646, -0.1245,\n",
       "          -0.0476, -0.1236, -0.1217, -0.1672, -0.1191, -0.0534, -0.0912, -0.1293,\n",
       "          -0.1327, -0.0594,  0.1271,  0.0788, -0.1356,  0.0534,  0.0460,  0.1535,\n",
       "          -0.0604, -0.1210, -0.1033, -0.0526, -0.1479,  0.0944,  0.0750, -0.1631,\n",
       "          -0.0531,  0.0952, -0.0742, -0.1275,  0.0488, -0.1187, -0.0815,  0.0465,\n",
       "           0.1156,  0.0923, -0.1192, -0.0842,  0.1232,  0.1395, -0.1047, -0.1014],\n",
       "         [-0.0182,  0.2419, -0.1660, -0.1213, -0.0368,  0.1046,  0.0342,  0.1058,\n",
       "           0.0130, -0.0416,  0.1886,  0.0534, -0.0551,  0.0532, -0.0586, -0.0615,\n",
       "           0.2120, -0.0528,  0.0027,  0.0613, -0.1558, -0.1192, -0.0629, -0.0415,\n",
       "           0.0373,  0.2185,  0.0053,  0.1296,  0.2228,  0.0279,  0.0533, -0.0869,\n",
       "          -0.0884,  0.2181,  0.0492,  0.0191, -0.0697, -0.2136,  0.0479, -0.2224,\n",
       "           0.0297, -0.0715, -0.1011,  0.0315,  0.2576, -0.0005, -0.0364, -0.0428,\n",
       "           0.0444, -0.1809,  0.1267, -0.0582,  0.0390, -0.0733, -0.0396, -0.0139,\n",
       "           0.0721, -0.0255, -0.0714, -0.0525, -0.1452, -0.0930,  0.1983,  0.1724]]),\n",
       " 'action_net.bias': tensor([-0.0428, -0.0004,  0.0200,  0.0258])}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Include only variables with \"policy\", \"action\" (policy) or \"shared_net\" (shared layers)\n",
    "# in their name: only these ones affect the action.\n",
    "# NOTE: you can retrieve those parameters using model.get_parameters() too\n",
    "mean_params = dict(\n",
    "    (key, value)\n",
    "    for key, value in model.policy.state_dict().items()\n",
    "    if (\"policy\" in key or \"shared_net\" in key or \"action\" in key)\n",
    ")\n",
    "\n",
    "mean_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Evolution Strategy Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14_w,29)-aCMA-ES (mu_w=8.4,w_1=21%) in dimension 4996 (seed=91831, Sat Oct 23 10:53:46 2021)\n"
     ]
    }
   ],
   "source": [
    "es = cma.CMAEvolutionStrategy(flatten(mean_params), sigma0=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterate through Mutated Policy Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arnab/.miniconda3/envs/pydrl/lib/python3.7/site-packages/stable_baselines3/common/evaluation.py:69: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  UserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0   Mean top 10% reward: 924.50\n",
      "Iteration 1   Mean top 10% reward: 1773.43\n",
      "Iteration 2   Mean top 10% reward: 1087.66\n",
      "Iteration 3   Mean top 10% reward: 768.52\n",
      "Iteration 4   Mean top 10% reward: 1079.23\n",
      "Iteration 5   Mean top 10% reward: 1614.32\n",
      "Iteration 6   Mean top 10% reward: 1089.86\n",
      "Iteration 7   Mean top 10% reward: 1164.56\n",
      "Iteration 8   Mean top 10% reward: 1112.89\n",
      "Iteration 9   Mean top 10% reward: 1182.44\n"
     ]
    }
   ],
   "source": [
    "for iteration in range(10):\n",
    "    # Create population of candidates and evaluate them\n",
    "    candidates, fitnesses = es.ask(), []\n",
    "    for candidate in candidates:\n",
    "        # Load new policy parameters to agent.\n",
    "        # print(candidate.shape)\n",
    "        model.policy.load_state_dict(to_dict(candidate, mean_params), strict=False)\n",
    "        # Evaluate the agent using stable-baselines predict function\n",
    "        fitness, _ = evaluate_policy(model, env)\n",
    "        fitnesses.append(fitness)\n",
    "    # CMA-ES update\n",
    "    es.tell(candidates, fitnesses)\n",
    "    # Display some training infos\n",
    "    mean_fitness = np.mean(sorted(fitnesses)[:int(0.1 * len(candidates))])\n",
    "    print(\"Iteration {:<3} Mean top 10% reward: {:.2f}\".format(iteration, -mean_fitness))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exporting Params as JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to Convert Params Dict to Flattened List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_list(params):\n",
    "    \"\"\"\n",
    "    :param params: (dict)\n",
    "    :return: (np.ndarray)\n",
    "    \"\"\"\n",
    "    params_ = {}\n",
    "    for key in params.keys():\n",
    "        params_[key] = params[key].flatten().tolist()\n",
    "    return params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write Parameters to JSON File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('data.json', 'w') as f:\n",
    "    json.dump(flatten_list(mean_params), f, indent='\\t')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3fe87c7677a9be80aab770929aa8f3d40850ac08a0f73ec246342c77c48f1c11"
  },
  "kernelspec": {
   "display_name": "Python 3.7.2 64-bit ('pydrl': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
