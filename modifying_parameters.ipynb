{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modifying and Loading Parameters of Policies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "import gym\n",
    "import numpy as np\n",
    "import torch as th\n",
    "\n",
    "from stable_baselines3 import A2C\n",
    "from stable_baselines3.common.evaluation import evaluate_policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mutate Function to modify Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutate(params: Dict[str, th.Tensor]) -> Dict[str, th.Tensor]:\n",
    "    \"\"\"Mutate parameters by adding normal noise to them\"\"\"\n",
    "    return dict((name, param + th.randn_like(param)) for name, param in params.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Policy with a small Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('LunarLander-v2')\n",
    "model = A2C(\n",
    "    \"MlpPolicy\",\n",
    "    env,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Initial Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 99.5     |\n",
      "|    ep_rew_mean        | -188     |\n",
      "| time/                 |          |\n",
      "|    fps                | 702      |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 0        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.26    |\n",
      "|    explained_variance | 0.0233   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | 0.318    |\n",
      "|    value_loss         | 0.357    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 117      |\n",
      "|    ep_rew_mean        | -274     |\n",
      "| time/                 |          |\n",
      "|    fps                | 738      |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 1        |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.28    |\n",
      "|    explained_variance | -0.00511 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | -5.45    |\n",
      "|    value_loss         | 30.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 125      |\n",
      "|    ep_rew_mean        | -317     |\n",
      "| time/                 |          |\n",
      "|    fps                | 747      |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 2        |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.888   |\n",
      "|    explained_variance | -0.0958  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | 4.33     |\n",
      "|    value_loss         | 32.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 129      |\n",
      "|    ep_rew_mean        | -306     |\n",
      "| time/                 |          |\n",
      "|    fps                | 752      |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 2        |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.09    |\n",
      "|    explained_variance | -0.00126 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | -11.6    |\n",
      "|    value_loss         | 110      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 133      |\n",
      "|    ep_rew_mean        | -305     |\n",
      "| time/                 |          |\n",
      "|    fps                | 748      |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 3        |\n",
      "|    total_timesteps    | 2500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.836   |\n",
      "|    explained_variance | -0.0317  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | 1.83     |\n",
      "|    value_loss         | 2.07     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 140      |\n",
      "|    ep_rew_mean        | -305     |\n",
      "| time/                 |          |\n",
      "|    fps                | 746      |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 4        |\n",
      "|    total_timesteps    | 3000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.748   |\n",
      "|    explained_variance | -0.00461 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | 3.38     |\n",
      "|    value_loss         | 24.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 151      |\n",
      "|    ep_rew_mean        | -283     |\n",
      "| time/                 |          |\n",
      "|    fps                | 736      |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 4        |\n",
      "|    total_timesteps    | 3500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.843   |\n",
      "|    explained_variance | -0.00585 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | 5.78     |\n",
      "|    value_loss         | 30.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 158      |\n",
      "|    ep_rew_mean        | -276     |\n",
      "| time/                 |          |\n",
      "|    fps                | 727      |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 5        |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.885   |\n",
      "|    explained_variance | 0.00112  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | -4.75    |\n",
      "|    value_loss         | 67.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 164      |\n",
      "|    ep_rew_mean        | -261     |\n",
      "| time/                 |          |\n",
      "|    fps                | 722      |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 6        |\n",
      "|    total_timesteps    | 4500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.862   |\n",
      "|    explained_variance | 0.00319  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | -0.458   |\n",
      "|    value_loss         | 5.59     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 165      |\n",
      "|    ep_rew_mean        | -254     |\n",
      "| time/                 |          |\n",
      "|    fps                | 723      |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 6        |\n",
      "|    total_timesteps    | 5000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.707   |\n",
      "|    explained_variance | 0.000356 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | -1.47    |\n",
      "|    value_loss         | 14.6     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 164      |\n",
      "|    ep_rew_mean        | -251     |\n",
      "| time/                 |          |\n",
      "|    fps                | 706      |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 7        |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.302   |\n",
      "|    explained_variance | -0.0005  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | 0.0278   |\n",
      "|    value_loss         | 0.187    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 172      |\n",
      "|    ep_rew_mean        | -223     |\n",
      "| time/                 |          |\n",
      "|    fps                | 703      |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 8        |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.692   |\n",
      "|    explained_variance | -0.0541  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | 6.57     |\n",
      "|    value_loss         | 108      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 172      |\n",
      "|    ep_rew_mean        | -211     |\n",
      "| time/                 |          |\n",
      "|    fps                | 705      |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 9        |\n",
      "|    total_timesteps    | 6500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.11    |\n",
      "|    explained_variance | 0.00149  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | 8.31     |\n",
      "|    value_loss         | 67.3     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 178      |\n",
      "|    ep_rew_mean        | -207     |\n",
      "| time/                 |          |\n",
      "|    fps                | 699      |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 10       |\n",
      "|    total_timesteps    | 7000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.805   |\n",
      "|    explained_variance | -0.00116 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | 0.439    |\n",
      "|    value_loss         | 1.76     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 178      |\n",
      "|    ep_rew_mean        | -207     |\n",
      "| time/                 |          |\n",
      "|    fps                | 683      |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 10       |\n",
      "|    total_timesteps    | 7500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.01    |\n",
      "|    explained_variance | -0.179   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | 0.0612   |\n",
      "|    value_loss         | 0.0621   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 194      |\n",
      "|    ep_rew_mean        | -196     |\n",
      "| time/                 |          |\n",
      "|    fps                | 670      |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 11       |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.518   |\n",
      "|    explained_variance | 0.0101   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | -6.19    |\n",
      "|    value_loss         | 127      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 194      |\n",
      "|    ep_rew_mean        | -192     |\n",
      "| time/                 |          |\n",
      "|    fps                | 674      |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 12       |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.561   |\n",
      "|    explained_variance | -0.0584  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | -1.82    |\n",
      "|    value_loss         | 19.6     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 195      |\n",
      "|    ep_rew_mean        | -192     |\n",
      "| time/                 |          |\n",
      "|    fps                | 675      |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 13       |\n",
      "|    total_timesteps    | 9000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.043   |\n",
      "|    explained_variance | 0.184    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | -0.236   |\n",
      "|    value_loss         | 1.3e+03  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 198      |\n",
      "|    ep_rew_mean        | -193     |\n",
      "| time/                 |          |\n",
      "|    fps                | 674      |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 14       |\n",
      "|    total_timesteps    | 9500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.266   |\n",
      "|    explained_variance | 0.0835   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | -0.169   |\n",
      "|    value_loss         | 12       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 198      |\n",
      "|    ep_rew_mean        | -189     |\n",
      "| time/                 |          |\n",
      "|    fps                | 677      |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 14       |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.719   |\n",
      "|    explained_variance | 0.0305   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | -0.185   |\n",
      "|    value_loss         | 1.07     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.a2c.a2c.A2C at 0x7f84192df4e0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use traditional actor-critic policy gradient updates to\n",
    "# find good initial parameters\n",
    "model.learn(total_timesteps=10_000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve Policy Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mlp_extractor.policy_net.0.weight': tensor([[ 0.0523,  0.0923, -0.2493,  0.1845,  0.1131,  0.0717,  0.1366,  0.2136],\n",
       "         [ 0.0480, -0.1824, -0.3128, -0.1512,  0.0041, -0.1035,  0.2259,  0.4073],\n",
       "         [-0.1503, -0.0196, -0.2226,  0.2811,  0.3213,  0.1049,  0.0091, -0.3590],\n",
       "         [ 0.0396, -0.0116,  0.2437,  0.0271, -0.2210,  0.2227,  0.1610,  0.3043],\n",
       "         [ 0.2401, -0.0132, -0.1946, -0.5740, -0.1654, -0.2685, -0.0142, -0.0328],\n",
       "         [-0.0884,  0.0479,  0.0621, -0.0735, -0.2888, -0.0338, -0.0490,  0.0546],\n",
       "         [-0.1125, -0.1088,  0.1204,  0.3141, -0.1330, -0.1819, -0.1169,  0.1096],\n",
       "         [-0.2690, -0.2706, -0.1742,  0.0074,  0.2683,  0.1308, -0.0188,  0.0504],\n",
       "         [-0.1101,  0.2377,  0.6249, -0.2528, -0.2431, -0.1072,  0.1510,  0.4252],\n",
       "         [ 0.0110,  0.1031, -0.1026,  0.2955,  0.2761, -0.0483, -0.0125,  0.1004],\n",
       "         [ 0.0055, -0.2950,  0.1107,  0.3956, -0.1347, -0.0932,  0.0628,  0.0114],\n",
       "         [ 0.2168,  0.0573,  0.1756,  0.2874, -0.3408, -0.1294, -0.0122, -0.0818],\n",
       "         [-0.4062, -0.0890,  0.0847,  0.2351, -0.1123,  0.0901,  0.1890,  0.0929],\n",
       "         [-0.2666,  0.0170, -0.2606, -0.0591,  0.3929,  0.1852, -0.2638,  0.0768],\n",
       "         [ 0.2313, -0.0181, -0.0453,  0.2591, -0.1898,  0.2388, -0.0054,  0.1445],\n",
       "         [-0.0098, -0.1252, -0.1262,  0.0300, -0.1288,  0.1583,  0.2086,  0.2238],\n",
       "         [-0.2358,  0.2996, -0.3818,  0.1017,  0.3208, -0.0354, -0.2866,  0.0692],\n",
       "         [-0.0235,  0.0760, -0.2884, -0.3936,  0.0938,  0.0300, -0.1854,  0.0286],\n",
       "         [-0.2792,  0.2246, -0.3193,  0.6558, -0.0555, -0.2224,  0.3008, -0.0195],\n",
       "         [ 0.3148, -0.0190,  0.2158, -0.1763, -0.3654, -0.3213, -0.1610, -0.1248],\n",
       "         [-0.1040,  0.1891,  0.0853, -0.0586, -0.1416,  0.2663, -0.4023,  0.0361],\n",
       "         [ 0.0089,  0.2107, -0.0267,  0.0140, -0.5517,  0.1436, -0.0813, -0.1527],\n",
       "         [ 0.2453,  0.2265,  0.2048,  0.0721,  0.0276,  0.0960, -0.2060, -0.1879],\n",
       "         [-0.0008,  0.0523,  0.3311, -0.0054, -0.4688,  0.1841,  0.1435,  0.0320],\n",
       "         [-0.0776, -0.1310, -0.3711,  0.2024,  0.0557, -0.0963,  0.0980,  0.0420],\n",
       "         [ 0.1823,  0.0326,  0.0195,  0.3688, -0.1758,  0.1746,  0.0849,  0.0531],\n",
       "         [-0.1068,  0.2301,  0.2965, -0.2854,  0.0556,  0.1233,  0.0143, -0.0069],\n",
       "         [-0.1516, -0.1889, -0.1253, -0.3789,  0.1559, -0.4080, -0.0032, -0.2464],\n",
       "         [ 0.0583,  0.3165,  0.0716, -0.5228,  0.1646, -0.2099, -0.1943, -0.0365],\n",
       "         [ 0.0807, -0.0318, -0.3679,  0.6760,  0.2762,  0.1868,  0.0426,  0.0399],\n",
       "         [-0.2300,  0.0790, -0.1428,  0.3477,  0.4208,  0.0792,  0.2062, -0.0340],\n",
       "         [-0.1531,  0.1175, -0.0314, -0.6021,  0.2093,  0.0316,  0.2229, -0.0713],\n",
       "         [-0.0623,  0.0665, -0.3619,  0.1343,  0.3680,  0.0095,  0.0370, -0.2178],\n",
       "         [-0.1336,  0.1933, -0.2684, -0.5621,  0.0235,  0.2758,  0.3378, -0.3788],\n",
       "         [-0.0299, -0.1473, -0.1294,  0.1587,  0.0984, -0.2199,  0.1912,  0.1357],\n",
       "         [ 0.1433, -0.0736, -0.0389,  0.2346, -0.0699,  0.0852,  0.2595,  0.1832],\n",
       "         [-0.1924, -0.0668, -0.0200,  0.1949, -0.0891,  0.0834,  0.1059,  0.4326],\n",
       "         [-0.1443,  0.0340, -0.1871, -0.3402,  0.3430,  0.0324, -0.2925,  0.0953],\n",
       "         [-0.0458, -0.2298,  0.1449,  0.0036, -0.4253,  0.0397, -0.2123, -0.0261],\n",
       "         [ 0.2223,  0.0589, -0.4908, -0.2383, -0.0728, -0.0293,  0.0660,  0.0832],\n",
       "         [ 0.0876,  0.1115,  0.2782,  0.3694,  0.1697, -0.2407, -0.0749, -0.1950],\n",
       "         [-0.1141,  0.1571,  0.2034, -0.1678, -0.1981, -0.2189, -0.2249,  0.2054],\n",
       "         [-0.0596,  0.1920,  0.0755,  0.2346, -0.3624, -0.1668,  0.1854, -0.0365],\n",
       "         [ 0.1784, -0.0619, -0.4952, -0.0164,  0.4691,  0.3667,  0.0919,  0.0750],\n",
       "         [ 0.2270,  0.2196,  0.6547, -0.0131, -0.0672,  0.0014,  0.2547,  0.0139],\n",
       "         [-0.2815, -0.1606, -0.3595, -0.2813, -0.1760,  0.0023,  0.1462, -0.3849],\n",
       "         [ 0.1390,  0.2619, -0.3373,  0.0530,  0.1847, -0.0401,  0.0102, -0.1553],\n",
       "         [-0.1957, -0.2541,  0.2114,  0.1408, -0.2155, -0.0026,  0.4446, -0.0768],\n",
       "         [-0.5872, -0.0321,  0.2404,  0.2869, -0.1031,  0.2233, -0.0413, -0.1482],\n",
       "         [ 0.1110, -0.1421,  0.2296,  0.1983, -0.2341,  0.1920,  0.0276,  0.0457],\n",
       "         [-0.0258, -0.0287,  0.2611,  0.1318, -0.1563,  0.1233,  0.1688,  0.0031],\n",
       "         [ 0.3440, -0.2270,  0.4147,  0.0530, -0.3843,  0.2266, -0.1473, -0.2572],\n",
       "         [ 0.0955, -0.0768, -0.2672,  0.2384,  0.0830,  0.0120,  0.3596,  0.2704],\n",
       "         [-0.0464,  0.2541, -0.0388, -0.5140, -0.0887,  0.0559, -0.4340, -0.1244],\n",
       "         [-0.0086,  0.0363,  0.0457,  0.4241, -0.5051, -0.0513,  0.0366,  0.0437],\n",
       "         [ 0.2915,  0.2080,  0.3056,  0.0945, -0.2180, -0.2483,  0.2460, -0.0788],\n",
       "         [-0.2030,  0.1052, -0.2901,  0.2553, -0.0689,  0.1809,  0.0333,  0.3632],\n",
       "         [-0.1709,  0.1359, -0.3065,  0.4443,  0.2552, -0.1095, -0.0014, -0.0819],\n",
       "         [-0.0498,  0.3380, -0.3493, -0.0059,  0.0993,  0.1864,  0.1641,  0.0469],\n",
       "         [-0.3244,  0.0597, -0.2968,  0.2075,  0.2794, -0.1949,  0.2324,  0.2607],\n",
       "         [-0.2904, -0.0486, -0.3719,  0.1713, -0.0674, -0.1037, -0.1868, -0.1647],\n",
       "         [-0.2131,  0.3592, -0.2251,  0.3696, -0.0020,  0.3524,  0.1340, -0.0413],\n",
       "         [ 0.1326, -0.0490,  0.4360, -0.0200, -0.2233,  0.3326,  0.2091, -0.3901],\n",
       "         [ 0.0943,  0.1092,  0.2626, -0.1705,  0.0618, -0.2931,  0.1542, -0.2396]]),\n",
       " 'mlp_extractor.policy_net.0.bias': tensor([-0.0184,  0.0285, -0.0282, -0.0197,  0.0289,  0.0141, -0.0155,  0.0074,\n",
       "          0.0224, -0.0310,  0.0125, -0.0201,  0.0050, -0.0361, -0.0063,  0.0373,\n",
       "         -0.0495,  0.0264, -0.0428,  0.0447, -0.0616, -0.0166, -0.0172,  0.0334,\n",
       "         -0.0211, -0.0199, -0.0232,  0.0023, -0.0155, -0.0276, -0.0531, -0.0035,\n",
       "         -0.0278, -0.0193,  0.0031, -0.0105,  0.0152, -0.0003,  0.0224,  0.0234,\n",
       "         -0.0294,  0.0378, -0.0194, -0.0273,  0.0039, -0.0031, -0.0430,  0.0104,\n",
       "         -0.0190, -0.0200,  0.0225,  0.0316, -0.0219, -0.0128, -0.0207, -0.0066,\n",
       "         -0.0313, -0.0410, -0.0417, -0.0524, -0.0228, -0.0423,  0.0226,  0.0046]),\n",
       " 'mlp_extractor.policy_net.2.weight': tensor([[ 0.2499, -0.3162, -0.2474,  ...,  0.2039,  0.1034,  0.2052],\n",
       "         [ 0.0560, -0.1042,  0.0287,  ...,  0.0305, -0.0930, -0.2512],\n",
       "         [-0.4067, -0.0414,  0.0066,  ..., -0.0466,  0.2087, -0.0382],\n",
       "         ...,\n",
       "         [-0.0971,  0.1045, -0.3585,  ..., -0.1537,  0.0935, -0.1882],\n",
       "         [-0.0075, -0.4226,  0.2632,  ..., -0.1209,  0.1981, -0.0733],\n",
       "         [ 0.2534,  0.3161,  0.3259,  ..., -0.1023, -0.0202, -0.1914]]),\n",
       " 'mlp_extractor.policy_net.2.bias': tensor([ 0.0003,  0.0057,  0.0202,  0.0506, -0.0310,  0.0319,  0.0011,  0.0092,\n",
       "          0.0244,  0.0219, -0.0140, -0.0031, -0.0156, -0.0092,  0.0027,  0.0208,\n",
       "          0.0254,  0.0122,  0.0011, -0.0153, -0.0254, -0.0160,  0.0190, -0.0004,\n",
       "         -0.0242,  0.0175, -0.0109, -0.0110,  0.0066,  0.0153, -0.0437,  0.0383,\n",
       "         -0.0320,  0.0148,  0.0045,  0.0015,  0.0316,  0.0376,  0.0108, -0.0195,\n",
       "          0.0211,  0.0093, -0.0215, -0.0400,  0.0066,  0.0050, -0.0277, -0.0114,\n",
       "          0.0065, -0.0032, -0.0155,  0.0285,  0.0174,  0.0184, -0.0114,  0.0037,\n",
       "          0.0097, -0.0053,  0.0135,  0.0177, -0.0020,  0.0201, -0.0091, -0.0505]),\n",
       " 'action_net.weight': tensor([[ 1.1630e-01,  6.7144e-02, -1.4320e-01,  3.6342e-03, -8.8253e-02,\n",
       "          -4.7754e-02,  1.4541e-01, -9.5893e-02, -8.7982e-04, -1.5691e-01,\n",
       "          -1.4072e-01, -1.3914e-01, -9.9590e-02, -1.2730e-01,  1.6770e-01,\n",
       "           1.0420e-01,  7.9991e-02,  7.2921e-03, -1.5898e-01,  1.3503e-01,\n",
       "           9.6278e-02, -3.8996e-02,  1.2926e-01, -9.2880e-02,  1.1307e-01,\n",
       "           1.2378e-01, -4.7693e-02, -8.3903e-02, -1.3614e-01, -1.3229e-01,\n",
       "          -7.5248e-02,  1.4885e-03, -1.2185e-01,  4.2287e-03, -1.4749e-01,\n",
       "           1.0732e-01, -3.8999e-02,  1.2857e-01,  1.2488e-01, -1.1614e-01,\n",
       "          -1.0444e-02,  1.3304e-01, -1.2777e-01,  4.0835e-02,  1.6113e-01,\n",
       "          -1.6244e-01,  8.8793e-03,  8.3676e-02, -1.2687e-01,  1.3562e-01,\n",
       "          -1.0288e-01,  4.3891e-02,  1.6180e-01,  9.0073e-02,  1.1951e-01,\n",
       "           7.7261e-03,  9.8996e-02,  8.5696e-02, -1.4094e-01,  8.2039e-02,\n",
       "           1.1632e-01,  4.3708e-03, -6.7443e-02,  9.2232e-02],\n",
       "         [ 7.2039e-06, -4.9763e-02,  2.3905e-02,  7.7979e-02, -9.6105e-02,\n",
       "           1.1042e-01, -3.6854e-02, -2.2840e-01,  6.4917e-02, -1.5179e-01,\n",
       "           7.6448e-03, -1.7436e-01, -6.0588e-02,  1.1749e-02,  2.4120e-02,\n",
       "           1.0983e-01,  4.2390e-02,  1.8658e-01,  3.6713e-02,  1.3396e-01,\n",
       "          -9.8176e-02, -1.0625e-01,  4.7800e-02,  7.2554e-02, -7.4141e-02,\n",
       "           1.5192e-01, -2.0998e-01, -2.1387e-01,  5.6624e-02,  3.8789e-02,\n",
       "          -8.2748e-02,  1.1123e-01,  1.6170e-02,  3.9341e-02,  4.2097e-02,\n",
       "          -4.1148e-02,  2.7567e-02,  2.8372e-02, -3.9148e-02, -1.2998e-02,\n",
       "           8.3544e-02,  1.1871e-01,  2.1987e-02, -1.2026e-01,  6.0991e-02,\n",
       "          -2.1255e-01, -1.3728e-01, -5.5908e-02, -1.5215e-01,  1.8166e-01,\n",
       "          -1.5331e-01,  1.0428e-01,  2.1513e-02,  8.3209e-02,  2.1307e-01,\n",
       "           1.4038e-01,  1.3432e-01,  1.5344e-01, -1.8266e-01,  1.3845e-01,\n",
       "          -1.6643e-02,  1.7700e-01,  4.4296e-02, -8.1621e-02],\n",
       "         [-7.9683e-02, -1.3524e-01,  1.2898e-01,  3.4928e-02,  3.7433e-02,\n",
       "           7.1423e-02, -1.2614e-01,  1.2157e-01,  9.9100e-02,  1.5079e-01,\n",
       "           1.2621e-01,  1.1356e-01,  4.3162e-02,  1.3384e-01, -1.3472e-01,\n",
       "          -7.2462e-02, -6.1679e-02, -3.1838e-02,  1.6132e-01, -9.4711e-02,\n",
       "          -1.4787e-01, -2.6453e-02, -8.4769e-02,  5.1779e-02, -1.5635e-01,\n",
       "          -9.2941e-02,  6.1959e-02,  1.0627e-01,  1.5236e-01,  1.4148e-01,\n",
       "           6.1410e-02, -6.9200e-03,  6.9935e-02,  4.1022e-02,  1.5057e-01,\n",
       "          -9.1093e-02,  1.2728e-01, -8.1283e-02, -8.5072e-02,  5.7081e-02,\n",
       "           9.8693e-02, -8.5490e-02,  9.3845e-02, -7.7320e-02, -1.2239e-01,\n",
       "           1.7256e-01, -2.6246e-02, -6.8375e-02,  1.0302e-01, -1.1170e-01,\n",
       "           8.5130e-02,  3.8332e-02, -1.1497e-01, -3.5260e-02, -1.2613e-01,\n",
       "          -2.1983e-02, -5.3577e-02, -4.1694e-02,  1.2046e-01, -1.4081e-02,\n",
       "          -1.3318e-01, -2.4491e-02,  7.4032e-02, -1.1774e-01],\n",
       "         [ 1.6052e-02,  1.4028e-01, -7.7717e-02, -1.2644e-01,  9.8837e-02,\n",
       "          -1.8244e-01,  6.8071e-02,  9.7657e-02, -2.0597e-01,  2.0335e-02,\n",
       "          -7.3117e-02,  9.0349e-02,  5.7738e-02, -7.0735e-02,  1.3673e-02,\n",
       "          -6.4854e-02, -2.9599e-02, -1.2524e-01, -1.3331e-01, -6.2465e-02,\n",
       "           2.1080e-01,  1.7170e-01, -2.8653e-02, -7.2669e-02,  2.1563e-01,\n",
       "          -8.7741e-02,  1.2161e-01,  9.2736e-02, -1.6205e-01, -1.4328e-01,\n",
       "           4.5927e-02, -1.0065e-01, -7.6804e-04, -1.2907e-01, -1.2509e-01,\n",
       "           8.4455e-02, -1.9733e-01, -1.8634e-02,  7.2555e-02,  3.6650e-02,\n",
       "          -2.1882e-01, -6.9849e-02, -3.6756e-02,  1.9865e-01, -1.6004e-02,\n",
       "           7.7918e-02,  1.6227e-01,  9.5673e-02,  7.9353e-02, -9.8187e-02,\n",
       "           7.9751e-02, -1.8417e-01, -6.5819e-03, -8.1728e-02, -7.8278e-02,\n",
       "          -1.1504e-01, -9.8797e-02, -1.4813e-01,  7.7543e-02, -1.4950e-01,\n",
       "           1.1602e-01, -1.2391e-01, -1.1316e-01,  1.8547e-01]]),\n",
       " 'action_net.bias': tensor([-0.0143, -0.0058,  0.0177,  0.0028])}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Include only variables with \"policy\", \"action\" (policy) or \"shared_net\" (shared layers)\n",
    "# in their name: only these ones affect the action.\n",
    "# NOTE: you can retrieve those parameters using model.get_parameters() too\n",
    "mean_params = dict(\n",
    "    (key, value)\n",
    "    for key, value in model.policy.state_dict().items()\n",
    "    if (\"policy\" in key or \"shared_net\" in key or \"action\" in key)\n",
    ")\n",
    "\n",
    "mean_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Population Size and Retrieve Environment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# population size of 50 invdiduals\n",
    "pop_size = 50\n",
    "# Keep top 10%\n",
    "n_elite = pop_size // 10\n",
    "# Retrieve the environment\n",
    "env = model.get_env()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterate through Mutated Policy Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1   Mean top fitness: -139.48\n",
      "Best fitness: -121.85\n",
      "Iteration 2   Mean top fitness: -136.02\n",
      "Best fitness: -106.02\n",
      "Iteration 3   Mean top fitness: -119.73\n",
      "Best fitness: -103.64\n",
      "Iteration 4   Mean top fitness: -127.08\n",
      "Best fitness: -124.50\n",
      "Iteration 5   Mean top fitness: -114.11\n",
      "Best fitness: -106.69\n",
      "Iteration 6   Mean top fitness: -98.15\n",
      "Best fitness: -83.05\n",
      "Iteration 7   Mean top fitness: -95.81\n",
      "Best fitness: -87.04\n",
      "Iteration 8   Mean top fitness: -77.52\n",
      "Best fitness: -68.93\n",
      "Iteration 9   Mean top fitness: -75.12\n",
      "Best fitness: -65.89\n",
      "Iteration 10  Mean top fitness: -85.35\n",
      "Best fitness: -79.72\n"
     ]
    }
   ],
   "source": [
    "for iteration in range(10):\n",
    "    # Create population of candidates and evaluate them\n",
    "    population = []\n",
    "    for population_i in range(pop_size):\n",
    "        candidate = mutate(mean_params)\n",
    "        # Load new policy parameters to agent.\n",
    "        # Tell function that it should only update parameters\n",
    "        # we give it (policy parameters)\n",
    "        model.policy.load_state_dict(candidate, strict=False)\n",
    "        # Evaluate the candidate\n",
    "        fitness, _ = evaluate_policy(model, env)\n",
    "        population.append((candidate, fitness))\n",
    "    # Take top 10% and use average over their parameters as next mean parameter\n",
    "    top_candidates = sorted(population, key=lambda x: x[1], reverse=True)[:n_elite]\n",
    "    mean_params = dict(\n",
    "        (\n",
    "            name,\n",
    "            th.stack([candidate[0][name] for candidate in top_candidates]).mean(dim=0),\n",
    "        )\n",
    "        for name in mean_params.keys()\n",
    "    )\n",
    "    mean_fitness = sum(top_candidate[1] for top_candidate in top_candidates) / n_elite\n",
    "    print(f\"Iteration {iteration + 1:<3} Mean top fitness: {mean_fitness:.2f}\")\n",
    "    print(f\"Best fitness: {top_candidates[0][1]:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3fe87c7677a9be80aab770929aa8f3d40850ac08a0f73ec246342c77c48f1c11"
  },
  "kernelspec": {
   "display_name": "Python 3.7.2 64-bit ('pydrl': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
