{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Train Gradient Update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "import threading\n",
    "\n",
    "import gym\n",
    "import numpy as np\n",
    "import torch as th\n",
    "\n",
    "from stable_baselines3 import A2C as ALGO\n",
    "from stable_baselines3.common.evaluation import evaluate_policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init. ENV and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('CartPole-v1')\n",
    "model = ALGO(\n",
    "    \"MlpPolicy\",\n",
    "    env\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to Evaluate Model and Train Model within Thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, env, message = '', verbose = 0):\n",
    "    fitnesses = []\n",
    "    iterations = 10\n",
    "    for i in range(iterations):\n",
    "        fitness, _ = evaluate_policy(model, env)\n",
    "        if verbose == 1:\n",
    "            print(i, fitness, end=\" \")\n",
    "        fitnesses.append(fitness)\n",
    "\n",
    "    mean_fitness = np.mean(sorted(fitnesses))\n",
    "    print(f'Type {message} Mean reward: {mean_fitness}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, timesteps):\n",
    "    # print('Starting Training')\n",
    "    model.learn(total_timesteps=timesteps)\n",
    "    # print('Completed Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arnab/.miniconda3/envs/pydrl/lib/python3.7/site-packages/stable_baselines3/common/evaluation.py:69: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  UserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type  Mean reward: 113.29\n"
     ]
    }
   ],
   "source": [
    "evaluate(model, env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train for 1K Steps and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type  Mean reward: 9.38\n"
     ]
    }
   ],
   "source": [
    "# Train MT Model 1\n",
    "t1 = threading.Thread(target=train, args=(model, 10_00))\n",
    "\n",
    "# starting thread\n",
    "t1.start()\n",
    "\n",
    "# wait until thread is completely executed\n",
    "t1.join()\n",
    "\n",
    "\n",
    "# model_trained.learn(total_timesteps=10_00)\n",
    "evaluate(model, env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Gradient and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Iter:  0| Type Updated Model Mean reward: 9.170000000000002\n",
      "Train Iter:  1| Type Updated Model Mean reward: 9.33\n",
      "Train Iter:  2| Type Updated Model Mean reward: 9.620000000000001\n",
      "Train Iter:  3| Type Updated Model Mean reward: 9.350000000000001\n",
      "Train Iter:  4| Type Updated Model Mean reward: 9.46\n",
      "Train Iter:  5| Type Updated Model Mean reward: 9.819999999999999\n",
      "Train Iter:  6| Type Updated Model Mean reward: 9.31\n",
      "Train Iter:  7| Type Updated Model Mean reward: 10.09\n",
      "Train Iter:  8| Type Updated Model Mean reward: 9.870000000000001\n",
      "Train Iter:  9| Type Updated Model Mean reward: 9.82\n",
      "Train Iter:  10| Type Updated Model Mean reward: 9.25\n",
      "Train Iter:  11| Type Updated Model Mean reward: 9.37\n",
      "Train Iter:  12| Type Updated Model Mean reward: 9.399999999999999\n",
      "Train Iter:  13| Type Updated Model Mean reward: 9.5\n",
      "Train Iter:  14| Type Updated Model Mean reward: 9.489999999999998\n",
      "Train Iter:  15| Type Updated Model Mean reward: 9.370000000000001\n",
      "Train Iter:  16| Type Updated Model Mean reward: 9.41\n",
      "Train Iter:  17| Type Updated Model Mean reward: 10.120000000000001\n",
      "Train Iter:  18| Type Updated Model Mean reward: 9.959999999999999\n",
      "Train Iter:  19| Type Updated Model Mean reward: 9.670000000000002\n",
      "Train Iter:  20| Type Updated Model Mean reward: 10.979999999999999\n",
      "Train Iter:  21| Type Updated Model Mean reward: 9.930000000000001\n",
      "Train Iter:  22| Type Updated Model Mean reward: 11.09\n",
      "Train Iter:  23| Type Updated Model Mean reward: 10.9\n",
      "Train Iter:  24| Type Updated Model Mean reward: 12.6\n",
      "Train Iter:  25| Type Updated Model Mean reward: 13.179999999999998\n",
      "Train Iter:  26| Type Updated Model Mean reward: 15.37\n",
      "Train Iter:  27| Type Updated Model Mean reward: 14.65\n",
      "Train Iter:  28| Type Updated Model Mean reward: 14.63\n",
      "Train Iter:  29| Type Updated Model Mean reward: 14.8\n",
      "Train Iter:  30| Type Updated Model Mean reward: 16.020000000000003\n",
      "Train Iter:  31| Type Updated Model Mean reward: 16.43\n",
      "Train Iter:  32| Type Updated Model Mean reward: 20.110000000000003\n",
      "Train Iter:  33| Type Updated Model Mean reward: 19.79\n",
      "Train Iter:  34| Type Updated Model Mean reward: 22.09\n",
      "Train Iter:  35| Type Updated Model Mean reward: 23.4\n",
      "Train Iter:  36| Type Updated Model Mean reward: 25.490000000000002\n",
      "Train Iter:  37| Type Updated Model Mean reward: 24.4\n",
      "Train Iter:  38| Type Updated Model Mean reward: 26.209999999999997\n",
      "Train Iter:  39| Type Updated Model Mean reward: 29.869999999999997\n",
      "Train Iter:  40| Type Updated Model Mean reward: 24.32\n",
      "Train Iter:  41| Type Updated Model Mean reward: 26.560000000000002\n",
      "Train Iter:  42| Type Updated Model Mean reward: 28.52\n",
      "Train Iter:  43| Type Updated Model Mean reward: 33.51\n",
      "Train Iter:  44| Type Updated Model Mean reward: 34.74999999999999\n",
      "Train Iter:  45| Type Updated Model Mean reward: 31.529999999999994\n",
      "Train Iter:  46| Type Updated Model Mean reward: 27.47\n",
      "Train Iter:  47| Type Updated Model Mean reward: 27.49\n",
      "Train Iter:  48| Type Updated Model Mean reward: 27.689999999999998\n",
      "Train Iter:  49| Type Updated Model Mean reward: 26.369999999999997\n",
      "Train Iter:  50| Type Updated Model Mean reward: 28.32\n",
      "Train Iter:  51| Type Updated Model Mean reward: 24.5\n",
      "Train Iter:  52| Type Updated Model Mean reward: 26.060000000000002\n",
      "Train Iter:  53| Type Updated Model Mean reward: 24.86\n",
      "Train Iter:  54| Type Updated Model Mean reward: 27.27\n",
      "Train Iter:  55| Type Updated Model Mean reward: 27.409999999999997\n",
      "Train Iter:  56| Type Updated Model Mean reward: 23.380000000000003\n",
      "Train Iter:  57| Type Updated Model Mean reward: 25.04\n",
      "Train Iter:  58| Type Updated Model Mean reward: 24.93\n",
      "Train Iter:  59| Type Updated Model Mean reward: 22.509999999999998\n",
      "Train Iter:  60| Type Updated Model Mean reward: 23.439999999999998\n",
      "Train Iter:  61| Type Updated Model Mean reward: 25.630000000000003\n",
      "Train Iter:  62| Type Updated Model Mean reward: 26.809999999999995\n",
      "Train Iter:  63| Type Updated Model Mean reward: 23.229999999999997\n",
      "Train Iter:  64| Type Updated Model Mean reward: 22.96\n",
      "Train Iter:  65| Type Updated Model Mean reward: 24.349999999999998\n",
      "Train Iter:  66| Type Updated Model Mean reward: 25.48\n",
      "Train Iter:  67| Type Updated Model Mean reward: 27.089999999999996\n",
      "Train Iter:  68| Type Updated Model Mean reward: 28.560000000000002\n",
      "Train Iter:  69| Type Updated Model Mean reward: 28.3\n",
      "Train Iter:  70| Type Updated Model Mean reward: 25.18\n",
      "Train Iter:  71| Type Updated Model Mean reward: 28.25\n",
      "Train Iter:  72| Type Updated Model Mean reward: 28.220000000000006\n",
      "Train Iter:  73| Type Updated Model Mean reward: 31.659999999999997\n",
      "Train Iter:  74| Type Updated Model Mean reward: 34.589999999999996\n",
      "Train Iter:  75| Type Updated Model Mean reward: 38.480000000000004\n",
      "Train Iter:  76| Type Updated Model Mean reward: 41.2\n",
      "Train Iter:  77| Type Updated Model Mean reward: 36.07\n",
      "Train Iter:  78| Type Updated Model Mean reward: 34.029999999999994\n",
      "Train Iter:  79| Type Updated Model Mean reward: 35.17\n",
      "Train Iter:  80| Type Updated Model Mean reward: 36.78\n",
      "Train Iter:  81| Type Updated Model Mean reward: 38.63\n",
      "Train Iter:  82| Type Updated Model Mean reward: 31.179999999999996\n",
      "Train Iter:  83| Type Updated Model Mean reward: 33.55\n",
      "Train Iter:  84| Type Updated Model Mean reward: 33.449999999999996\n",
      "Train Iter:  85| Type Updated Model Mean reward: 42.72\n",
      "Train Iter:  86| Type Updated Model Mean reward: 43.43\n",
      "Train Iter:  87| Type Updated Model Mean reward: 37.71\n",
      "Train Iter:  88| Type Updated Model Mean reward: 37.54\n",
      "Train Iter:  89| Type Updated Model Mean reward: 40.27\n",
      "Train Iter:  90| Type Updated Model Mean reward: 43.16000000000001\n",
      "Train Iter:  91| Type Updated Model Mean reward: 44.18\n",
      "Train Iter:  92| Type Updated Model Mean reward: 42.230000000000004\n",
      "Train Iter:  93| Type Updated Model Mean reward: 43.86\n",
      "Train Iter:  94| Type Updated Model Mean reward: 44.400000000000006\n",
      "Train Iter:  95| Type Updated Model Mean reward: 46.88\n",
      "Train Iter:  96| Type Updated Model Mean reward: 50.24\n",
      "Train Iter:  97| Type Updated Model Mean reward: 45.0\n",
      "Train Iter:  98| Type Updated Model Mean reward: 47.959999999999994\n",
      "Train Iter:  99| Type Updated Model Mean reward: 59.56\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    print('Train Iter: ', i, end=\"| \")\n",
    "\n",
    "    # Train MT Model 1\n",
    "    t1 = threading.Thread(target=train, args=(model, 50))\n",
    "\n",
    "    # starting thread\n",
    "    t1.start()\n",
    "    \n",
    "    # wait until thread is completely executed\n",
    "    t1.join()\n",
    "    \n",
    "    evaluate(model, env, 'Updated Model', verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'policy': OrderedDict([('mlp_extractor.policy_net.0.weight',\n",
       "               tensor([[-1.8331e-01, -1.6507e-01, -4.6408e-01,  8.8575e-02],\n",
       "                       [ 1.7446e-01,  2.9289e-01,  2.1712e-01, -1.7124e-01],\n",
       "                       [ 1.5389e-01,  1.4528e-01,  2.4494e-01, -4.4658e-02],\n",
       "                       [-1.9655e-01, -9.2355e-02,  2.5860e-01,  3.4209e-01],\n",
       "                       [ 5.3109e-02,  5.8897e-02,  1.2367e-01,  2.2904e-01],\n",
       "                       [-1.2061e-01, -2.9573e-02, -1.2578e-01, -1.0536e-01],\n",
       "                       [-7.9987e-02,  2.6514e-01,  5.0527e-02,  2.0904e-01],\n",
       "                       [ 1.0737e-01, -3.9490e-02,  1.0363e-02, -2.4301e-01],\n",
       "                       [-2.0188e-01, -1.9806e-01, -4.7069e-03, -1.1911e-01],\n",
       "                       [ 2.7154e-03,  1.7215e-01,  1.7344e-01,  3.0100e-02],\n",
       "                       [ 1.8351e-01, -6.1347e-02,  5.2896e-02, -4.4096e-01],\n",
       "                       [ 1.0752e-01, -2.6380e-01,  2.3568e-01,  1.1084e-01],\n",
       "                       [ 6.9694e-02, -8.5981e-02, -1.2762e-01, -1.2148e-01],\n",
       "                       [ 1.2147e-01,  1.4035e-01,  1.6540e-01,  1.4332e-01],\n",
       "                       [-7.3746e-02,  2.4278e-02,  4.3890e-02,  1.0169e-01],\n",
       "                       [-3.7020e-01, -1.2965e-01,  2.8864e-02, -4.4903e-01],\n",
       "                       [ 7.9300e-02, -2.4857e-01, -4.5989e-02,  2.9721e-01],\n",
       "                       [-2.3527e-01,  1.7868e-01, -9.1297e-02,  4.1915e-01],\n",
       "                       [ 1.9823e-01,  1.3437e-01,  1.0271e-02, -2.1037e-01],\n",
       "                       [ 2.7783e-01,  2.0088e-01, -1.1762e-01, -2.8364e-01],\n",
       "                       [-1.3238e-01,  9.7177e-02, -3.2793e-01, -1.7730e-01],\n",
       "                       [ 8.7102e-02, -1.3264e-01, -1.3483e-01,  3.0964e-01],\n",
       "                       [ 5.7599e-03, -7.5561e-02, -9.4252e-03,  1.3402e-01],\n",
       "                       [-1.0279e-01, -3.5521e-01,  5.9183e-02,  2.1411e-01],\n",
       "                       [ 7.2850e-02, -2.9863e-01,  3.4993e-02, -2.9679e-01],\n",
       "                       [-8.6965e-02, -1.8471e-03, -1.4096e-01, -9.1875e-02],\n",
       "                       [ 1.4813e-01, -1.0216e-02,  2.9623e-01,  1.3991e-01],\n",
       "                       [ 7.2690e-03, -1.8606e-02,  3.3333e-01,  2.1602e-01],\n",
       "                       [-6.0389e-02, -8.3090e-02,  2.2442e-01,  8.9154e-02],\n",
       "                       [ 4.3168e-01, -6.1987e-02,  1.9506e-01,  1.3821e-01],\n",
       "                       [-2.3224e-01,  2.5594e-01,  1.7688e-01, -3.5315e-01],\n",
       "                       [ 1.6146e-01, -2.3434e-01, -2.3664e-02,  4.0103e-02],\n",
       "                       [ 2.3527e-01,  1.9359e-01, -7.2522e-02, -2.8841e-01],\n",
       "                       [-2.2606e-01, -1.1632e-01,  1.0423e-02, -5.7901e-02],\n",
       "                       [-4.1591e-01, -2.9672e-01,  2.0611e-01, -5.5269e-02],\n",
       "                       [-2.6321e-01,  5.4330e-01, -1.1902e-01, -1.9975e-01],\n",
       "                       [-2.5219e-01, -2.2505e-01,  3.2439e-02,  4.8577e-01],\n",
       "                       [ 1.4181e-01, -3.6861e-01, -1.9709e-01, -2.2445e-01],\n",
       "                       [ 1.4431e-01,  1.5761e-01, -3.0537e-01, -1.6973e-02],\n",
       "                       [-5.6706e-02, -6.3212e-02,  5.9709e-02,  2.8910e-01],\n",
       "                       [ 6.8947e-02,  1.8699e-01, -4.8454e-01,  1.4704e-01],\n",
       "                       [ 6.3300e-02,  9.3502e-02, -1.0158e-01, -4.2088e-01],\n",
       "                       [-8.7826e-02,  3.3534e-02, -6.6289e-02, -1.1506e-01],\n",
       "                       [-5.4218e-02,  1.7681e-02, -2.7131e-01,  1.6387e-01],\n",
       "                       [-3.4669e-01, -1.4580e-01,  2.6882e-01,  4.0868e-02],\n",
       "                       [ 1.1393e-01, -2.7050e-02,  1.6408e-01,  7.9290e-02],\n",
       "                       [ 2.4641e-01,  2.1228e-01, -1.1221e-01, -1.9188e-01],\n",
       "                       [-5.5939e-02, -3.1104e-01,  1.4848e-02,  2.8691e-01],\n",
       "                       [-1.1769e-01, -1.5054e-02,  3.6521e-02,  1.1711e-01],\n",
       "                       [-3.1548e-02, -2.3937e-01, -3.7413e-02,  1.6035e-01],\n",
       "                       [ 2.7801e-01, -4.5732e-03,  1.0594e-01,  1.0620e-01],\n",
       "                       [-1.9345e-02,  1.6701e-05,  2.3841e-01,  1.3189e-01],\n",
       "                       [ 2.1998e-01,  4.9763e-02, -2.0801e-01, -2.5282e-01],\n",
       "                       [ 1.0525e-01, -1.3453e-02, -5.9885e-02, -1.7605e-01],\n",
       "                       [ 1.0007e-01, -5.1344e-02, -3.0423e-01,  2.2736e-02],\n",
       "                       [ 4.4150e-02, -1.0658e-01,  3.3673e-01, -3.4617e-02],\n",
       "                       [-3.1467e-01, -1.9717e-01, -3.1828e-03,  1.0900e-01],\n",
       "                       [-1.0293e-01, -1.6517e-01, -5.9749e-02, -9.1659e-02],\n",
       "                       [ 9.6978e-02,  1.1697e-01, -3.0967e-01, -1.0187e-01],\n",
       "                       [-1.9985e-01, -8.0931e-02, -7.2255e-02, -1.6124e-01],\n",
       "                       [-2.9428e-01,  1.8564e-01,  1.4022e-01,  8.8572e-02],\n",
       "                       [-1.0053e-01,  4.5589e-01, -1.4034e-01,  2.4870e-01],\n",
       "                       [ 1.4531e-01, -2.5049e-01, -1.0825e-01,  8.2386e-02],\n",
       "                       [ 1.1580e-01, -3.6776e-01, -3.6387e-02,  2.8165e-01]])),\n",
       "              ('mlp_extractor.policy_net.0.bias',\n",
       "               tensor([-0.0337,  0.0236,  0.0452, -0.0373, -0.0460,  0.0558,  0.0470,  0.0418,\n",
       "                        0.0540,  0.0458,  0.0077, -0.0367,  0.0599, -0.0534,  0.0628, -0.0611,\n",
       "                       -0.0310, -0.0319,  0.0277,  0.0209,  0.0416, -0.0266, -0.0499, -0.0227,\n",
       "                        0.0540,  0.0502, -0.0643, -0.0366, -0.0558, -0.0467,  0.0232, -0.0380,\n",
       "                        0.0255, -0.0425, -0.0152, -0.0065, -0.0342,  0.0564,  0.0431, -0.0339,\n",
       "                        0.0568,  0.0325,  0.0500, -0.0554, -0.0477, -0.0482,  0.0290, -0.0186,\n",
       "                       -0.0503, -0.0280,  0.0670, -0.0552,  0.0269,  0.0369, -0.0467, -0.0562,\n",
       "                        0.0565, -0.0600,  0.0404,  0.0598, -0.0352,  0.0426, -0.0295, -0.0190])),\n",
       "              ('mlp_extractor.policy_net.2.weight',\n",
       "               tensor([[ 0.0894,  0.1204, -0.1515,  ...,  0.2410,  0.0840,  0.4308],\n",
       "                       [ 0.3447, -0.2993, -0.0630,  ..., -0.0278,  0.2153,  0.0985],\n",
       "                       [-0.1621,  0.1160,  0.0526,  ..., -0.0553, -0.0961,  0.1497],\n",
       "                       ...,\n",
       "                       [ 0.1670,  0.0553, -0.2863,  ..., -0.0758, -0.1341, -0.2182],\n",
       "                       [ 0.0519,  0.0045, -0.1752,  ...,  0.1691, -0.1085, -0.2357],\n",
       "                       [-0.1463,  0.2967, -0.1796,  ..., -0.0876, -0.1841,  0.0347]])),\n",
       "              ('mlp_extractor.policy_net.2.bias',\n",
       "               tensor([-0.0473, -0.0264,  0.0443, -0.0372, -0.0295,  0.0234, -0.0352, -0.0187,\n",
       "                        0.0317,  0.0283,  0.0292,  0.0256, -0.0381,  0.0341, -0.0136,  0.0224,\n",
       "                       -0.0252,  0.0202, -0.0358, -0.0316,  0.0292,  0.0268, -0.0334,  0.0259,\n",
       "                       -0.0396, -0.0230, -0.0242,  0.0255, -0.0307, -0.0274,  0.0462,  0.0287,\n",
       "                        0.0388, -0.0389,  0.0249,  0.0263, -0.0386,  0.0369,  0.0290, -0.0244,\n",
       "                        0.0282, -0.0482,  0.0082, -0.0323, -0.0300,  0.0381,  0.0242,  0.0393,\n",
       "                       -0.0380, -0.0284,  0.0463,  0.0344, -0.0597, -0.0366, -0.0255, -0.0248,\n",
       "                        0.0324,  0.0275,  0.0248,  0.0315,  0.0253,  0.0284, -0.0314,  0.0375])),\n",
       "              ('mlp_extractor.value_net.0.weight',\n",
       "               tensor([[-1.7924e-02, -2.4719e-01, -2.1231e-01,  6.2743e-02],\n",
       "                       [ 5.2768e-02, -1.2904e-01, -1.6027e-01,  4.1222e-03],\n",
       "                       [-1.5611e-01, -1.3527e-01, -3.8039e-02,  3.2535e-01],\n",
       "                       [ 8.7331e-03, -1.3747e-01, -1.2925e-01,  1.9289e-01],\n",
       "                       [-1.8976e-01,  6.0202e-02,  2.5261e-01,  3.8876e-01],\n",
       "                       [-3.6164e-02, -1.5592e-01,  4.9968e-02,  4.0244e-02],\n",
       "                       [ 3.8885e-02,  2.8217e-02, -5.9960e-02, -2.9075e-01],\n",
       "                       [ 7.1391e-02,  2.8221e-01, -3.4371e-02, -1.1329e-01],\n",
       "                       [ 1.4779e-01,  1.6752e-01, -1.0657e-01, -3.7333e-01],\n",
       "                       [-1.4187e-01, -2.3050e-01,  1.2159e-01, -1.8253e-01],\n",
       "                       [ 5.6695e-02, -2.3782e-01, -1.1250e-01,  1.0565e-01],\n",
       "                       [ 4.1112e-02,  1.4311e-01,  1.2001e-01,  3.9220e-01],\n",
       "                       [ 4.7607e-02, -8.9170e-02,  5.8944e-02,  2.5490e-01],\n",
       "                       [ 1.1897e-01,  1.8597e-01,  3.8641e-02, -6.8463e-02],\n",
       "                       [-1.1204e-01, -1.1816e-01,  1.8569e-01,  2.0923e-01],\n",
       "                       [-1.4117e-01,  2.7227e-01,  8.7024e-02, -1.8880e-01],\n",
       "                       [-2.1525e-01,  1.1601e-01, -1.1020e-01,  1.7310e-01],\n",
       "                       [-1.2366e-01,  1.8130e-02, -1.9148e-02, -3.9677e-01],\n",
       "                       [ 6.4587e-02,  2.4034e-01, -4.2812e-01, -2.3772e-01],\n",
       "                       [ 1.4229e-01, -5.9461e-02, -2.4583e-01,  1.0701e-01],\n",
       "                       [ 1.9629e-01,  1.0323e-01, -7.0411e-02,  8.3712e-02],\n",
       "                       [-1.2250e-01, -7.8222e-02,  5.0686e-01,  2.2719e-02],\n",
       "                       [ 5.9043e-01,  1.4494e-01,  1.3909e-01,  5.1593e-02],\n",
       "                       [ 1.6656e-01, -1.9422e-01, -3.0293e-02, -2.8810e-01],\n",
       "                       [ 1.3554e-01,  5.7872e-02, -1.6822e-01,  1.4780e-01],\n",
       "                       [-3.0592e-01, -1.2767e-01,  7.9722e-02,  3.3807e-01],\n",
       "                       [ 1.6344e-01, -3.4456e-01,  4.6683e-02,  8.6890e-02],\n",
       "                       [ 6.4924e-02,  3.7611e-01,  1.1595e-01,  6.8628e-02],\n",
       "                       [ 2.4541e-01,  3.0833e-01, -5.4587e-01, -1.4304e-01],\n",
       "                       [ 5.2799e-02, -1.7618e-01,  1.2796e-01,  2.9138e-01],\n",
       "                       [-1.9947e-01,  2.4362e-01,  6.5132e-02, -1.2599e-02],\n",
       "                       [-1.0839e-01,  6.3450e-02,  1.5436e-01, -8.8631e-02],\n",
       "                       [-6.3658e-02,  1.3580e-01, -2.5392e-01, -1.6567e-01],\n",
       "                       [ 7.3661e-02,  2.2912e-01, -2.8195e-01, -8.6629e-02],\n",
       "                       [ 3.1193e-01, -6.9377e-02,  2.4244e-01,  1.7995e-01],\n",
       "                       [-5.1738e-02, -1.6890e-01,  2.4271e-02,  3.4379e-01],\n",
       "                       [-2.4792e-01, -1.0038e-01,  3.3825e-01,  1.5340e-01],\n",
       "                       [ 3.2502e-01,  9.9432e-02,  1.1002e-01, -1.3110e-01],\n",
       "                       [ 7.8086e-04, -3.2667e-01, -1.6349e-02, -1.1681e-01],\n",
       "                       [-1.5455e-01, -1.3929e-01,  4.1216e-01,  2.8057e-01],\n",
       "                       [-1.8022e-01, -7.2228e-02,  1.1159e-01, -1.7652e-02],\n",
       "                       [-3.0762e-01, -1.3421e-01,  1.8932e-03,  3.8136e-02],\n",
       "                       [ 6.2908e-02, -2.8936e-01, -2.3395e-01,  9.5921e-02],\n",
       "                       [ 1.4374e-01,  5.4266e-02,  7.2826e-02, -5.9971e-01],\n",
       "                       [ 7.5321e-03, -2.8537e-01, -5.3937e-02, -9.6411e-02],\n",
       "                       [ 2.5519e-01, -1.5272e-01, -1.6737e-02, -2.3782e-01],\n",
       "                       [ 3.4984e-01, -5.2125e-01,  4.6538e-01,  1.5710e-01],\n",
       "                       [ 2.3277e-01, -1.1968e-02,  9.2845e-02,  7.5250e-02],\n",
       "                       [-1.8992e-01,  2.1569e-01,  1.9319e-01,  2.3000e-01],\n",
       "                       [ 2.8534e-01,  1.0208e-02, -1.8752e-02,  2.5309e-01],\n",
       "                       [-9.1461e-02, -2.7789e-01,  1.5896e-01,  6.5316e-02],\n",
       "                       [ 6.1824e-02,  1.7402e-01,  5.4066e-02, -1.5463e-02],\n",
       "                       [ 2.6941e-01, -1.5826e-01, -1.2992e-01, -2.3265e-01],\n",
       "                       [ 2.6496e-01,  1.5746e-01, -1.9896e-01, -4.2132e-02],\n",
       "                       [ 3.8325e-02, -8.2796e-02,  1.4437e-01,  4.1561e-01],\n",
       "                       [ 1.2620e-01, -1.4129e-01, -1.1334e-01,  2.0891e-01],\n",
       "                       [ 1.8121e-01, -9.2870e-02, -5.0768e-02,  1.4488e-01],\n",
       "                       [ 3.7183e-04, -2.2598e-03,  2.0115e-01,  1.8188e-01],\n",
       "                       [ 3.4517e-01,  3.5328e-01,  2.3490e-01, -1.0278e-01],\n",
       "                       [ 1.0609e-01, -2.5184e-01,  3.0172e-01,  2.0633e-01],\n",
       "                       [ 7.9712e-02,  8.9386e-02, -9.8301e-02,  1.7501e-01],\n",
       "                       [ 7.6365e-02,  1.1639e-02,  8.6140e-02,  2.4793e-01],\n",
       "                       [-1.0201e-02,  4.8876e-02,  5.9318e-02, -1.3607e-01],\n",
       "                       [ 1.2398e-01, -4.2039e-02, -1.1785e-01, -5.2647e-01]])),\n",
       "              ('mlp_extractor.value_net.0.bias',\n",
       "               tensor([ 0.3581, -0.3314, -0.2110, -0.3036,  0.3127,  0.3463, -0.3374, -0.3569,\n",
       "                       -0.3445, -0.3361,  0.3806,  0.2325,  0.3343,  0.3332, -0.2796, -0.3604,\n",
       "                       -0.3735, -0.2876, -0.3361,  0.3183,  0.3138, -0.3462,  0.3566, -0.3559,\n",
       "                        0.3668,  0.3055,  0.3042, -0.3268, -0.3504,  0.2227, -0.3536,  0.3573,\n",
       "                       -0.2936, -0.3543,  0.3328,  0.3435,  0.3510,  0.3142, -0.3601,  0.2837,\n",
       "                       -0.3496, -0.3537,  0.3792, -0.2920, -0.3656, -0.3508,  0.3401,  0.3492,\n",
       "                        0.3583,  0.3582, -0.3076,  0.3349,  0.3175, -0.3605,  0.3345, -0.2978,\n",
       "                       -0.3312,  0.3434, -0.3662,  0.2714,  0.3636,  0.3206, -0.3389, -0.2776])),\n",
       "              ('mlp_extractor.value_net.2.weight',\n",
       "               tensor([[ 5.0865e-02,  1.7572e-01, -1.6791e-02,  ..., -2.3900e-01,\n",
       "                         6.4107e-01,  3.2478e-01],\n",
       "                       [-1.4759e-01, -3.0505e-01,  1.1770e-02,  ...,  2.2269e-02,\n",
       "                        -4.3720e-01, -1.5852e-01],\n",
       "                       [-2.8229e-01,  3.0825e-04,  2.2579e-02,  ..., -1.7274e-01,\n",
       "                         1.8050e-01,  1.8632e-01],\n",
       "                       ...,\n",
       "                       [-3.5027e-01, -2.5075e-02,  2.3100e-01,  ..., -2.9896e-01,\n",
       "                         2.1615e-01,  4.1964e-01],\n",
       "                       [-6.6549e-02,  2.6823e-01, -1.0769e-01,  ..., -3.2642e-01,\n",
       "                         2.4328e-01,  1.5449e-01],\n",
       "                       [ 1.0929e-01, -5.5588e-01, -2.3731e-02,  ...,  3.5982e-01,\n",
       "                         4.7317e-02, -2.3628e-01]])),\n",
       "              ('mlp_extractor.value_net.2.bias',\n",
       "               tensor([-0.1963,  0.2178, -0.2258,  0.1458,  0.2249, -0.1732, -0.2389,  0.1998,\n",
       "                       -0.1952,  0.2313, -0.2395, -0.1840,  0.2344,  0.1838, -0.2218, -0.2330,\n",
       "                        0.2329, -0.1756, -0.2160,  0.2153, -0.2508,  0.2414,  0.2386,  0.2179,\n",
       "                       -0.2324,  0.2482, -0.1998, -0.2010, -0.2483,  0.2058, -0.2496, -0.2104,\n",
       "                        0.2479,  0.1988,  0.1662,  0.2075, -0.2497,  0.1836, -0.2140,  0.2074,\n",
       "                       -0.1780, -0.2125, -0.1567,  0.1797, -0.2294,  0.2338,  0.2138,  0.2022,\n",
       "                       -0.2004, -0.2121,  0.2412,  0.1964, -0.1977,  0.1815,  0.2901, -0.2374,\n",
       "                       -0.2791,  0.1489,  0.2700,  0.2377,  0.2340, -0.1843, -0.1978,  0.3008])),\n",
       "              ('action_net.weight',\n",
       "               tensor([[-0.0894, -0.1183,  0.0809, -0.0828, -0.0734,  0.0826, -0.0608, -0.1008,\n",
       "                         0.1198,  0.1243,  0.0873,  0.1161, -0.0767,  0.1204, -0.0685,  0.0968,\n",
       "                        -0.1173,  0.0981, -0.0691, -0.1197,  0.1017,  0.0987, -0.0992,  0.0772,\n",
       "                        -0.0844, -0.1140, -0.1058,  0.0825, -0.0972, -0.1206,  0.0888,  0.1100,\n",
       "                         0.0931, -0.0924,  0.0974,  0.1108, -0.0896,  0.0921,  0.1040, -0.0894,\n",
       "                         0.0571, -0.0816,  0.0358, -0.0993, -0.0995,  0.1072,  0.0978,  0.0828,\n",
       "                        -0.0835, -0.1111,  0.0880,  0.0770, -0.0905, -0.1144, -0.1175, -0.1136,\n",
       "                         0.1097,  0.1209,  0.1152,  0.1114,  0.0981,  0.1226, -0.1215,  0.0668],\n",
       "                       [ 0.0884,  0.1185, -0.0811,  0.0841,  0.0709, -0.0830,  0.0625,  0.1011,\n",
       "                        -0.1200, -0.1261, -0.0873, -0.1156,  0.0758, -0.1213,  0.0709, -0.0945,\n",
       "                         0.1146, -0.0983,  0.0724,  0.1158, -0.0991, -0.1016,  0.0994, -0.0776,\n",
       "                         0.0846,  0.1132,  0.1036, -0.0828,  0.0979,  0.1232, -0.0914, -0.1074,\n",
       "                        -0.0951,  0.0925, -0.0937, -0.1112,  0.0858, -0.0892, -0.1044,  0.0899,\n",
       "                        -0.0584,  0.0818, -0.0366,  0.0988,  0.0977, -0.1079, -0.0976, -0.0854,\n",
       "                         0.0828,  0.1120, -0.0867, -0.0775,  0.0870,  0.1132,  0.1160,  0.1134,\n",
       "                        -0.1085, -0.1231, -0.1146, -0.1105, -0.0969, -0.1255,  0.1221, -0.0643]])),\n",
       "              ('action_net.bias', tensor([ 0.0252, -0.0252])),\n",
       "              ('value_net.weight',\n",
       "               tensor([[-0.6687,  0.7674, -0.5729,  0.8293,  0.6694, -0.6408, -0.7146,  0.7382,\n",
       "                        -0.6716,  0.7972, -0.6295, -0.6767,  0.5882,  0.7933, -0.7603, -0.5588,\n",
       "                         0.6294, -0.6439, -0.6663,  0.6443, -0.5714,  0.5582,  0.7365,  0.5871,\n",
       "                        -0.6815,  0.6597, -0.6569, -0.5375, -0.5362,  0.8173, -0.5947, -0.7587,\n",
       "                         0.5655,  0.7146,  0.8147,  0.6424, -0.7022,  0.7278, -0.6383,  0.6637,\n",
       "                        -0.6672, -0.7518, -0.7709,  0.6531, -0.5889,  0.6745,  0.6526,  0.5808,\n",
       "                        -0.6164, -0.7079,  0.7857,  0.7353, -0.7524,  0.8144,  0.5317, -0.5892,\n",
       "                        -0.5792,  0.8447,  0.5766,  0.5580,  0.6284, -0.6811, -0.6912,  0.5556]])),\n",
       "              ('value_net.bias', tensor([0.5510]))]),\n",
       " 'policy.optimizer': {'state': {0: {'step': 1200,\n",
       "    'square_avg': tensor([[2.1423e-07, 2.9713e-06, 1.2374e-06, 8.8941e-06],\n",
       "            [2.8154e-07, 4.3404e-06, 1.7779e-06, 1.1862e-05],\n",
       "            [6.5536e-08, 8.4260e-07, 3.6146e-07, 2.7070e-06],\n",
       "            [3.3545e-07, 5.8611e-06, 2.3225e-06, 1.4784e-05],\n",
       "            [3.3482e-07, 5.8093e-06, 2.3207e-06, 1.4968e-05],\n",
       "            [1.4684e-07, 2.2108e-06, 9.0568e-07, 6.4069e-06],\n",
       "            [3.7076e-09, 1.0053e-07, 3.6164e-08, 2.1004e-07],\n",
       "            [3.2872e-07, 5.6905e-06, 2.2710e-06, 1.4640e-05],\n",
       "            [2.3053e-08, 3.3253e-07, 1.3554e-07, 1.0629e-06],\n",
       "            [3.7987e-08, 4.3688e-07, 1.8758e-07, 1.5459e-06],\n",
       "            [1.3205e-07, 2.4561e-06, 9.5637e-07, 5.8666e-06],\n",
       "            [2.4704e-07, 3.9998e-06, 1.6338e-06, 1.0693e-05],\n",
       "            [1.6514e-07, 2.6317e-06, 1.0725e-06, 7.3676e-06],\n",
       "            [3.2837e-08, 5.5664e-07, 2.2229e-07, 1.5287e-06],\n",
       "            [4.4065e-09, 1.1469e-07, 4.1692e-08, 2.4007e-07],\n",
       "            [5.4053e-08, 1.0360e-06, 3.9713e-07, 2.3834e-06],\n",
       "            [3.4637e-07, 5.7426e-06, 2.3222e-06, 1.4995e-05],\n",
       "            [2.7216e-07, 4.8387e-06, 1.9017e-06, 1.2088e-05],\n",
       "            [2.2041e-07, 3.8012e-06, 1.5249e-06, 9.6865e-06],\n",
       "            [1.9767e-07, 3.5153e-06, 1.3970e-06, 8.7206e-06],\n",
       "            [1.9189e-07, 3.4173e-06, 1.3629e-06, 8.6441e-06],\n",
       "            [3.1774e-07, 5.3756e-06, 2.1616e-06, 1.3879e-05],\n",
       "            [2.1759e-07, 3.3045e-06, 1.3637e-06, 9.3208e-06],\n",
       "            [2.5026e-07, 4.1429e-06, 1.6825e-06, 1.0755e-05],\n",
       "            [8.0158e-08, 1.4745e-06, 5.7698e-07, 3.7165e-06],\n",
       "            [1.8203e-07, 2.7665e-06, 1.1328e-06, 7.9513e-06],\n",
       "            [2.1182e-07, 3.4897e-06, 1.4153e-06, 9.4222e-06],\n",
       "            [1.9330e-07, 3.4948e-06, 1.3813e-06, 8.7184e-06],\n",
       "            [2.4419e-07, 3.8114e-06, 1.5624e-06, 1.0587e-05],\n",
       "            [3.3565e-07, 5.3042e-06, 2.1692e-06, 1.4683e-05],\n",
       "            [3.8807e-07, 6.3905e-06, 2.5958e-06, 1.6730e-05],\n",
       "            [2.2562e-07, 3.2039e-06, 1.3371e-06, 9.4835e-06],\n",
       "            [2.3626e-07, 4.1215e-06, 1.6476e-06, 1.0390e-05],\n",
       "            [5.5013e-08, 6.8707e-07, 2.8739e-07, 2.2834e-06],\n",
       "            [1.2643e-07, 1.8754e-06, 7.7025e-07, 5.2480e-06],\n",
       "            [1.9402e-07, 3.1205e-06, 1.2819e-06, 8.1830e-06],\n",
       "            [4.3284e-07, 7.4718e-06, 2.9902e-06, 1.8812e-05],\n",
       "            [6.2166e-08, 1.1282e-06, 4.3959e-07, 2.9070e-06],\n",
       "            [1.3484e-07, 2.0439e-06, 8.4002e-07, 5.7363e-06],\n",
       "            [2.3652e-07, 4.1931e-06, 1.6711e-06, 1.0557e-05],\n",
       "            [4.2321e-09, 3.5029e-08, 1.6203e-08, 1.8117e-07],\n",
       "            [3.0162e-07, 5.2924e-06, 2.0939e-06, 1.3226e-05],\n",
       "            [2.1883e-07, 3.3453e-06, 1.3747e-06, 9.4866e-06],\n",
       "            [9.3706e-08, 1.3072e-06, 5.4892e-07, 3.9376e-06],\n",
       "            [2.2479e-07, 3.6107e-06, 1.4675e-06, 9.7169e-06],\n",
       "            [1.6819e-07, 2.5355e-06, 1.0384e-06, 7.3020e-06],\n",
       "            [2.7526e-07, 4.6895e-06, 1.8853e-06, 1.2059e-05],\n",
       "            [3.3118e-07, 5.5627e-06, 2.2489e-06, 1.4348e-05],\n",
       "            [1.8395e-07, 2.8673e-06, 1.1762e-06, 7.9948e-06],\n",
       "            [2.4813e-07, 3.9297e-06, 1.6014e-06, 1.0537e-05],\n",
       "            [2.1147e-09, 3.2570e-08, 1.1405e-08, 1.1262e-07],\n",
       "            [2.3939e-07, 4.0084e-06, 1.6191e-06, 1.0691e-05],\n",
       "            [3.1913e-07, 5.5664e-06, 2.2053e-06, 1.4125e-05],\n",
       "            [5.0564e-07, 8.5258e-06, 3.4131e-06, 2.2397e-05],\n",
       "            [3.1340e-08, 3.5961e-07, 1.5383e-07, 1.2986e-06],\n",
       "            [4.0271e-08, 5.2748e-07, 2.2297e-07, 1.7089e-06],\n",
       "            [1.1191e-08, 2.3861e-07, 9.0811e-08, 5.1109e-07],\n",
       "            [2.2756e-09, 3.7238e-08, 1.3426e-08, 1.1877e-07],\n",
       "            [3.2271e-07, 5.5279e-06, 2.2142e-06, 1.4331e-05],\n",
       "            [6.8020e-08, 1.0587e-06, 4.3471e-07, 3.0343e-06],\n",
       "            [5.3332e-09, 1.1543e-07, 4.3521e-08, 2.8514e-07],\n",
       "            [1.7267e-08, 1.5716e-07, 7.0021e-08, 6.8936e-07],\n",
       "            [2.8893e-07, 4.1892e-06, 1.7386e-06, 1.2138e-05],\n",
       "            [1.9638e-07, 3.2503e-06, 1.3270e-06, 8.4302e-06]])},\n",
       "   1: {'step': 1200,\n",
       "    'square_avg': tensor([7.4023e-05, 1.0636e-04, 2.1160e-05, 1.4023e-04, 1.3956e-04, 5.4293e-05,\n",
       "            2.2390e-06, 1.3700e-04, 7.9862e-06, 1.1063e-05, 5.8580e-05, 9.6227e-05,\n",
       "            6.3557e-05, 1.3462e-05, 2.5083e-06, 2.5119e-05, 1.3825e-04, 1.1618e-04,\n",
       "            9.0638e-05, 8.3314e-05, 8.1858e-05, 1.2878e-04, 8.1135e-05, 9.9676e-05,\n",
       "            3.5314e-05, 6.7617e-05, 8.4782e-05, 8.3218e-05, 9.3113e-05, 1.2908e-04,\n",
       "            1.5424e-04, 7.9308e-05, 9.8313e-05, 1.7210e-05, 4.6000e-05, 7.5991e-05,\n",
       "            1.7833e-04, 2.7065e-05, 5.0436e-05, 9.9683e-05, 9.0806e-07, 1.2647e-04,\n",
       "            8.1691e-05, 3.2468e-05, 8.7241e-05, 6.2170e-05, 1.1193e-04, 1.3358e-04,\n",
       "            6.9983e-05, 9.5396e-05, 6.6672e-07, 9.6784e-05, 1.3341e-04, 2.0618e-04,\n",
       "            9.0479e-06, 1.3128e-05, 5.3490e-06, 8.0101e-07, 1.3270e-04, 2.6052e-05,\n",
       "            2.7005e-06, 4.1604e-06, 1.0372e-04, 7.8475e-05])},\n",
       "   2: {'step': 1200,\n",
       "    'square_avg': tensor([[2.4625e-08, 1.4805e-08, 1.9834e-08,  ..., 6.6611e-08, 1.3293e-08,\n",
       "             1.8643e-08],\n",
       "            [4.8453e-08, 2.8436e-08, 3.9037e-08,  ..., 1.3140e-07, 2.6074e-08,\n",
       "             3.4651e-08],\n",
       "            [2.7116e-08, 1.6659e-08, 2.1963e-08,  ..., 7.4695e-08, 1.4613e-08,\n",
       "             2.2963e-08],\n",
       "            ...,\n",
       "            [4.8875e-08, 2.9068e-08, 3.9335e-08,  ..., 1.3150e-07, 2.6369e-08,\n",
       "             3.5381e-08],\n",
       "            [4.8056e-08, 2.8599e-08, 3.8657e-08,  ..., 1.2967e-07, 2.5912e-08,\n",
       "             3.4955e-08],\n",
       "            [1.8079e-08, 1.1114e-08, 1.4700e-08,  ..., 4.9864e-08, 9.7704e-09,\n",
       "             1.5570e-08]])},\n",
       "   3: {'step': 1200,\n",
       "    'square_avg': tensor([2.7286e-06, 5.3058e-06, 3.0595e-06, 2.0257e-06, 2.4174e-06, 2.2417e-06,\n",
       "            1.8934e-06, 4.3629e-06, 4.9115e-06, 5.6963e-06, 2.5075e-06, 5.3937e-06,\n",
       "            2.7757e-06, 5.1523e-06, 1.9011e-06, 3.6731e-06, 4.9997e-06, 3.8578e-06,\n",
       "            2.3988e-06, 4.8215e-06, 3.0843e-06, 4.0546e-06, 3.0487e-06, 2.8064e-06,\n",
       "            3.2076e-06, 4.6842e-06, 4.4919e-06, 2.2898e-06, 3.0647e-06, 5.2490e-06,\n",
       "            3.5400e-06, 3.7723e-06, 3.9927e-06, 3.7194e-06, 3.1528e-06, 4.4764e-06,\n",
       "            3.5614e-06, 3.2924e-06, 3.4007e-06, 2.9058e-06, 1.7109e-06, 2.2564e-06,\n",
       "            6.4982e-07, 3.1645e-06, 3.6129e-06, 4.3670e-06, 3.0258e-06, 3.2031e-06,\n",
       "            3.1245e-06, 4.1530e-06, 3.2139e-06, 2.4725e-06, 3.2067e-06, 4.6086e-06,\n",
       "            4.9207e-06, 4.9378e-06, 4.9713e-06, 5.4207e-06, 5.3214e-06, 3.9218e-06,\n",
       "            3.3665e-06, 5.3765e-06, 5.2736e-06, 2.0981e-06])},\n",
       "   4: {'step': 1200,\n",
       "    'square_avg': tensor([[1.6322e-09, 5.8189e-08, 3.6625e-09, 1.7144e-07],\n",
       "            [5.1333e-09, 2.0832e-07, 1.1192e-08, 6.0141e-07],\n",
       "            [1.7612e-09, 7.3705e-08, 4.1584e-09, 2.1978e-07],\n",
       "            [3.1681e-09, 1.3831e-07, 7.4594e-09, 4.0830e-07],\n",
       "            [1.7823e-10, 2.1670e-09, 1.9974e-10, 4.2108e-09],\n",
       "            [1.2244e-09, 3.4516e-08, 2.1852e-09, 9.4105e-08],\n",
       "            [4.9988e-10, 9.9963e-09, 7.3436e-10, 2.5383e-08],\n",
       "            [5.2069e-10, 1.1660e-08, 9.3967e-10, 3.2177e-08],\n",
       "            [6.6709e-10, 1.6668e-08, 1.1875e-09, 4.5773e-08],\n",
       "            [3.1073e-09, 1.1233e-07, 6.4118e-09, 3.2154e-07],\n",
       "            [7.7604e-10, 2.0541e-08, 1.6051e-09, 5.9531e-08],\n",
       "            [4.7156e-11, 2.1834e-09, 9.2727e-11, 5.5447e-09],\n",
       "            [1.6137e-09, 5.2064e-08, 3.2157e-09, 1.4819e-07],\n",
       "            [5.3049e-09, 2.2284e-07, 1.2111e-08, 6.5294e-07],\n",
       "            [8.1745e-09, 3.7556e-07, 1.8752e-08, 1.0901e-06],\n",
       "            [4.0461e-10, 7.1126e-09, 7.9222e-10, 2.0970e-08],\n",
       "            [7.0641e-09, 2.8396e-07, 1.6165e-08, 8.4006e-07],\n",
       "            [2.7291e-10, 2.8973e-09, 2.8841e-10, 5.5532e-09],\n",
       "            [5.4815e-10, 1.1731e-08, 9.6413e-10, 3.2196e-08],\n",
       "            [4.0922e-09, 1.4633e-07, 8.1403e-09, 4.1178e-07],\n",
       "            [6.3942e-09, 2.6058e-07, 1.3584e-08, 7.4497e-07],\n",
       "            [2.9344e-09, 9.7532e-08, 6.6497e-09, 2.9448e-07],\n",
       "            [3.8116e-09, 1.4616e-07, 8.3208e-09, 4.2880e-07],\n",
       "            [2.5857e-09, 1.0881e-07, 5.3643e-09, 3.0402e-07],\n",
       "            [1.5610e-09, 4.7180e-08, 2.9825e-09, 1.3221e-07],\n",
       "            [1.1238e-10, 2.1385e-09, 1.5991e-10, 4.8784e-09],\n",
       "            [1.4955e-09, 3.5022e-08, 2.5467e-09, 9.7132e-08],\n",
       "            [2.4622e-09, 8.8612e-08, 5.5200e-09, 2.6173e-07],\n",
       "            [3.2975e-10, 6.4902e-09, 4.8642e-10, 1.5884e-08],\n",
       "            [2.5605e-10, 9.6677e-09, 4.5315e-10, 2.6899e-08],\n",
       "            [1.1073e-09, 2.5623e-08, 2.1185e-09, 7.3689e-08],\n",
       "            [8.2513e-09, 3.6780e-07, 1.8700e-08, 1.0663e-06],\n",
       "            [4.0380e-10, 5.3095e-09, 3.6741e-10, 1.0495e-08],\n",
       "            [4.6610e-10, 8.5636e-09, 7.1220e-10, 2.1608e-08],\n",
       "            [4.0644e-10, 5.8280e-09, 4.7534e-10, 1.2594e-08],\n",
       "            [1.1000e-10, 1.3585e-09, 1.7110e-10, 2.9278e-09],\n",
       "            [2.4551e-10, 3.2751e-09, 3.4889e-10, 7.3283e-09],\n",
       "            [8.8785e-09, 3.9697e-07, 2.0055e-08, 1.1498e-06],\n",
       "            [5.7436e-09, 2.3967e-07, 1.2729e-08, 6.9573e-07],\n",
       "            [2.4915e-10, 3.4228e-09, 2.5087e-10, 6.8230e-09],\n",
       "            [1.1393e-08, 4.9238e-07, 2.5418e-08, 1.4255e-06],\n",
       "            [8.3877e-09, 3.4266e-07, 1.9138e-08, 1.0138e-06],\n",
       "            [7.5239e-10, 1.8068e-08, 1.6391e-09, 5.5075e-08],\n",
       "            [2.0357e-10, 2.0101e-09, 2.1433e-10, 3.7019e-09],\n",
       "            [4.8029e-09, 2.0517e-07, 1.0633e-08, 5.9333e-07],\n",
       "            [7.4986e-10, 2.5082e-08, 1.3765e-09, 6.7547e-08],\n",
       "            [9.0298e-10, 1.9156e-08, 1.7781e-09, 5.6931e-08],\n",
       "            [3.7952e-09, 1.5309e-07, 8.1124e-09, 4.3860e-07],\n",
       "            [5.5745e-10, 1.5131e-08, 1.0031e-09, 4.0628e-08],\n",
       "            [8.2845e-10, 2.0943e-08, 1.4959e-09, 5.8637e-08],\n",
       "            [3.5024e-09, 1.5206e-07, 7.9712e-09, 4.4347e-07],\n",
       "            [5.8962e-09, 2.3676e-07, 1.3118e-08, 6.9294e-07],\n",
       "            [7.1528e-09, 2.9500e-07, 1.6373e-08, 8.6835e-07],\n",
       "            [1.1800e-09, 3.6135e-08, 2.3118e-09, 1.0230e-07],\n",
       "            [8.3279e-11, 1.0463e-09, 1.3771e-10, 2.3803e-09],\n",
       "            [5.0671e-09, 2.2778e-07, 1.1411e-08, 6.5774e-07],\n",
       "            [4.7603e-09, 1.8966e-07, 1.0976e-08, 5.6343e-07],\n",
       "            [5.0796e-10, 7.5429e-09, 6.8204e-10, 1.7791e-08],\n",
       "            [2.1625e-10, 3.7540e-09, 4.3170e-10, 1.0330e-08],\n",
       "            [6.7849e-11, 2.2530e-09, 1.2915e-10, 5.7519e-09],\n",
       "            [1.6609e-09, 5.9018e-08, 3.4056e-09, 1.6739e-07],\n",
       "            [5.9046e-10, 8.7308e-09, 8.4274e-10, 2.1848e-08],\n",
       "            [1.8826e-09, 5.1929e-08, 3.7477e-09, 1.5186e-07],\n",
       "            [1.5915e-10, 2.1189e-09, 1.4602e-10, 4.2895e-09]])},\n",
       "   5: {'step': 1200,\n",
       "    'square_avg': tensor([2.8867e-07, 8.7338e-07, 2.6420e-07, 5.0177e-07, 5.3012e-08, 2.6073e-07,\n",
       "            1.2615e-07, 1.2238e-07, 1.6333e-07, 5.3918e-07, 1.6085e-07, 1.2197e-08,\n",
       "            3.0922e-07, 8.3472e-07, 1.2253e-06, 9.1216e-08, 1.1455e-06, 7.1849e-08,\n",
       "            1.3481e-07, 7.2442e-07, 1.0547e-06, 5.0513e-07, 6.1578e-07, 4.6217e-07,\n",
       "            3.0545e-07, 3.6772e-08, 2.9625e-07, 4.3071e-07, 9.2169e-08, 4.8247e-08,\n",
       "            2.3582e-07, 1.3098e-06, 1.0457e-07, 1.2398e-07, 1.0788e-07, 4.0173e-08,\n",
       "            8.0436e-08, 1.3492e-06, 9.2703e-07, 7.0176e-08, 1.7505e-06, 1.2740e-06,\n",
       "            1.5092e-07, 5.4674e-08, 7.8587e-07, 1.7409e-07, 1.9069e-07, 6.3053e-07,\n",
       "            1.4224e-07, 1.7359e-07, 5.4617e-07, 9.6410e-07, 1.1061e-06, 2.4593e-07,\n",
       "            2.7147e-08, 7.7853e-07, 7.5393e-07, 1.3782e-07, 6.3876e-08, 2.1843e-08,\n",
       "            3.1536e-07, 1.4791e-07, 3.6207e-07, 4.4420e-08])},\n",
       "   6: {'step': 1200,\n",
       "    'square_avg': tensor([[5.1451e-11, 3.3641e-11, 4.3701e-11,  ..., 3.8537e-11, 3.9321e-11,\n",
       "             8.3607e-11],\n",
       "            [4.8116e-10, 2.0750e-10, 4.7580e-10,  ..., 3.9884e-10, 3.5764e-10,\n",
       "             1.0365e-09],\n",
       "            [1.2039e-11, 1.2104e-11, 9.6362e-12,  ..., 1.0276e-11, 1.0937e-11,\n",
       "             1.4809e-11],\n",
       "            ...,\n",
       "            [4.9159e-11, 4.0043e-11, 4.4661e-11,  ..., 3.8487e-11, 4.0027e-11,\n",
       "             7.3749e-11],\n",
       "            [8.7508e-11, 6.5435e-11, 7.1169e-11,  ..., 6.7141e-11, 7.0163e-11,\n",
       "             1.2811e-10],\n",
       "            [3.2333e-10, 7.8561e-11, 3.3090e-10,  ..., 3.0614e-10, 2.4328e-10,\n",
       "             8.1497e-10]])},\n",
       "   7: {'step': 1200,\n",
       "    'square_avg': tensor([1.8110e-09, 9.1466e-09, 3.8817e-10, 4.6143e-09, 2.8031e-09, 9.6721e-10,\n",
       "            2.1853e-07, 4.4714e-09, 2.0145e-09, 3.9069e-07, 1.5941e-09, 1.8370e-09,\n",
       "            5.0126e-10, 6.1804e-09, 2.6574e-07, 3.9158e-10, 1.7298e-09, 1.0913e-09,\n",
       "            2.5522e-09, 2.0642e-09, 4.5303e-10, 3.4529e-10, 2.2217e-07, 5.3363e-10,\n",
       "            1.0514e-07, 2.7104e-08, 1.6533e-09, 1.1892e-10, 2.8228e-10, 3.0526e-08,\n",
       "            1.0375e-09, 7.1342e-09, 2.9429e-10, 3.3272e-09, 5.9391e-09, 1.9632e-09,\n",
       "            2.0921e-08, 3.3348e-09, 1.2380e-09, 2.6467e-09, 1.4397e-09, 6.4905e-09,\n",
       "            3.2258e-09, 1.4412e-09, 4.9238e-10, 4.3228e-09, 2.2850e-09, 3.7574e-10,\n",
       "            1.0465e-09, 3.8910e-09, 3.2476e-07, 4.8366e-09, 4.9504e-09, 7.3034e-09,\n",
       "            2.8508e-10, 3.6707e-10, 1.0115e-09, 5.4069e-09, 8.6181e-10, 1.8184e-10,\n",
       "            1.2025e-09, 2.0918e-09, 3.1963e-09, 2.8604e-09])},\n",
       "   8: {'step': 1200,\n",
       "    'square_avg': tensor([[2.0835e-06, 1.6217e-06, 2.9651e-06, 3.1129e-06, 1.9811e-06, 4.1288e-06,\n",
       "             4.2890e-06, 2.3854e-06, 1.9872e-06, 1.7031e-06, 4.9303e-06, 1.9194e-06,\n",
       "             2.6310e-06, 1.6820e-06, 3.5049e-06, 3.0191e-06, 2.2657e-06, 2.4904e-06,\n",
       "             2.9090e-06, 1.8818e-06, 5.3261e-06, 1.1573e-06, 7.1832e-06, 3.0002e-06,\n",
       "             3.2025e-06, 1.3709e-06, 2.4281e-06, 4.2647e-06, 5.2500e-06, 1.9272e-06,\n",
       "             2.0977e-06, 4.1477e-06, 3.4892e-06, 1.3374e-06, 3.7477e-06, 2.4120e-06,\n",
       "             2.2052e-06, 1.7922e-06, 4.9778e-06, 3.4233e-06, 3.6711e-06, 1.5535e-06,\n",
       "             1.0085e-06, 5.7218e-06, 8.2214e-07, 1.3389e-06, 3.4047e-06, 1.8088e-06,\n",
       "             2.1816e-06, 2.4133e-06, 2.0724e-06, 8.3237e-07, 1.3133e-06, 1.2257e-06,\n",
       "             1.7973e-06, 1.8461e-06, 1.6816e-06, 2.1499e-06, 2.1160e-06, 4.1000e-06,\n",
       "             3.1757e-06, 1.9043e-06, 1.6750e-06, 2.2750e-06],\n",
       "            [2.0835e-06, 1.6217e-06, 2.9651e-06, 3.1129e-06, 1.9811e-06, 4.1288e-06,\n",
       "             4.2890e-06, 2.3854e-06, 1.9872e-06, 1.7031e-06, 4.9303e-06, 1.9194e-06,\n",
       "             2.6310e-06, 1.6820e-06, 3.5049e-06, 3.0191e-06, 2.2657e-06, 2.4904e-06,\n",
       "             2.9090e-06, 1.8818e-06, 5.3261e-06, 1.1573e-06, 7.1832e-06, 3.0002e-06,\n",
       "             3.2025e-06, 1.3709e-06, 2.4281e-06, 4.2647e-06, 5.2500e-06, 1.9272e-06,\n",
       "             2.0977e-06, 4.1477e-06, 3.4892e-06, 1.3374e-06, 3.7477e-06, 2.4120e-06,\n",
       "             2.2052e-06, 1.7922e-06, 4.9778e-06, 3.4233e-06, 3.6711e-06, 1.5535e-06,\n",
       "             1.0085e-06, 5.7218e-06, 8.2214e-07, 1.3389e-06, 3.4047e-06, 1.8088e-06,\n",
       "             2.1816e-06, 2.4133e-06, 2.0724e-06, 8.3237e-07, 1.3133e-06, 1.2257e-06,\n",
       "             1.7973e-06, 1.8461e-06, 1.6816e-06, 2.1499e-06, 2.1160e-06, 4.1000e-06,\n",
       "             3.1757e-06, 1.9043e-06, 1.6750e-06, 2.2750e-06]])},\n",
       "   9: {'step': 1200, 'square_avg': tensor([0.0001, 0.0001])},\n",
       "   10: {'step': 1200,\n",
       "    'square_avg': tensor([[0.0037, 0.0037, 0.0037, 0.0037, 0.0037, 0.0037, 0.0037, 0.0037, 0.0037,\n",
       "             0.0037, 0.0037, 0.0037, 0.0037, 0.0037, 0.0037, 0.0037, 0.0037, 0.0037,\n",
       "             0.0037, 0.0037, 0.0037, 0.0037, 0.0037, 0.0037, 0.0037, 0.0037, 0.0037,\n",
       "             0.0037, 0.0037, 0.0037, 0.0037, 0.0037, 0.0037, 0.0037, 0.0037, 0.0037,\n",
       "             0.0037, 0.0037, 0.0037, 0.0037, 0.0037, 0.0037, 0.0037, 0.0037, 0.0037,\n",
       "             0.0037, 0.0037, 0.0037, 0.0037, 0.0037, 0.0037, 0.0037, 0.0037, 0.0037,\n",
       "             0.0037, 0.0037, 0.0037, 0.0037, 0.0037, 0.0037, 0.0037, 0.0037, 0.0037,\n",
       "             0.0037]])},\n",
       "   11: {'step': 1200, 'square_avg': tensor([0.0037])}},\n",
       "  'param_groups': [{'lr': 0.0007,\n",
       "    'momentum': 0,\n",
       "    'alpha': 0.99,\n",
       "    'eps': 1e-05,\n",
       "    'centered': False,\n",
       "    'weight_decay': 0,\n",
       "    'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('a2c_lunar_singleproc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Object of type Tensor is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_172712/2579705099.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'a2c_lunar_singleproc.json'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.miniconda3/envs/pydrl/lib/python3.7/json/__init__.py\u001b[0m in \u001b[0;36mdump\u001b[0;34m(obj, fp, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0;31m# could accelerate with writelines in some versions of Python, at\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;31m# a debuggability cost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m         \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/pydrl/lib/python3.7/json/encoder.py\u001b[0m in \u001b[0;36m_iterencode\u001b[0;34m(o, _current_indent_level)\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m_iterencode_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 431\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m_iterencode_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmarkers\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/pydrl/lib/python3.7/json/encoder.py\u001b[0m in \u001b[0;36m_iterencode_dict\u001b[0;34m(dct, _current_indent_level)\u001b[0m\n\u001b[1;32m    403\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m                     \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mchunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    406\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnewline_indent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m             \u001b[0m_current_indent_level\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/pydrl/lib/python3.7/json/encoder.py\u001b[0m in \u001b[0;36m_iterencode_dict\u001b[0;34m(dct, _current_indent_level)\u001b[0m\n\u001b[1;32m    403\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m                     \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mchunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    406\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnewline_indent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m             \u001b[0m_current_indent_level\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/pydrl/lib/python3.7/json/encoder.py\u001b[0m in \u001b[0;36m_iterencode_dict\u001b[0;34m(dct, _current_indent_level)\u001b[0m\n\u001b[1;32m    403\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m                     \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mchunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    406\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnewline_indent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m             \u001b[0m_current_indent_level\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/pydrl/lib/python3.7/json/encoder.py\u001b[0m in \u001b[0;36m_iterencode_dict\u001b[0;34m(dct, _current_indent_level)\u001b[0m\n\u001b[1;32m    403\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m                     \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mchunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    406\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnewline_indent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m             \u001b[0m_current_indent_level\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/pydrl/lib/python3.7/json/encoder.py\u001b[0m in \u001b[0;36m_iterencode\u001b[0;34m(o, _current_indent_level)\u001b[0m\n\u001b[1;32m    436\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Circular reference detected\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m                 \u001b[0mmarkers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmarkerid\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m             \u001b[0mo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmarkers\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/pydrl/lib/python3.7/json/encoder.py\u001b[0m in \u001b[0;36mdefault\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \"\"\"\n\u001b[0;32m--> 179\u001b[0;31m         raise TypeError(f'Object of type {o.__class__.__name__} '\n\u001b[0m\u001b[1;32m    180\u001b[0m                         f'is not JSON serializable')\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Object of type Tensor is not JSON serializable"
     ]
    }
   ],
   "source": [
    "# Exporting Params as JSON\n",
    "## Function to Convert Params Dict to Flattened List\n",
    "def flatten_list(params):\n",
    "    \"\"\"\n",
    "    :param params: (dict)\n",
    "    :return: (np.ndarray)\n",
    "    \"\"\"\n",
    "    params_ = {}\n",
    "    for key in params.keys():\n",
    "        params_[key] = params[key].tolist()\n",
    "    return params_\n",
    "## Write Parameters to JSON File\n",
    "import json\n",
    "\n",
    "all_params = model.get_parameters()\n",
    "pol_params = flatten_list(all_params['policy'])\n",
    "\n",
    "all_params['policy'] = pol_params\n",
    "\n",
    "with open('a2c_lunar_singleproc.json', 'w') as f:\n",
    "    json.dump(all_params, f, indent='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_loaded = ALGO(\n",
    "    \"MlpPolicy\",\n",
    "    env\n",
    ")\n",
    "\n",
    "evaluate(model_loaded,env, verbose=1)\n",
    "\n",
    "new_params = all_params\n",
    "loaded_pol_params = new_params['policy']\n",
    "for key in loaded_pol_params.keys():\n",
    "    loaded_pol_params[key] = th.tensor(loaded_pol_params[key])\n",
    "\n",
    "new_params['policy'] = loaded_pol_params\n",
    "\n",
    "model_loaded.set_parameters(new_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()\n",
    "evaluate(model_loaded,env, verbose=1)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3fe87c7677a9be80aab770929aa8f3d40850ac08a0f73ec246342c77c48f1c11"
  },
  "kernelspec": {
   "display_name": "Python 3.7.2 64-bit ('pydrl': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
