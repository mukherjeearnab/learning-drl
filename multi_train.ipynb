{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi Train Gradient Update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "import threading\n",
    "\n",
    "import gym\n",
    "import numpy as np\n",
    "import torch as th\n",
    "\n",
    "from stable_baselines3 import A2C as ALGO\n",
    "from stable_baselines3.common.evaluation import evaluate_policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init. ENV and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('LunarLander-v2')\n",
    "model = ALGO(\n",
    "    \"MlpPolicy\",\n",
    "    env\n",
    ")\n",
    "\n",
    "model_trained_1 = ALGO(\n",
    "    \"MlpPolicy\",\n",
    "    env\n",
    ")\n",
    "\n",
    "model_trained_2 = ALGO(\n",
    "    \"MlpPolicy\",\n",
    "    env\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to Evaluate Model and Train Model within Thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, env, message = '', verbose = 0):\n",
    "    fitnesses = []\n",
    "    iterations = 10\n",
    "    for i in range(iterations):\n",
    "        fitness, _ = evaluate_policy(model, env)\n",
    "        if verbose == 1:\n",
    "            print(i, fitness, end=\" \")\n",
    "        fitnesses.append(fitness)\n",
    "\n",
    "    mean_fitness = np.mean(sorted(fitnesses))\n",
    "    print(f'Type {message} Mean reward: {mean_fitness}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, timesteps):\n",
    "    print('Starting Training')\n",
    "    model.learn(total_timesteps=timesteps)\n",
    "    print('Completed Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arnab/.miniconda3/envs/pydrl/lib/python3.7/site-packages/stable_baselines3/common/evaluation.py:69: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  UserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type  Mean reward: -431.4619080990739\n",
      "Type  Mean reward: -445.2882938029006\n",
      "Type  Mean reward: -494.61938431913507\n"
     ]
    }
   ],
   "source": [
    "evaluate(model, env)\n",
    "evaluate(model_trained_1, env)\n",
    "evaluate(model_trained_2, env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train for 1K Steps and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training\n",
      "Starting Training\n",
      "Completed Training\n",
      "Completed Training\n",
      "Type  Mean reward: -962.1624753702479\n",
      "Type  Mean reward: -817.9836377596282\n",
      "Type  Mean reward: -445.4719514189521\n"
     ]
    }
   ],
   "source": [
    "# Train MT Model 1\n",
    "t1 = threading.Thread(target=train, args=(model_trained_1, 10_00))\n",
    "\n",
    "# Train MT Model 2\n",
    "t2 = threading.Thread(target=train, args=(model_trained_2, 10_00))\n",
    "\n",
    "# starting thread\n",
    "t1.start()\n",
    "t2.start()\n",
    "\n",
    "# wait until thread is completely executed\n",
    "t1.join()\n",
    "t2.join()\n",
    "\n",
    "\n",
    "# model_trained.learn(total_timesteps=10_00)\n",
    "evaluate(model_trained_1, env)\n",
    "evaluate(model_trained_2, env)\n",
    "evaluate(model, env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Gradient and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arnab/.miniconda3/envs/pydrl/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1025.)\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type  Mean reward: -1013.8730055048061\n"
     ]
    }
   ],
   "source": [
    "# For Trained Model 1\n",
    "state_dict = model.policy.state_dict()\n",
    "optim_dict = model_trained_1.policy.optimizer.param_groups[0]['params']\n",
    "optim_alpha = model.policy.optimizer.param_groups[0]['alpha']\n",
    "\n",
    "optim_index = 0\n",
    "for key, value in state_dict.items():\n",
    "    # print(key)\n",
    "    state_dict[key].add_(optim_alpha, optim_dict[optim_index])\n",
    "    optim_index += 1\n",
    "\n",
    "model.policy.load_state_dict(state_dict)\n",
    "\n",
    "# For Trained Model 2\n",
    "state_dict = model.policy.state_dict()\n",
    "optim_dict = model_trained_2.policy.optimizer.param_groups[0]['params']\n",
    "optim_alpha = model.policy.optimizer.param_groups[0]['alpha']\n",
    "\n",
    "optim_index = 0\n",
    "for key, value in state_dict.items():\n",
    "    # print(key)\n",
    "    state_dict[key].add_(optim_alpha, optim_dict[optim_index])\n",
    "    optim_index += 1\n",
    "\n",
    "model.policy.load_state_dict(state_dict)\n",
    "\n",
    "\n",
    "evaluate(model, env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Iter:  0\n",
      "Starting Training\n",
      "Starting Training\n",
      "Completed Training\n",
      "Completed Training\n",
      "0 -2660.270971801644 1 -2783.74361298015 2 -2662.3348019203054 3 -2427.2091898242943 4 -2229.277876516305 5 -2523.3956706062395 6 -2359.949037573987 7 -2421.1822055381954 8 -2294.029686663032 9 -2506.892941570854 Type Trained Model 1 Mean reward: -2486.8285994995003\n",
      "0 -8.624941579909114 1 -9.18273109467118 2 -23.07342647242058 3 24.531086154386866 4 26.956538421118456 5 -32.537770424538756 6 30.356180476475856 7 9.369339340706938 8 -65.73432079327176 9 36.801928885414235 Type Trained Model 2 Mean reward: -1.1138117086709065\n",
      "0 -1084.7570516026578 1 -1220.731389884831 2 -934.773939095065 3 -875.3112892461941 4 -766.3548823645339 5 -987.0417992171831 6 -1141.3576850225218 7 -1298.498894039169 8 -1168.9746140966192 9 -1045.324966353603 Type Initial Model Mean reward: -1052.3126510922377\n",
      "0 -369.8592925339064 1 -381.9445559002459 2 -339.2384945921076 3 -312.22853385728087 4 -276.76520256088986 5 -359.2461087589152 6 -351.4956547717855 7 -410.9864271184371 8 -369.7901495817699 9 -290.48589151479825 Type Updated Model Mean reward: -346.2040311190137\n",
      "Train Iter:  1\n",
      "Starting Training\n",
      "Starting Training\n",
      "Completed Training\n",
      "Completed Training\n",
      "0 -36.93856754406909 1 -11.546975872975157 2 -46.24044982028821 3 -2.757035600009027 4 28.549889363564727 5 -43.11563929284089 6 118.04219359260898 7 -29.034571375892078 8 -56.23173751983069 9 35.37945637261752 Type Trained Model 1 Mean reward: -4.389343769711391\n",
      "0 -269.4272669803723 1 -216.04112618498365 2 -44.467734974026754 3 -227.22740045913116 4 -433.01023934302503 5 -181.5373963749124 6 -111.82723239583069 7 -268.72336251646936 8 -375.9161598969715 9 -79.75458910191865 Type Trained Model 2 Mean reward: -220.79325082276415\n",
      "0 -308.8430594974314 1 -343.4420697193418 2 -394.7909514382278 3 -290.23399880530195 4 -334.85312582451735 5 -420.3900381671534 6 -354.4530484985444 7 -364.5717990616657 8 -319.19680801337233 9 -276.09081494702843 Type Initial Model Mean reward: -340.68657139725843\n",
      "0 -21.672292785240245 1 -39.46101844653309 2 -77.88721191631254 3 -209.62955538632232 4 -71.15732397492975 5 -113.66518184991962 6 -100.58740501172335 7 -64.48346200592505 8 -53.49805142448381 9 -72.23319519932917 Type Updated Model Mean reward: -82.42746980007189\n",
      "Train Iter:  2\n",
      "Starting TrainingStarting Training\n",
      "\n",
      "Completed Training\n",
      "Completed Training\n",
      "0 -15.04675439848329 1 -16.337766777006397 2 -18.546423300782834 3 -1.2294114627262929 4 -0.8322517167884087 5 -9.546648063705828 6 -2.7800546411600293 7 -15.949477508376708 8 -13.812178808267356 9 22.650604191017976 Type Trained Model 1 Mean reward: -7.143036248627915\n",
      "0 -168.1513601519342 1 -148.90500122726297 2 -153.32849064401816 3 -93.69023786156295 4 -119.32225422852689 5 -175.28965839000884 6 -129.51173551058454 7 -89.83926782270589 8 -47.72129534647338 9 5.438547626091119 Type Trained Model 2 Mean reward: -112.03207535569868\n",
      "0 -160.49392272491923 1 85.48399645130027 2 -78.43226240572383 3 -33.768346071827224 4 -73.63776978856463 5 -82.81497356259436 6 -103.25869998501221 7 -96.84809921825806 8 -51.655613051769066 9 -69.4239186335283 Type Initial Model Mean reward: -66.48496089908966\n",
      "0 -76.46268169872461 1 -132.26104560073819 2 -3.1999297054528713 3 -52.95586835324648 4 -121.38471260675428 5 -37.612891277284625 6 -110.8228998564988 7 -132.2426538689219 8 -114.01712035981473 9 -136.82370622409508 Type Updated Model Mean reward: -91.77835095515316\n",
      "Train Iter:  3\n",
      "Starting TrainingStarting Training\n",
      "\n",
      "Completed Training\n",
      "Completed Training\n",
      "0 -122.24503256324824 1 -145.84157625318554 2 -141.84938850943038 3 -162.05610709308692 4 -107.61739712678828 5 -50.55149599417727 6 -150.48183209029375 7 -141.1460438739101 8 -164.91806201565487 9 -106.6329257554753 Type Trained Model 1 Mean reward: -129.33398612752507\n",
      "0 -31.348188841681605 1 -26.685623101577896 2 -140.59022222846107 3 -146.43536920940969 4 -139.16176923369056 5 -86.36052635864034 6 -140.96060302814004 7 -67.00130138608947 8 -95.96592677785743 9 -157.20744052639347 Type Trained Model 2 Mean reward: -103.17169706919415\n",
      "0 -128.4680007956048 1 -35.47419086747686 2 -101.36392494774967 3 -75.6911944140351 4 -42.540666343028064 5 -77.67825392893077 6 -58.56033773622518 7 -121.69277343461951 8 -51.36322667873215 9 -63.29027171965227 Type Initial Model Mean reward: -75.61228408660544\n",
      "0 -129.36614818191083 1 -142.08001569825137 2 -90.39431685410673 3 -115.52076478438975 4 -167.65558091041459 5 -137.3754245379183 6 -181.00410771367606 7 -104.09293977313318 8 -124.03859156408453 9 -101.95627862395486 Type Updated Model Mean reward: -129.34841686418403\n",
      "Train Iter:  4\n",
      "Starting Training\n",
      "Starting Training\n",
      "Completed Training\n",
      "Completed Training\n",
      "0 -121.09384641043957 1 -159.69207838790027 2 -140.851708678063 3 -160.53405435275636 4 -97.63074409703614 5 -200.68660046900624 6 -20.180642171388126 7 -125.53530904429249 8 -133.93055329764175 9 -158.24804418401035 Type Trained Model 1 Mean reward: -131.83835810925342\n",
      "0 -130.07211980198045 1 -158.8207684277966 2 -66.91695680101402 3 -157.96377983854327 4 -171.9082507710438 5 -35.18104231543257 6 -145.40508547777426 7 -101.39549688507395 8 -182.68904844246208 9 -175.97778748609107 Type Trained Model 2 Mean reward: -132.6330336247212\n",
      "0 -83.37866525405552 1 -139.15911429692932 2 -115.79224413635674 3 -121.04452987705591 4 -127.11615660160734 5 -48.59546318014704 6 -160.79607389965093 7 -147.24335427865154 8 -124.20867423520758 9 -44.93434610378754 Type Initial Model Mean reward: -111.22686218634495\n",
      "0 -118.85748953328398 1 -66.94205527644927 2 -102.09372993710058 3 -137.44798849693012 4 -111.80676607177585 5 -117.02512621341471 6 -140.98825667656493 7 -153.6488463754882 8 -142.89741937777512 9 -91.64756124191445 Type Updated Model Mean reward: -118.33552392006973\n",
      "Train Iter:  5\n",
      "Starting TrainingStarting Training\n",
      "\n",
      "Completed Training\n",
      "Completed Training\n",
      "0 -151.35445052019787 1 -201.30815299472016 2 -125.42779799616758 3 -160.21955765354068 4 -154.96610356217133 5 -164.85594515665434 6 -110.70025309351331 7 -167.548621678599 8 -147.1359076110326 9 -52.28093110616678 Type Trained Model 1 Mean reward: -143.57977213727634\n",
      "0 -118.1604739079834 1 -110.08543013342481 2 -168.14844057865105 3 -194.0856769277263 4 -80.30854845019057 5 -181.53283867294667 6 -67.70338791909323 7 -103.29262972753494 8 -150.55618611997886 9 -173.7750045816414 Type Trained Model 2 Mean reward: -134.7648617019171\n",
      "0 -146.21403055101035 1 -131.12550527073762 2 -156.40645898001094 3 -135.74294868164057 4 -138.41710470091783 5 39.261245774910265 6 -112.37343680853955 7 -116.66026365577709 8 -115.59220040957734 9 -150.12023372779367 Type Initial Model Mean reward: -116.33909370110946\n",
      "0 -120.01072290560697 1 -159.62557265161013 2 -96.16199048108197 3 -162.9324536626751 4 -207.48786419765673 5 -140.65870324519346 6 -108.08072385352497 7 -168.96869782614522 8 -139.1267920927843 9 -103.80535452895273 Type Updated Model Mean reward: -140.68588754452315\n",
      "Train Iter:  6\n",
      "Starting Training\n",
      "Starting Training\n",
      "Completed Training\n",
      "Completed Training\n",
      "0 -76.80276256975193 1 -108.5043324933271 2 -66.0046591297095 3 -198.08106731007575 4 -21.846510815475106 5 -93.47058090487262 6 -88.19867475536884 7 -58.35396856800976 8 -156.41978326444513 9 -181.24954428928322 Type Trained Model 1 Mean reward: -104.8931884100319\n",
      "0 -180.14460264784867 1 -112.88156935127918 2 -37.46007890354376 3 -156.6451652464304 4 -148.37686738622725 5 -211.69388827488874 6 -119.40011990964413 7 -156.01829610104613 8 -130.3481558098778 9 -138.41121411305213 Type Trained Model 2 Mean reward: -139.13799577438382\n",
      "0 -101.16968611610355 1 -184.8267166173784 2 -126.45357840743964 3 -177.71798017560505 4 -207.10858446194325 5 -120.71526735952357 6 -202.27059212652966 7 -150.7385069412645 8 -162.11880180652952 9 -61.466514104016326 Type Initial Model Mean reward: -149.45862281163335\n",
      "0 -212.4817422571592 1 -115.53677917469633 2 -101.52494752510684 3 -142.37364347536058 4 -88.3510053166495 5 -84.02391190172237 6 -139.05085164799235 7 -205.23098111064755 8 -161.1230772830808 9 -158.94841036528524 Type Updated Model Mean reward: -140.86453500577005\n",
      "Train Iter:  7\n",
      "Starting Training\n",
      "Starting Training\n",
      "Completed Training\n",
      "Completed Training\n",
      "0 -165.13191665458726 1 -177.5215531170601 2 -103.49957038647025 3 -91.28386944788036 4 -83.91215656361003 5 -103.87760094158584 6 -117.411494152667 7 -191.10406673646065 8 -134.49804581713397 9 -159.18956965084652 Type Trained Model 1 Mean reward: -132.74298434683018\n",
      "0 -58.47300532132501 1 -127.56789310709573 2 -150.30301678772668 3 -144.1822520764894 4 -127.67015058162579 5 -176.8134025520063 6 -50.82078171055041 7 -153.47826596410013 8 -118.0164618618926 9 -107.14514605164027 Type Trained Model 2 Mean reward: -121.44703760144523\n",
      "0 -158.43253698981135 1 -107.07097665753099 2 -112.23843742922182 3 -174.44972542658797 4 -128.4689213703548 5 -152.63325843589845 6 -122.29552972616966 7 -109.93567941801157 8 -109.67221972342406 9 -108.48605638085864 Type Initial Model Mean reward: -128.36833415578695\n",
      "0 -103.89545789029258 1 -179.60625886278575 2 -146.92190701690416 3 -109.93390506558936 4 -103.27689231557486 5 -135.9992379199437 6 -141.34516537312885 7 -174.84551806493837 8 -99.61075731247547 9 -130.7864500470605 Type Updated Model Mean reward: -132.62215498686936\n",
      "Train Iter:  8\n",
      "Starting TrainingStarting Training\n",
      "\n",
      "Completed Training\n",
      "Completed Training\n",
      "0 -180.97452343596814 1 -107.30639150534675 2 -162.42172446848127 3 -137.34542322964407 4 -175.39704754236155 5 -162.00618217700975 6 -116.0847435945645 7 -138.6278532420576 8 -149.0258023288916 9 -143.5372978635365 Type Trained Model 1 Mean reward: -147.27269893878616\n",
      "0 -179.7408552086068 1 -121.44442136435232 2 -170.56060458549763 3 -161.26034450919832 4 -136.92359683723188 5 -123.64910454220953 6 -171.3576736854855 7 -114.5577000819845 8 -114.746017588527 9 -148.55089828962954 Type Trained Model 2 Mean reward: -144.27912166927229\n",
      "0 -203.0836521623947 1 -173.31982681816444 2 -207.6987622417859 3 -100.96574813035258 4 -81.13479839513708 5 -163.4361458710405 6 -100.11411158444244 7 -104.65442019344773 8 -134.2283581259253 9 -114.86825791923984 Type Initial Model Mean reward: -138.35040814419307\n",
      "0 -177.06975069002948 1 -157.276911562954 2 -169.08790429004003 3 -107.95709612368955 4 -128.03214429332874 5 -117.36459688693284 6 -135.5895479306433 7 -156.47167885799718 8 -82.37983758718674 9 -139.62622829743137 Type Updated Model Mean reward: -137.08556965202334\n",
      "Train Iter:  9\n",
      "Starting TrainingStarting Training\n",
      "\n",
      "Completed Training\n",
      "Completed Training\n",
      "0 -185.89637277168222 1 -154.65186270334235 2 -71.99553825122385 3 -120.34858119459822 4 -162.58186636560131 5 -129.40900998904834 6 -57.08453795925266 7 -112.88519094228104 8 -78.15775688162928 9 -147.33895714506508 Type Trained Model 1 Mean reward: -122.03496742037244\n",
      "0 -122.08547456994566 1 -175.11310823895036 2 -60.531511671693444 3 -100.66128056190792 4 -126.0760810625945 5 -137.44667893126606 6 -86.80333136759582 7 -95.05994021762224 8 -124.46101406615344 9 -169.04705100105033 Type Trained Model 2 Mean reward: -119.72854716887795\n",
      "0 -108.12194039749447 1 -149.64152870515827 2 -113.45625446655322 3 -103.15199390219932 4 -144.75672452958534 5 -180.95185589685497 6 -143.56383142312401 7 -127.49227706075763 8 -144.81553339888197 9 -202.43205321036658 Type Initial Model Mean reward: -141.8383992990976\n",
      "0 -123.55602152084975 1 -178.2390928739216 2 -130.29508433270675 3 -165.00624838547083 4 -142.08411295623517 5 -184.7605310936473 6 -110.36640528100543 7 -157.53501515488605 8 -192.64743616654306 9 -81.88644582351569 Type Updated Model Mean reward: -146.63763935887818\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print('Train Iter: ', i)\n",
    "\n",
    "    # Train MT Model 1\n",
    "    t1 = threading.Thread(target=train, args=(model_trained_1, 10_000))\n",
    "\n",
    "    # Train MT Model 2\n",
    "    t2 = threading.Thread(target=train, args=(model_trained_2, 10_000))\n",
    "\n",
    "    # starting thread\n",
    "    t1.start()\n",
    "    t2.start()\n",
    "\n",
    "    # wait until thread is completely executed\n",
    "    t1.join()\n",
    "    t2.join()\n",
    "\n",
    "    evaluate(model_trained_1, env, 'Trained Model 1', verbose=1)\n",
    "    evaluate(model_trained_2, env, 'Trained Model 2', verbose=1)\n",
    "    evaluate(model, env, 'Initial Model', verbose=1)\n",
    "\n",
    "    # For Trained Model 1\n",
    "    state_dict = model.policy.state_dict()\n",
    "    optim_dict = model_trained_1.policy.optimizer.param_groups[0]['params']\n",
    "    optim_alpha = model_trained_1.policy.optimizer.param_groups[0]['alpha']\n",
    "\n",
    "    optim_index = 0\n",
    "    for key, value in state_dict.items():\n",
    "        # print(key)\n",
    "        state_dict[key].add_(optim_alpha, optim_dict[optim_index])\n",
    "        optim_index += 1\n",
    "\n",
    "    model.policy.load_state_dict(state_dict)\n",
    "\n",
    "    # For Trained Model 2\n",
    "    state_dict = model.policy.state_dict()\n",
    "    optim_dict = model_trained_2.policy.optimizer.param_groups[0]['params']\n",
    "    optim_alpha = model_trained_2.policy.optimizer.param_groups[0]['alpha']\n",
    "\n",
    "    optim_index = 0\n",
    "    for key, value in state_dict.items():\n",
    "        # print(key)\n",
    "        state_dict[key].add_(optim_alpha, optim_dict[optim_index])\n",
    "        optim_index += 1\n",
    "\n",
    "    model_trained_1.policy.load_state_dict(state_dict)\n",
    "    model_trained_2.policy.load_state_dict(state_dict)\n",
    "    model.policy.load_state_dict(state_dict)\n",
    "\n",
    "\n",
    "    evaluate(model, env, 'Updated Model', verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'policy': OrderedDict([('mlp_extractor.policy_net.0.weight',\n",
       "               tensor([[-22362.0977,  -3081.3545,    801.2779,   6870.6895, -10768.9414,\n",
       "                          -276.7640,   4536.3721,   5394.2510],\n",
       "                       [ -6643.8032,   2509.6279,  -6237.9946,  -2613.2415,   -615.9299,\n",
       "                          3988.4851, -12677.0488,  -9107.0986],\n",
       "                       [  -524.6043, -16094.4893,  -5325.1270, -15252.5635,   6950.4927,\n",
       "                         10159.3105, -16265.6152, -13284.9775],\n",
       "                       [ 23559.7441, -10320.5479,  -5160.8179,   -944.0709,   7477.3643,\n",
       "                         -1309.9873,   3617.0942,  -9305.7334],\n",
       "                       [   379.7978,  13770.9600,  -4300.2817, -38598.3164,   -639.1262,\n",
       "                         -3667.5242,   1559.7115,   8702.4121],\n",
       "                       [-14291.5508,  -2079.0923,  -4034.8157,   1173.3798,  17696.5879,\n",
       "                         10375.6104,  -1698.8304,   7390.4360],\n",
       "                       [  1827.3058,   3508.0581,  -3300.0039,  13626.2334,  -7139.8716,\n",
       "                        -11365.4307,   8877.2490,   2070.6980],\n",
       "                       [-14597.8018,   -114.1059,   4062.7781,   6120.2949,  -9212.1494,\n",
       "                           264.7410,  13646.8096,   9798.5205],\n",
       "                       [ 14160.8730,   2619.4136,  -8087.0835,  15262.6436,   4151.4219,\n",
       "                         -8775.5518,  -5126.5337,   4108.6929],\n",
       "                       [  1252.9258,  -5225.5044,  -9251.5078,  -2622.9180,  -1192.5397,\n",
       "                          3420.2043, -10675.0830,  16122.0869],\n",
       "                       [  1251.4580,   9578.9316,    332.8629,  10867.1660,   9369.1123,\n",
       "                        -12197.1855,  12274.3105, -11704.2129],\n",
       "                       [  2135.1609,  -8455.4795,  20790.5957,   2857.5085, -10240.0088,\n",
       "                          6301.2646,   -827.5383,  -1466.6241],\n",
       "                       [ -8764.0625,   2244.0925,  -7022.3687,  -9405.7217,  26520.4961,\n",
       "                        -26519.1211,   4306.9253, -14979.3584],\n",
       "                       [  7056.2900,   3443.0862,   3499.4341,   6855.9053,   1189.3923,\n",
       "                          4541.6655, -13900.8643,  -6297.9307],\n",
       "                       [-17568.7285,  15581.3848,  -6105.0791,  11209.4971, -18259.1777,\n",
       "                         -1148.2966,  -6306.8320, -21191.4414],\n",
       "                       [ -8880.5498,   4611.8535,  12431.9590,   1227.8450,  -6143.9351,\n",
       "                         18646.4824, -19841.3242, -13991.6631],\n",
       "                       [ -5991.3213,   -444.0742,  -6365.5049,  14414.8086,    686.4485,\n",
       "                          2774.1428,   -290.8648,    798.2158],\n",
       "                       [   464.5087,  11095.4307,  -8271.9180,   -461.4998,  -8974.0703,\n",
       "                         -6098.7871,   -822.6299,  -4001.5051],\n",
       "                       [-13533.2783, -17262.8379,  19758.4629,  12771.6094, -11202.8750,\n",
       "                         16678.8828,   6037.9258,   5125.7944],\n",
       "                       [   151.8844,  -1182.6744,  -2723.6548, -17793.8340,  34170.4062,\n",
       "                           886.7114,  -4779.8813,   -796.5639],\n",
       "                       [  9323.3008, -17711.2949, -17751.0312,  20677.7012,  -2899.9282,\n",
       "                         -6823.9946,   7679.1318,   1862.6239],\n",
       "                       [-26880.4727,  -2023.2101, -21349.7812,  -4877.6348,  15753.0879,\n",
       "                         21790.0723, -31392.2715, -13123.7637],\n",
       "                       [  3007.7910,   7274.8291,  16550.7344, -17255.7949,     81.4596,\n",
       "                         -7436.1152, -11822.0049,   5092.5952],\n",
       "                       [-13586.4258,   -580.5378,   7667.1362,   1444.1268, -14745.8379,\n",
       "                          1845.4998,  18104.2363,  -4261.9722],\n",
       "                       [ 18079.6855,  14132.0537,  -6278.5103,  -2344.4966,   4064.1707,\n",
       "                         -4731.4844,  -1394.8446,  12787.8477],\n",
       "                       [  6032.2979,   -538.7580,  11928.7852,   4018.5696,  -4401.8911,\n",
       "                         11613.4287,   8863.1494, -13337.4053],\n",
       "                       [ 15120.8926,  11061.7061,  -3997.4673, -20406.5898,  15581.8135,\n",
       "                         -6266.8408, -12264.4844,   5023.9258],\n",
       "                       [-25829.1230,   -938.2411,  10957.7783,  12985.2998,   1711.0735,\n",
       "                         -6634.3818,   6196.2183,  -7514.2354],\n",
       "                       [-16732.6738,   1819.6108,  -9619.1299,  15198.7090,  19770.9023,\n",
       "                         -3443.4124,  14585.9443,  11320.4561],\n",
       "                       [-14663.0479,   -327.6770, -12774.2783,   9991.6777,   7987.5112,\n",
       "                          2868.6404,  -4163.4980,  13750.8379],\n",
       "                       [ -7146.2383, -10180.0742,  -3007.3628, -30297.6484, -11823.6865,\n",
       "                          8664.8008,   6449.2983,  -2985.6321],\n",
       "                       [ 12720.9746,   2266.8445,   5927.4800,    418.9072, -16739.0215,\n",
       "                          1674.6034, -16267.9023, -13146.2402],\n",
       "                       [  7028.7603,   2130.6917, -10317.5498,   9622.6826, -14103.2266,\n",
       "                          6289.2886,   4996.2666,   8745.2295],\n",
       "                       [ -5046.0137,   3906.1807, -12269.0986, -11175.8770,  13378.2783,\n",
       "                        -13134.7354,   6393.0308,  -7036.8735],\n",
       "                       [ -7689.3721,  -6244.6885, -23292.1250,   5102.3022,   7960.2344,\n",
       "                            47.7764,  10607.8916,   -482.6817],\n",
       "                       [ 23001.5879,  -5747.1040,  14660.9697,  20192.6914,   3660.6917,\n",
       "                           958.5355,  10969.3320, -11205.6689],\n",
       "                       [ 13038.2969,  -2664.1589,  10167.3555, -10499.0684,   3890.5820,\n",
       "                        -17977.6641,  -8828.0303, -25127.9707],\n",
       "                       [-12400.1133,  13309.9287,   2575.4919, -16532.5781,   6120.6289,\n",
       "                         -1181.5160,   2034.4506,   8376.7266],\n",
       "                       [ -5426.0278,  21601.6680, -30084.4785, -12652.9824, -19575.9902,\n",
       "                         11706.7207,   6794.1523,  -4690.9062],\n",
       "                       [  5132.4854,   7235.9873,   2412.9702, -11041.0244,   -943.8899,\n",
       "                        -10496.0889,  13230.5254,   2401.7878],\n",
       "                       [  2082.1270,    201.3378, -11110.4297, -12897.7422, -11740.4951,\n",
       "                         -2478.6282,   4564.0425,  -2686.9690],\n",
       "                       [  5587.2231,   3431.2690,   6285.7930,  -2247.2900,  -3873.3591,\n",
       "                         -9073.7520,   1243.2238,   9252.6650],\n",
       "                       [-17203.4727,  -3858.1001,   6561.5913,  11801.4229,   -308.2162,\n",
       "                          7203.8638,   8687.6768,  -3556.6855],\n",
       "                       [  -107.7942, -19570.5977,   8462.1543,  15642.2842,  -7766.0498,\n",
       "                        -10446.1562,   5912.9941,   8846.1729],\n",
       "                       [ -4410.0107,   4739.0737,  -4030.9932,  -8371.1885,   5893.9248,\n",
       "                          6110.6758,   2248.8662,   8995.6904],\n",
       "                       [ 18463.6309,  13179.2402,   5369.1748,  19801.1660,   7870.8369,\n",
       "                         -6981.4814,   1051.2057, -13637.9189],\n",
       "                       [  4004.8379,   8139.5854,  18975.5645,  -6340.0518,  12688.4717,\n",
       "                           202.2950,   3594.7439,  -2780.8237],\n",
       "                       [  -863.3747, -16997.7148,  -7885.3633,  -7609.1636,  -1826.1285,\n",
       "                          -390.9943,  10089.8154,  -1537.5001],\n",
       "                       [ -5551.6011,  -4591.6108, -14048.7090,  25699.8906,  -3680.4692,\n",
       "                         11250.5664,  -5913.7808,  20894.8730],\n",
       "                       [ 14474.7822,  -4434.3237,   5441.2500, -12416.3486,   2633.6213,\n",
       "                         -7027.8184,   6448.9707,  -3836.6072],\n",
       "                       [ 13866.5332,  17069.3887,  18772.2051,  11610.3301,  -7133.3042,\n",
       "                         -7467.0303,  -7079.2344,   6218.6582],\n",
       "                       [  4391.0742,   9637.3047,  -9220.8350,   5671.1533,   9881.3877,\n",
       "                         -2985.7537,   7047.0991, -12928.8359],\n",
       "                       [  1220.6049, -22554.7031,   9660.5479,  18569.9434,  -9742.1689,\n",
       "                          2073.7942, -11184.9590, -16534.1074],\n",
       "                       [-12040.8457,  13697.5732,   7986.8374,  10576.7012,   -333.1802,\n",
       "                        -15718.9385, -16584.2676,  -2059.0623],\n",
       "                       [   315.9328,  11309.4248,  -4347.6685,  14838.7988, -10628.1709,\n",
       "                        -11802.8633,  -8876.5703,  -9041.2754],\n",
       "                       [  4616.6465,   5519.8877,  18221.5371, -12563.7236, -21472.7227,\n",
       "                          8553.8438,   1891.3597,  11408.2910],\n",
       "                       [ -6824.4824,  -5133.1460,  11047.7324, -15120.0020,  14948.4170,\n",
       "                          3019.7661,    -71.2138,  -3515.7456],\n",
       "                       [ -8704.4531,  21203.1035,  11294.3633,   2040.1466,   5453.0757,\n",
       "                         11494.8877,    287.3729,  11721.0225],\n",
       "                       [ -7027.4409,  -2160.6768,  12004.6016, -16454.9902,   5779.2393,\n",
       "                          4539.7324,    841.2031, -15495.5820],\n",
       "                       [  -634.5044,  -1137.4890,   -653.5031,  24976.2480,  10341.0557,\n",
       "                         16941.4199,   4097.7095,   2085.1323],\n",
       "                       [ -1729.6260,  23267.5059,  -1366.3728,  12094.9746,   9031.6016,\n",
       "                         -2328.1990,  -1172.1056,   2164.7354],\n",
       "                       [  1035.3608,   -938.9647,  21887.0020,   7363.5024,    958.7244,\n",
       "                        -10749.6934,  -9631.1465,   2915.2920],\n",
       "                       [ 16183.3936,  -4363.3481,  13513.6426,  14175.3467,  -3261.4663,\n",
       "                          4132.0176,   7092.4634,   6702.1914],\n",
       "                       [-13876.0713,  -8748.4727,  -7446.7588,  -5780.7852,   -779.2676,\n",
       "                         -4179.9082,   8728.9658,    934.2320]])),\n",
       "              ('mlp_extractor.policy_net.0.bias',\n",
       "               tensor([ -411.1478,  -801.8130,    80.7802,  -774.5754,  2084.0725,   141.2728,\n",
       "                        -547.0269,  -341.4629,  -842.9897,   572.4116, -1091.8407,   279.0946,\n",
       "                         674.5246,  1169.5225,  1349.1796,    41.7366, -1172.1976,   808.5209,\n",
       "                        1040.6953,   544.8049, -1693.4092, -1622.7502,  1787.6178,   787.0488,\n",
       "                        1081.9686,  -683.6329,  1461.4823,    31.9627,  -921.9094,  -331.6333,\n",
       "                        1757.3268,   219.0571, -1364.7676,  -146.6309,   180.5479,  -672.5919,\n",
       "                          11.8702,  1311.2369,  -102.6135,  -419.1181,  1833.3937,  1378.6771,\n",
       "                        -446.6688,  -654.3992,  -104.2717,   781.7307,  2309.0198,  -787.1948,\n",
       "                       -1243.9919,  1262.7894,  1023.4040,   730.5206, -1009.4683,  -583.7786,\n",
       "                         841.7858,   139.5385,   641.8714,  1443.0155,  1138.6846,  1063.4963,\n",
       "                         506.1998,  -753.3361,  -821.2571,   613.5442])),\n",
       "              ('mlp_extractor.policy_net.2.weight',\n",
       "               tensor([[-13392.5352,  11299.5635,  -3792.4556,  ...,   3969.2258,\n",
       "                          2731.4512,  -3779.7542],\n",
       "                       [-10837.3340,   7364.7871,    375.1728,  ...,  20771.7539,\n",
       "                        -11632.8018,  14728.4922],\n",
       "                       [  1075.0968,   9059.3730,   3799.2517,  ...,  -7214.3672,\n",
       "                           765.2064,  -1151.0021],\n",
       "                       ...,\n",
       "                       [ 13644.7285,   -343.9175,  -1612.5083,  ..., -14642.0156,\n",
       "                         -4988.0713, -18219.7617],\n",
       "                       [  6749.8188,   5322.7979,   8497.5537,  ...,  -4808.1372,\n",
       "                         15593.9521,  -9688.1162],\n",
       "                       [  6196.0317,   4853.2070, -12575.0938,  ...,  17933.9551,\n",
       "                         10673.5352,    538.9632]])),\n",
       "              ('mlp_extractor.policy_net.2.bias',\n",
       "               tensor([ -709.1274,  1629.5491,   926.4532,   338.3610,  -731.3275,  -680.2178,\n",
       "                        -555.3665,  2232.7109, -1603.9895,  -478.2412,  -588.1490, -1396.2162,\n",
       "                       -1248.2500, -1660.1008, -2046.1205,  -404.0897,  -406.4035,   567.8511,\n",
       "                        -365.1117,  1191.9548, -2916.0896,  1444.7352,   922.5302,  -266.9138,\n",
       "                        -188.1606,  -528.5747,   955.6342, -1405.3097,  -614.7715,   -58.7510,\n",
       "                         169.3118,  1187.0657,  -676.0370,   507.7777,   496.9129,  -976.4642,\n",
       "                        1163.8684,  -296.8900,   526.0332,  -884.1161,  -739.6334, -1012.4305,\n",
       "                         268.5437,   331.6747,  1467.9652,  1392.4022, -1266.1582,  -655.6256,\n",
       "                          71.3506,   746.3358,  -423.5638,  -657.8349,   418.7373, -1615.0082,\n",
       "                        1322.3417,  -946.9579, -2763.4812,   385.1349,  1171.9380,  -608.8960,\n",
       "                         906.8524,  -523.5248,  -930.8858, -1492.2646])),\n",
       "              ('mlp_extractor.value_net.0.weight',\n",
       "               tensor([[ 5.9156e+03, -1.2678e+03,  6.4454e+03, -1.7014e+03,  7.0715e+03,\n",
       "                        -1.3034e+03,  7.7558e+03,  7.3247e+03],\n",
       "                       [ 5.1526e+02,  2.0976e+04,  9.7977e+03, -1.8030e+04,  1.5615e+04,\n",
       "                        -8.7610e+03,  6.9576e+03, -1.3621e+04],\n",
       "                       [-2.7742e+03,  1.1874e+04, -2.7058e+03, -3.6299e+03,  8.0431e+03,\n",
       "                         9.3184e+03,  2.3573e+03,  2.0288e+04],\n",
       "                       [-1.0243e+04, -3.2659e+04,  5.2734e+03,  3.0440e+03,  1.1848e+04,\n",
       "                         5.5797e+03,  1.7756e+03, -1.6410e+03],\n",
       "                       [-1.0626e+04, -1.6340e+04, -1.7049e+03,  1.1453e+03,  1.2955e+04,\n",
       "                        -1.8864e+04, -2.1174e+03,  9.5200e+03],\n",
       "                       [-1.4096e+04, -3.1146e+04, -1.5791e+02,  1.1960e+03, -5.5064e+03,\n",
       "                         1.6975e+03,  1.2873e+03,  4.2583e+03],\n",
       "                       [ 4.2675e+03, -1.6754e+04, -9.6319e+03, -2.5907e+03,  2.6200e+03,\n",
       "                         5.6244e+03, -5.1175e+03, -1.6532e+04],\n",
       "                       [-1.0748e+04, -3.4999e+03, -1.5945e+04,  9.2583e+03, -7.8169e+03,\n",
       "                        -5.0710e+03,  1.3012e+04,  1.6470e+03],\n",
       "                       [-4.8449e+03, -1.7267e+04,  1.1143e+04, -2.6073e+03,  8.0995e+03,\n",
       "                        -4.3057e+03, -3.7706e+03,  5.6781e+03],\n",
       "                       [ 1.9553e+04, -8.6075e+03,  6.7346e+03,  2.2508e+04,  1.6710e+04,\n",
       "                        -1.9312e+04,  3.4342e+03,  8.7744e+03],\n",
       "                       [-1.0032e+03,  2.4374e+02, -1.4308e+04,  1.2007e+04,  1.2995e+04,\n",
       "                        -1.5703e+04,  5.5108e+03,  4.7684e+03],\n",
       "                       [-2.7176e+03, -8.3208e+03, -1.7311e+04, -6.0864e+03,  2.1383e+03,\n",
       "                        -3.2486e+03,  1.1494e+02,  1.1818e+04],\n",
       "                       [-1.2980e+04, -1.5538e+04, -3.9069e+03,  8.7918e+03,  9.3381e+03,\n",
       "                         1.0739e+04, -1.4827e+04, -2.2599e+04],\n",
       "                       [-2.2893e+03,  4.6419e+03, -3.4429e+03,  1.2021e+03,  8.0351e+03,\n",
       "                        -9.6390e+03,  1.2065e+04,  9.5067e+02],\n",
       "                       [ 1.4402e+04,  1.9911e+04,  3.0019e+02, -1.2467e+04,  1.7699e+03,\n",
       "                        -1.2697e+04,  1.1539e+04, -1.0148e+04],\n",
       "                       [ 7.5444e+03,  2.2945e+03, -2.5241e+03, -1.8308e+03, -5.6624e+03,\n",
       "                        -9.4760e+03,  1.2623e+04,  6.6554e+03],\n",
       "                       [-7.2088e+03, -3.2488e+02, -2.0494e+03, -5.1272e+03, -6.1751e+02,\n",
       "                        -6.9217e+03,  7.3234e+03, -9.3230e+03],\n",
       "                       [ 1.7988e+03, -5.1517e+03,  9.3548e+03, -1.0726e+04,  6.5673e+02,\n",
       "                        -3.5266e+03, -2.3042e+04, -8.0283e+03],\n",
       "                       [-1.5995e+04, -1.0743e+04, -8.5427e+03, -1.9983e+03,  5.8169e+03,\n",
       "                        -1.2776e+04, -8.5658e+03,  7.3275e+03],\n",
       "                       [ 1.1837e+04,  2.7136e+01, -2.3072e+04, -1.0482e+03,  4.5914e+04,\n",
       "                        -1.7065e+03, -6.3063e+03,  4.5857e+03],\n",
       "                       [-2.3664e+03,  8.3011e+03, -5.2953e+03, -2.1700e+04, -1.1460e+04,\n",
       "                         2.5374e+03,  3.6094e+03,  1.0911e+04],\n",
       "                       [ 6.2778e+03,  3.7397e+03,  4.3058e+03, -1.1411e+04, -7.6050e+03,\n",
       "                        -1.3726e+03,  1.0162e+04,  8.0371e+03],\n",
       "                       [-7.0146e+03,  5.3711e+03, -5.3759e+03, -1.1107e+04,  1.5480e+04,\n",
       "                        -5.4113e+03, -1.5208e+03, -1.0383e+04],\n",
       "                       [ 5.8048e+03,  2.6807e+04,  1.3401e+03, -1.6949e+04,  4.8221e+03,\n",
       "                        -5.0476e+03,  2.7698e+02,  2.3834e+03],\n",
       "                       [ 1.1932e+04,  2.2700e+04,  3.0510e+02,  2.1002e+04,  1.2682e+04,\n",
       "                        -5.8892e+03,  8.6839e+03,  2.7798e+03],\n",
       "                       [ 1.2695e+03, -2.0805e+04,  6.8919e+03, -7.3092e+03,  2.8875e+03,\n",
       "                         1.2928e+03, -7.9221e+03, -2.4843e+03],\n",
       "                       [ 9.8218e+03,  5.0720e+03, -2.0197e+03,  2.8815e+03,  9.1422e+03,\n",
       "                         3.6453e+03, -8.9771e+03,  6.7566e+03],\n",
       "                       [-5.1916e+03,  6.9156e+03,  2.0772e+04,  1.5191e+04, -2.1352e+03,\n",
       "                        -4.2636e+03, -5.5599e+03,  1.5239e+02],\n",
       "                       [-6.4119e+02,  5.1307e+03, -1.7364e+04,  1.1928e+04,  1.8156e+01,\n",
       "                         1.3282e+04, -6.7896e+03, -2.0853e+03],\n",
       "                       [-8.0909e+03,  2.9319e+04, -1.4028e+04, -5.2071e+02, -9.2597e+03,\n",
       "                         5.4782e+03, -7.3397e+03,  9.8761e+03],\n",
       "                       [ 7.6482e+03,  2.0956e+04,  3.0855e+03, -1.1605e+04, -8.3403e+03,\n",
       "                         7.5638e+03,  1.7223e+04, -3.1766e+03],\n",
       "                       [ 5.0557e+03, -3.8854e+03, -1.8272e+04,  2.0472e+03, -1.3997e+04,\n",
       "                        -4.9352e+03, -1.2049e+04, -7.9628e+03],\n",
       "                       [ 5.6866e+03,  1.2234e+04,  7.5177e+03,  5.5391e+03, -6.8545e+03,\n",
       "                         1.4506e+03,  1.4313e+03, -1.5250e+04],\n",
       "                       [ 9.8819e+03,  2.1220e+03, -7.2900e+03, -6.1275e+02,  8.5390e+03,\n",
       "                        -1.3375e+04,  1.3108e+03, -1.1447e+04],\n",
       "                       [ 1.3529e+04,  1.7529e+04, -6.5770e+03, -1.8015e+04, -1.2520e+04,\n",
       "                         4.4908e+03, -4.3189e+03,  1.4542e+03],\n",
       "                       [ 4.2572e+03,  9.5452e+03, -1.3923e+04, -1.1517e+04, -1.0872e+04,\n",
       "                        -5.8113e+03, -4.9934e+03, -5.8945e+03],\n",
       "                       [ 4.2317e+03,  3.2469e+03,  5.5166e+03, -6.2358e+03,  1.0262e+04,\n",
       "                         4.6266e+03,  1.6555e+04, -7.2359e+03],\n",
       "                       [-1.4085e+04, -2.6476e+04,  3.5965e+03,  3.3118e+03, -1.8431e+04,\n",
       "                         1.6438e+04,  9.5632e+03, -8.2870e+03],\n",
       "                       [-2.1664e+03,  7.3532e+03,  8.1694e+03,  5.4151e+03, -3.0125e+02,\n",
       "                         1.2721e+04,  8.1003e+03, -1.7650e+04],\n",
       "                       [ 7.8461e+02,  6.4027e+03, -1.1134e+04,  3.9351e+04,  6.2529e+03,\n",
       "                         8.0808e+03, -6.2763e+03, -1.8286e+04],\n",
       "                       [ 1.7997e+03,  9.0893e+03, -3.8893e+03,  2.8683e+03,  2.8173e+03,\n",
       "                        -2.5312e+04, -8.0901e+03, -1.0614e+03],\n",
       "                       [ 6.3547e+03, -3.5076e+03,  5.8682e+03,  6.5031e+03, -1.9572e+04,\n",
       "                        -3.8391e+03, -1.0075e+04, -9.8785e+02],\n",
       "                       [-1.0954e+04,  2.3551e+04,  1.8337e+03,  3.3022e+03, -2.2300e+03,\n",
       "                        -4.1821e+02, -1.6386e+03,  3.8959e+03],\n",
       "                       [-1.1870e+04, -6.8314e+03,  3.9277e+02, -8.1308e+03, -5.8603e+02,\n",
       "                         1.4886e+04, -5.6927e+03, -6.8616e+03],\n",
       "                       [ 1.9473e+04,  1.7448e+04,  1.8564e+04, -1.2061e+04, -7.5135e+03,\n",
       "                        -3.9056e+03, -2.1074e+04, -5.3855e+03],\n",
       "                       [-1.2804e+04,  2.1715e+02, -3.9791e+03,  2.0523e+03,  2.7694e+04,\n",
       "                         9.6071e+03,  6.2618e+03,  5.6389e+03],\n",
       "                       [ 5.6445e+03,  1.5946e+04,  9.6645e+03, -1.0599e+04, -9.4692e+03,\n",
       "                         2.1071e+03,  4.5414e+03,  1.6357e+03],\n",
       "                       [-2.5930e+03,  1.9092e+04, -1.0445e+04, -2.4498e+04, -3.4163e+03,\n",
       "                        -6.2273e+03, -2.0598e+04,  2.6633e+04],\n",
       "                       [-1.0424e+03,  1.0523e+04,  5.4207e+03,  7.0708e+03, -1.0929e+04,\n",
       "                         2.5062e+03,  2.2779e+03,  2.4093e+04],\n",
       "                       [-7.8850e+03, -1.0215e+04,  7.4661e+03, -6.8717e+03, -1.3922e+04,\n",
       "                         6.8505e+03,  1.6613e+04,  1.1849e+03],\n",
       "                       [ 6.3785e+03, -4.4748e+03,  7.8708e+03,  6.4465e+03,  2.3050e+03,\n",
       "                        -6.6885e+03, -1.2301e+04,  1.2451e+03],\n",
       "                       [ 7.1377e+03,  8.3647e+03, -9.9774e+03, -1.3383e+04,  5.9635e+03,\n",
       "                        -4.9896e+03, -7.4650e+03,  6.8936e+03],\n",
       "                       [ 3.7298e+03, -2.1202e+04,  1.1529e+03,  2.9229e+04, -6.1401e+03,\n",
       "                        -6.4370e+02, -3.1815e+03, -1.5224e+03],\n",
       "                       [-3.9026e+03, -5.4387e+03, -6.6376e+03,  9.6442e+03, -6.4783e+03,\n",
       "                         1.9968e+04, -1.3694e+04, -1.4722e+04],\n",
       "                       [-1.5158e+02,  7.8685e+03,  1.2248e+04, -8.3623e+03, -6.2165e+03,\n",
       "                         2.0756e+04, -1.4245e+04,  7.0243e+02],\n",
       "                       [-3.3776e+03,  2.8044e+04, -2.4433e+03, -1.7365e+03,  5.5589e+03,\n",
       "                        -2.4634e+03,  1.0182e+04,  2.1288e+04],\n",
       "                       [-7.0462e+03, -7.0726e+03,  5.7559e+03,  6.4004e+03, -7.0417e+02,\n",
       "                         1.1587e+03, -7.1899e+03, -2.2779e+04],\n",
       "                       [-6.6292e+03, -9.2034e+03,  1.0305e+04,  4.5276e+03, -3.5770e+03,\n",
       "                         7.8160e+03, -1.0029e+04,  8.3109e+03],\n",
       "                       [ 1.5134e+03, -1.2040e+04, -1.0772e+04,  3.9162e+03, -4.5428e+03,\n",
       "                         2.1209e+04, -2.2725e+03, -1.3308e+04],\n",
       "                       [ 8.4030e+03,  8.3685e+03, -1.3484e+03,  7.6716e+03, -1.4077e+03,\n",
       "                        -1.8380e+04, -1.0935e+04,  1.2321e+04],\n",
       "                       [-1.0121e+02,  3.3097e+03,  1.0843e+04, -6.8664e+03, -1.4826e+04,\n",
       "                        -3.4998e+03, -2.9909e+03, -1.3430e+04],\n",
       "                       [ 4.6543e+03, -5.1325e+02, -2.1444e+04,  1.9465e+03, -2.1941e+03,\n",
       "                        -6.7460e+03, -7.5372e+03, -2.4756e+03],\n",
       "                       [ 2.5894e+03,  7.8646e+03,  5.6659e+03, -3.0533e+03, -7.5972e+03,\n",
       "                         9.0564e+03, -1.0921e+04,  4.5629e+03],\n",
       "                       [ 9.2683e+03, -2.1747e+03, -2.1306e+04, -3.9106e+02,  1.2790e+04,\n",
       "                        -1.4545e+04, -3.2475e+03, -3.0044e+03]])),\n",
       "              ('mlp_extractor.value_net.0.bias',\n",
       "               tensor([-1570.1538,  6273.9238,  -575.4704, -5882.2603,  2145.7236, -5718.6675,\n",
       "                       -6177.3081,   913.7023, -4709.9829,   446.0085,    91.5524, -2959.6580,\n",
       "                       -4659.9741,  -432.4459,  7157.8984,  -289.7899,  1851.5619, -5427.9922,\n",
       "                         998.9812, -1349.2231,  3996.0742,  1489.4825, -1383.5992,  7647.4897,\n",
       "                        4239.5708, -5704.5122,   529.2822,  -956.0062,   862.2928,  5812.5752,\n",
       "                        8419.6963,   -63.1539,  1133.4829,  1016.1112,  4855.0186,  1914.3879,\n",
       "                        3338.9175, -3807.4927,  -979.2875, -5391.5303, -1522.1436, -3790.7974,\n",
       "                        7361.4971,  -142.1071,  5683.7314,   733.7953,  6624.9028,  8621.8984,\n",
       "                         -32.2210,  4427.9600,  -801.0198,  -134.4465, -7743.5435,  3211.8916,\n",
       "                         922.0020,  4351.5713, -1142.3934, -2775.8674, -5618.5815,  5065.4209,\n",
       "                         147.6888,  2962.7754,  1044.4624, -1472.2240])),\n",
       "              ('mlp_extractor.value_net.2.weight',\n",
       "               tensor([[ 18040.1934,  17814.6992,   4755.8145,  ...,  -5381.5903,\n",
       "                          -444.6371,   7558.5815],\n",
       "                       [ 15530.9512,  -9108.6152, -13155.8135,  ...,    233.0353,\n",
       "                           167.0181,  -3935.8057],\n",
       "                       [ -8068.5386,   2180.2920, -16954.8320,  ...,  10124.0781,\n",
       "                          -151.9261,  12866.9463],\n",
       "                       ...,\n",
       "                       [  6676.9878,  -7688.8789, -10673.9238,  ...,   3491.1741,\n",
       "                         -6770.1230, -11593.0254],\n",
       "                       [-11287.1855,  -2486.5920,  -1031.8872,  ...,  -4404.6748,\n",
       "                          3688.9480, -32435.8711],\n",
       "                       [ 12883.2588,   7701.5557, -10855.6035,  ...,   6155.4014,\n",
       "                        -19086.1602,   8178.7812]])),\n",
       "              ('mlp_extractor.value_net.2.bias',\n",
       "               tensor([-4091.9500, -5737.6445,   610.0124,  9082.2246, -4514.2480, -5701.9248,\n",
       "                       -1443.4515,  -139.8540, -5718.0127,  7234.5957, -1699.3193, -1120.1768,\n",
       "                       -7318.2593, -6236.7280,  -744.8622, -3074.5149,  -374.0417,  6531.2476,\n",
       "                        1687.0818,  2321.5791, -7566.5044,    75.9829, -7090.9150,  -296.6999,\n",
       "                       -6280.8311,  4394.8560, -3827.1003,  4087.7451,  8942.7559,   296.2180,\n",
       "                       -5310.0269, -8982.2441,   435.5654,  5123.1562, -7143.2095,  -243.2843,\n",
       "                        5718.0557, -5199.3252, -7417.5264, -7376.7739, -6071.9521,   333.1152,\n",
       "                       -1909.3947, -5507.0552,  -543.9088,  6266.4805,  -113.9626,  -127.3695,\n",
       "                       -1411.5795,  1025.7292,  7092.7886,  2170.0505, -6706.9551, -3979.7932,\n",
       "                         893.3170,  7888.8232,   778.2858, -7697.6733,  7407.2217,   -75.5695,\n",
       "                        2302.1614, -2226.2991, -1338.2273,  4227.3818])),\n",
       "              ('action_net.weight',\n",
       "               tensor([[-1.2641e+03, -3.5505e+03, -9.3884e+02, -5.1353e-01,  2.3459e+03,\n",
       "                         2.2035e+03,  1.8883e+03, -1.4842e+03,  3.8129e+03,  1.6712e+03,\n",
       "                        -1.3010e+03, -6.8727e+02,  9.1777e+02,  4.8524e+03,  2.5068e+03,\n",
       "                         4.9095e+03, -5.1141e+02, -3.1279e+03,  6.2877e+01, -2.3908e+03,\n",
       "                         3.3899e+03, -4.5866e+03, -1.2442e+03,  8.3092e+02,  3.3709e+03,\n",
       "                         3.4124e+03, -1.8140e+03,  4.1269e+03, -8.0268e+02,  1.2960e+03,\n",
       "                        -2.8383e+03, -1.9806e+03,  1.3214e+03, -4.7411e+00, -1.7946e+03,\n",
       "                         9.1881e+02, -2.3071e+03, -4.9701e+02, -8.0557e+02,  4.2992e+02,\n",
       "                         4.7013e+03,  2.7405e+03,  1.6969e+03, -1.6217e+03, -3.8226e+03,\n",
       "                        -2.9983e+03,  4.5170e+03,  2.0026e+03, -2.9951e+03, -5.7985e+02,\n",
       "                         1.6954e+03, -2.8382e+02,  3.1875e+02, -4.9907e+02, -1.6643e+03,\n",
       "                         1.2898e+03,  4.5066e+03,  1.1196e+03, -4.0751e+03, -1.2891e+03,\n",
       "                        -3.3972e+03,  2.2736e+03,  1.7132e+03,  3.6964e+03],\n",
       "                       [ 1.7496e+03,  1.8033e+03,  1.1741e+03,  4.9849e+03, -4.8718e+03,\n",
       "                         1.9195e+03,  6.1825e+03,  7.1084e+02,  7.3271e+03, -3.0687e+03,\n",
       "                        -3.7741e+03, -3.8194e+02, -6.8309e+03, -3.4244e+03,  4.0835e+03,\n",
       "                        -1.7120e+03,  4.5894e+03,  2.5655e+02,  7.3912e+03,  5.1853e+03,\n",
       "                        -3.2396e+03,  1.3102e+03,  2.8751e+03,  6.8673e+03, -1.0528e+03,\n",
       "                         6.1288e+03,  1.7462e+03, -9.0686e+02, -1.9274e+03, -4.9341e+02,\n",
       "                         4.1017e+03, -2.2353e+03,  5.1536e+03, -2.4173e+03,  2.9164e+03,\n",
       "                         6.1286e+03,  4.2383e+03,  6.2182e+03, -7.2382e+03,  3.4858e+03,\n",
       "                        -2.2322e+03, -2.8580e+03, -5.3528e+03, -7.7490e+03, -2.7352e+03,\n",
       "                        -3.0940e+03, -2.2369e+03, -3.0603e+03,  1.6906e+03,  1.3511e+03,\n",
       "                         7.6064e+03,  9.8879e+02,  3.7816e+03, -1.2136e+02,  2.4275e+03,\n",
       "                        -2.7302e+03,  2.1411e+03, -1.2692e+03, -4.7681e+03,  7.2194e+03,\n",
       "                         3.6839e+01, -1.6655e+03, -3.5268e+03,  7.6473e+03],\n",
       "                       [ 2.4545e+03,  4.7533e+03,  1.3891e+03, -4.3476e+02, -4.0564e+03,\n",
       "                        -2.2769e+03, -3.0879e+03,  3.8303e+03, -7.8740e+03, -3.8741e+02,\n",
       "                         9.8850e+02,  8.2907e+02,  2.1840e+03, -4.8764e+03, -6.8568e+03,\n",
       "                        -5.2698e+03, -3.9756e+03,  4.9987e+03, -2.3793e+03, -2.4867e+02,\n",
       "                        -2.6255e+03,  6.3296e+03,  6.3013e+03, -3.7602e+03, -2.7770e+03,\n",
       "                        -5.1726e+03,  5.4868e+03, -2.8883e+03,  1.9007e+03, -1.1521e+02,\n",
       "                         2.4232e+03,  4.6762e+03, -3.5644e+03,  1.9428e+03,  4.1944e+03,\n",
       "                        -5.3058e+01,  2.4062e+03,  8.2679e+02,  2.8161e+03, -4.7631e+03,\n",
       "                        -2.1357e+03, -4.6861e+03,  4.3746e+03,  4.3562e+03,  2.9125e+03,\n",
       "                         4.6458e+03, -4.0572e+03,  1.0761e+03,  3.2416e+03,  3.8182e+03,\n",
       "                        -3.7352e+03,  1.8407e+03, -2.5267e+02, -1.6442e+03,  3.8508e+03,\n",
       "                        -3.3582e+03, -7.3872e+03,  2.8394e+02,  5.7214e+03, -4.3154e+03,\n",
       "                         1.5855e+03, -3.7050e+03, -3.6838e+03, -5.6094e+03],\n",
       "                       [-1.9490e+03, -5.7405e+03, -3.5168e+03, -3.3527e+03,  9.1877e+03,\n",
       "                        -3.4776e+03, -4.6239e+03, -5.0985e+03, -6.9842e+02,  3.9587e+02,\n",
       "                         6.8003e+03,  7.2162e+02,  8.6866e+02,  5.9356e+03,  1.6343e+03,\n",
       "                         4.3587e+03, -7.3292e+02, -4.7799e+03, -6.8220e+03, -9.9745e+02,\n",
       "                         4.3385e+03, -5.2841e+03, -1.2929e+04, -4.1794e+03,  1.2940e+03,\n",
       "                        -2.9083e+03, -1.0333e+04,  1.1603e+03,  8.1184e+02, -2.1664e+03,\n",
       "                        -3.6723e+03, -3.0049e+02, -3.4607e+03,  2.5227e+03, -9.4164e+03,\n",
       "                        -8.8696e+03, -5.5817e+03, -7.3072e+03,  5.9660e+03,  4.6654e+03,\n",
       "                         1.1860e+03,  1.0202e+04, -3.2847e+03,  4.5710e+03,  3.6883e+03,\n",
       "                         8.2898e+02,  3.9966e+03, -8.0922e+02, -2.7199e+03, -8.0661e+03,\n",
       "                        -4.1965e+03, -3.8001e+03, -2.7354e+03,  3.6370e+03, -5.3408e+03,\n",
       "                         8.3490e+03,  2.1920e+03, -1.1496e+03,  1.8313e+03,  3.8585e+02,\n",
       "                         1.4751e+03,  4.1162e+03,  6.5324e+03, -3.5880e+03]])),\n",
       "              ('action_net.bias',\n",
       "               tensor([-3207.7844,  -538.6916,  3232.2483,  1350.1316])),\n",
       "              ('value_net.weight',\n",
       "               tensor([[ 21628.1875,  18303.9258,  -6932.9917, -10602.3916,   4324.3276,\n",
       "                         13308.6133,  -4081.7236,   4267.6826,  16257.5781,  -9578.8721,\n",
       "                          4179.8804, -11810.4268,  14618.2666,   8829.0625,   8157.6831,\n",
       "                          5966.4370,  -2975.5710, -14442.4238,  14258.1064,   8858.8369,\n",
       "                          9348.8721,   6828.2261,  15413.1777,   7096.8525,  18140.4355,\n",
       "                        -17639.8281,  18174.4297,   7411.0723, -10978.4766,  -9854.6836,\n",
       "                         18010.4277,  12499.3555,  -5766.9663, -21332.7871,   9165.0859,\n",
       "                        -12176.7041, -11597.5820,  14846.8994,  18405.6387,   9702.8604,\n",
       "                         10836.3398,   5877.1240,  -3422.4841,  22687.7812,  -3103.7207,\n",
       "                        -11897.8467,  -4689.4941,   7748.7412, -13962.1895,  -8340.1504,\n",
       "                        -21375.0859,   4107.0625,   8859.8301,   6907.3735,  -3240.7688,\n",
       "                        -12774.2617,  11243.3613,  10143.4824, -13728.9062,   5356.8623,\n",
       "                          5906.1294,  -9950.6621,  -3465.7439, -22788.8398]])),\n",
       "              ('value_net.bias', tensor([-6057.6646]))]),\n",
       " 'policy.optimizer': {'state': {},\n",
       "  'param_groups': [{'lr': 0.0007,\n",
       "    'momentum': 0,\n",
       "    'alpha': 0.99,\n",
       "    'eps': 1e-05,\n",
       "    'centered': False,\n",
       "    'weight_decay': 0,\n",
       "    'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}]}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('a2c_lunar_multiproc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting Params as JSON\n",
    "## Function to Convert Params Dict to Flattened List\n",
    "def flatten_list(params):\n",
    "    \"\"\"\n",
    "    :param params: (dict)\n",
    "    :return: (np.ndarray)\n",
    "    \"\"\"\n",
    "    params_ = {}\n",
    "    for key in params.keys():\n",
    "        params_[key] = params[key].tolist()\n",
    "    return params_\n",
    "## Write Parameters to JSON File\n",
    "import json\n",
    "\n",
    "all_params = model.get_parameters()\n",
    "pol_params = flatten_list(all_params['policy'])\n",
    "\n",
    "all_params['policy'] = pol_params\n",
    "\n",
    "with open('a2c_lunar_multiproc.json', 'w') as f:\n",
    "    json.dump(all_params, f, indent='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 -125.8918386331643 1 -130.12257823236286 2 -133.80995555415285 3 -155.3977794014383 4 -135.67041762243025 5 -116.3916652476124 6 -138.49260917463397 7 -173.49132147997153 8 -123.89375966929947 9 -134.10918745084783 Type  Mean reward: -136.7271112465914\n"
     ]
    }
   ],
   "source": [
    "model_loaded = ALGO(\n",
    "    \"MlpPolicy\",\n",
    "    env\n",
    ")\n",
    "\n",
    "evaluate(model_loaded,env, verbose=1)\n",
    "\n",
    "new_params = all_params\n",
    "loaded_pol_params = new_params['policy']\n",
    "for key in loaded_pol_params.keys():\n",
    "    loaded_pol_params[key] = th.tensor(loaded_pol_params[key])\n",
    "\n",
    "new_params['policy'] = loaded_pol_params\n",
    "\n",
    "model_loaded.set_parameters(new_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 -189.31433846539804 1 -122.5401758715976 2 -149.45707392856565 3 -111.5959788093649 4 -106.72923593113664 5 -132.80579088629239 6 -147.23850057052914 7 -203.0111683366471 8 -160.72532241535373 9 -90.73251939904512 Type  Mean reward: -141.41501046139302\n"
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "evaluate(model_loaded,env, verbose=1)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3fe87c7677a9be80aab770929aa8f3d40850ac08a0f73ec246342c77c48f1c11"
  },
  "kernelspec": {
   "display_name": "Python 3.7.2 64-bit ('pydrl': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
