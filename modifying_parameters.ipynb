{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modifying and Loading Parameters of Policies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "import gym\n",
    "import numpy as np\n",
    "import torch as th\n",
    "\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.evaluation import evaluate_policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mutate Function to modify Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutate(params: Dict[str, th.Tensor]) -> Dict[str, th.Tensor]:\n",
    "    \"\"\"Mutate parameters by adding normal noise to them\"\"\"\n",
    "    return dict((name, param + th.randn_like(param)) for name, param in params.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Policy with a small Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('LunarLander-v2')\n",
    "model = DQN(\n",
    "    \"MlpPolicy\",\n",
    "    env,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Initial Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 79.2     |\n",
      "|    ep_rew_mean      | -220     |\n",
      "|    exploration rate | 0.699    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 2274     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total timesteps  | 317      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 82.5     |\n",
      "|    ep_rew_mean      | -189     |\n",
      "|    exploration rate | 0.373    |\n",
      "| time/               |          |\n",
      "|    episodes         | 8        |\n",
      "|    fps              | 2300     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total timesteps  | 660      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 79.4     |\n",
      "|    ep_rew_mean      | -170     |\n",
      "|    exploration rate | 0.0947   |\n",
      "| time/               |          |\n",
      "|    episodes         | 12       |\n",
      "|    fps              | 2258     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total timesteps  | 953      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 84.6     |\n",
      "|    ep_rew_mean      | -194     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16       |\n",
      "|    fps              | 2482     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total timesteps  | 1354     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 87.5     |\n",
      "|    ep_rew_mean      | -194     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 20       |\n",
      "|    fps              | 2663     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total timesteps  | 1750     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 91.3     |\n",
      "|    ep_rew_mean      | -195     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 24       |\n",
      "|    fps              | 2798     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total timesteps  | 2192     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 92.3     |\n",
      "|    ep_rew_mean      | -205     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 28       |\n",
      "|    fps              | 2700     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total timesteps  | 2584     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 92.5     |\n",
      "|    ep_rew_mean      | -197     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 32       |\n",
      "|    fps              | 2738     |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total timesteps  | 2960     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 92.6     |\n",
      "|    ep_rew_mean      | -191     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 36       |\n",
      "|    fps              | 2656     |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total timesteps  | 3335     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 94.7     |\n",
      "|    ep_rew_mean      | -199     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 40       |\n",
      "|    fps              | 2737     |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total timesteps  | 3788     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 94.9     |\n",
      "|    ep_rew_mean      | -211     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 44       |\n",
      "|    fps              | 2792     |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total timesteps  | 4176     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 94       |\n",
      "|    ep_rew_mean      | -213     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 48       |\n",
      "|    fps              | 2846     |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total timesteps  | 4513     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 93.7     |\n",
      "|    ep_rew_mean      | -203     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 52       |\n",
      "|    fps              | 2783     |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total timesteps  | 4871     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 93.1     |\n",
      "|    ep_rew_mean      | -197     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 56       |\n",
      "|    fps              | 2827     |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total timesteps  | 5215     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 94.1     |\n",
      "|    ep_rew_mean      | -199     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 60       |\n",
      "|    fps              | 2873     |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total timesteps  | 5645     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 94       |\n",
      "|    ep_rew_mean      | -197     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 64       |\n",
      "|    fps              | 2907     |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total timesteps  | 6015     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 93       |\n",
      "|    ep_rew_mean      | -195     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 68       |\n",
      "|    fps              | 2940     |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total timesteps  | 6323     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 92.7     |\n",
      "|    ep_rew_mean      | -191     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 72       |\n",
      "|    fps              | 2964     |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total timesteps  | 6671     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 92.7     |\n",
      "|    ep_rew_mean      | -195     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 76       |\n",
      "|    fps              | 2990     |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total timesteps  | 7042     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 92.5     |\n",
      "|    ep_rew_mean      | -197     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 80       |\n",
      "|    fps              | 3006     |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total timesteps  | 7398     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 92.1     |\n",
      "|    ep_rew_mean      | -193     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 84       |\n",
      "|    fps              | 3032     |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total timesteps  | 7733     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 91.2     |\n",
      "|    ep_rew_mean      | -194     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 88       |\n",
      "|    fps              | 3051     |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total timesteps  | 8027     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 91.2     |\n",
      "|    ep_rew_mean      | -194     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 92       |\n",
      "|    fps              | 3069     |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total timesteps  | 8394     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 90.7     |\n",
      "|    ep_rew_mean      | -189     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 96       |\n",
      "|    fps              | 3085     |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total timesteps  | 8709     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 90.3     |\n",
      "|    ep_rew_mean      | -188     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 100      |\n",
      "|    fps              | 3102     |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total timesteps  | 9027     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 90.8     |\n",
      "|    ep_rew_mean      | -186     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 104      |\n",
      "|    fps              | 3118     |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total timesteps  | 9395     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 90.9     |\n",
      "|    ep_rew_mean      | -187     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 108      |\n",
      "|    fps              | 3134     |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total timesteps  | 9747     |\n",
      "----------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.dqn.dqn.DQN at 0x7f841f261a90>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use traditional actor-critic policy gradient updates to\n",
    "# find good initial parameters\n",
    "model.learn(total_timesteps=10_000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve Policy Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Include only variables with \"policy\", \"action\" (policy) or \"shared_net\" (shared layers)\n",
    "# in their name: only these ones affect the action.\n",
    "# NOTE: you can retrieve those parameters using model.get_parameters() too\n",
    "mean_params = dict(\n",
    "    (key, value)\n",
    "    for key, value in model.policy.state_dict().items()\n",
    "    if (\"policy\" in key or \"shared_net\" in key or \"action\" in key)\n",
    ")\n",
    "\n",
    "mean_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Population Size and Retrieve Environment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# population size of 50 invdiduals\n",
    "pop_size = 50\n",
    "# Keep top 10%\n",
    "n_elite = pop_size // 10\n",
    "# Retrieve the environment\n",
    "env = model.get_env()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterate through Mutated Policy Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1   Mean top fitness: -478.50\n",
      "Best fitness: -454.47\n",
      "Iteration 2   Mean top fitness: -495.36\n",
      "Best fitness: -475.02\n",
      "Iteration 3   Mean top fitness: -492.54\n",
      "Best fitness: -475.36\n",
      "Iteration 4   Mean top fitness: -479.80\n",
      "Best fitness: -465.07\n",
      "Iteration 5   Mean top fitness: -478.58\n",
      "Best fitness: -440.46\n",
      "Iteration 6   Mean top fitness: -484.92\n",
      "Best fitness: -470.12\n",
      "Iteration 7   Mean top fitness: -482.87\n",
      "Best fitness: -453.33\n",
      "Iteration 8   Mean top fitness: -471.44\n",
      "Best fitness: -447.52\n",
      "Iteration 9   Mean top fitness: -480.96\n",
      "Best fitness: -437.54\n",
      "Iteration 10  Mean top fitness: -488.49\n",
      "Best fitness: -478.64\n"
     ]
    }
   ],
   "source": [
    "for iteration in range(10):\n",
    "    # Create population of candidates and evaluate them\n",
    "    population = []\n",
    "    for population_i in range(pop_size):\n",
    "        candidate = mutate(mean_params)\n",
    "        # Load new policy parameters to agent.\n",
    "        # Tell function that it should only update parameters\n",
    "        # we give it (policy parameters)\n",
    "        model.policy.load_state_dict(candidate, strict=False)\n",
    "        # Evaluate the candidate\n",
    "        fitness, _ = evaluate_policy(model, env)\n",
    "        population.append((candidate, fitness))\n",
    "    # Take top 10% and use average over their parameters as next mean parameter\n",
    "    top_candidates = sorted(population, key=lambda x: x[1], reverse=True)[:n_elite]\n",
    "    mean_params = dict(\n",
    "        (\n",
    "            name,\n",
    "            th.stack([candidate[0][name] for candidate in top_candidates]).mean(dim=0),\n",
    "        )\n",
    "        for name in mean_params.keys()\n",
    "    )\n",
    "    mean_fitness = sum(top_candidate[1] for top_candidate in top_candidates) / n_elite\n",
    "    print(f\"Iteration {iteration + 1:<3} Mean top fitness: {mean_fitness:.2f}\")\n",
    "    print(f\"Best fitness: {top_candidates[0][1]:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3fe87c7677a9be80aab770929aa8f3d40850ac08a0f73ec246342c77c48f1c11"
  },
  "kernelspec": {
   "display_name": "Python 3.7.2 64-bit ('pydrl': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
